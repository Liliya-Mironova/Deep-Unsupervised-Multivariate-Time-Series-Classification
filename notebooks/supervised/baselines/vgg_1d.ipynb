{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading: [samples, features, timesteps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'ERing'\n",
    "# dataset_name = 'Cricket'\n",
    "dataset_name = 'HandMovementDirection'\n",
    "\n",
    "datasets_directory = \"/root/data/Multivariate_ts/\"\n",
    "\n",
    "X_train, y_train = load_from_tsfile_to_dataframe(datasets_directory + dataset_name + f'/{dataset_name}_TRAIN.ts')\n",
    "X_test, y_test = load_from_tsfile_to_dataframe(datasets_directory + dataset_name + f'/{dataset_name}_TEST.ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_torch(X):\n",
    "    X = X.applymap(np.array)\n",
    "    \n",
    "#     sc = preprocessing.MinMaxScaler()\n",
    "#     X = X.applymap(lambda x: sc.fit_transform(x.reshape(-1,1)).flatten())\n",
    "\n",
    "    dimensions_lst = []\n",
    "\n",
    "    for dim in X.columns:\n",
    "        dimensions_lst.append(np.dstack(list(X[dim].values))[0])\n",
    "\n",
    "    dimensions_lst = np.array(dimensions_lst)\n",
    "    X = torch.from_numpy(np.array(dimensions_lst, dtype=np.float64))\n",
    "    X = X.transpose(0, 2)\n",
    "    X = X.transpose(1, 2)\n",
    "    X = F.normalize(X, dim=1)\n",
    "    return X.float()\n",
    "\n",
    "\n",
    "def answers_to_torch(y):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    y = torch.from_numpy(np.array(y, dtype=np.int32))\n",
    "    y = y.long()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps: 400\n",
      "train samples_num: 160\n",
      "dims_num: 10\n",
      "num_classes: 4\n"
     ]
    }
   ],
   "source": [
    "X_train = features_to_torch(X_train)\n",
    "X_test = features_to_torch(X_test)\n",
    "\n",
    "y_train = answers_to_torch(y_train)\n",
    "y_test = answers_to_torch(y_test)\n",
    "\n",
    "samples_num = X_train.shape[0]\n",
    "time_steps = X_train.shape[2]\n",
    "dims_num = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_test))\n",
    "\n",
    "print('time_steps:', time_steps)\n",
    "print('train samples_num:', samples_num)\n",
    "print('dims_num:', dims_num)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vgg_1d():\n",
    "    \n",
    "#     fc_hidden_dim = 4096\n",
    "    fc_hidden_dim = 50\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                nn.Conv1d(dims_num, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features=512 * (time_steps // 2**5), out_features=fc_hidden_dim, bias=True),\n",
    "\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=0.5, inplace=False),\n",
    "                nn.Linear(in_features=fc_hidden_dim, out_features=fc_hidden_dim, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=0.5, inplace=False),\n",
    "                nn.Linear(in_features=fc_hidden_dim, out_features=num_classes, bias=True),\n",
    "                nn.Softmax()\n",
    "                        )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# models.vgg11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "        \n",
    "    \n",
    "def compute_accuracy(logits, y_true, device='cuda:0'):\n",
    "    y_pred = torch.argmax(logits, dim=1)\n",
    "    y_true_on_device = y_true.to(device)\n",
    "    accuracy = (y_pred == y_true_on_device).float().mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, batch_size, opt, criterion):\n",
    "\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train(True)\n",
    "\n",
    "        train_accuracy_batch = []\n",
    "\n",
    "        for batch_no, (X_batch, y_batch) in enumerate(iterate_minibatches(X_train, y_train, \n",
    "                                                                  batchsize=batch_size, \n",
    "                                                                  shuffle=True)):\n",
    "            model.zero_grad()\n",
    "            X_batch_gpu = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch_gpu)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if batch_no % 10 == 0:\n",
    "                train_loss.append(loss.item())\n",
    "                accuracy = compute_accuracy(logits, y_batch, device=device)\n",
    "                train_accuracy_batch.append(accuracy.item())\n",
    "\n",
    "        train_accuracy_overall = np.mean(train_accuracy_batch) * 100\n",
    "        train_accuracy.append(train_accuracy_overall.item())\n",
    "\n",
    "    \n",
    "        model.train(False)\n",
    "        val_accuracy_batch = []\n",
    "        for X_batch, y_batch in iterate_minibatches(X_test, y_test, \n",
    "                                                    batchsize=batch_size, \n",
    "                                                    shuffle=True):\n",
    "            X_batch_gpu = X_batch.to(device)\n",
    "            logits = model(X_batch_gpu)\n",
    "\n",
    "            accuracy = compute_accuracy(logits, y_batch, device=device)\n",
    "            val_accuracy_batch.append(accuracy.item())\n",
    "\n",
    "        val_accuracy_overall = np.mean(val_accuracy_batch) * 100\n",
    "        val_accuracy.append(val_accuracy_overall.item())\n",
    "\n",
    "            \n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train accuracy = {train_accuracy_overall}')\n",
    "        print(f'Validation accuracy = {val_accuracy_overall}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = make_vgg_1d()\n",
    "model = model.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 25\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "Train accuracy = 10.000000149011612\n",
      "Validation accuracy = 23.333333929379783\n",
      "\n",
      "Epoch 2/25\n",
      "Train accuracy = 25.0\n",
      "Validation accuracy = 20.000000298023224\n",
      "\n",
      "Epoch 3/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 43.33333373069763\n",
      "\n",
      "Epoch 4/25\n",
      "Train accuracy = 30.000001192092896\n",
      "Validation accuracy = 41.66666766007741\n",
      "\n",
      "Epoch 5/25\n",
      "Train accuracy = 30.000001192092896\n",
      "Validation accuracy = 40.00000059604645\n",
      "\n",
      "Epoch 6/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 41.66666766007741\n",
      "\n",
      "Epoch 7/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 43.33333373069763\n",
      "\n",
      "Epoch 8/25\n",
      "Train accuracy = 34.99999940395355\n",
      "Validation accuracy = 36.666667461395264\n",
      "\n",
      "Epoch 9/25\n",
      "Train accuracy = 40.00000059604645\n",
      "Validation accuracy = 38.333334525426224\n",
      "\n",
      "Epoch 10/25\n",
      "Train accuracy = 40.00000059604645\n",
      "Validation accuracy = 40.0000015894572\n",
      "\n",
      "Epoch 11/25\n",
      "Train accuracy = 10.000000149011612\n",
      "Validation accuracy = 20.00000004967054\n",
      "\n",
      "Epoch 12/25\n",
      "Train accuracy = 15.000000596046448\n",
      "Validation accuracy = 23.333333929379783\n",
      "\n",
      "Epoch 13/25\n",
      "Train accuracy = 34.99999940395355\n",
      "Validation accuracy = 21.666666865348816\n",
      "\n",
      "Epoch 14/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 20.00000042219957\n",
      "\n",
      "Epoch 15/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 20.0000007947286\n",
      "\n",
      "Epoch 16/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 43.33333472410838\n",
      "\n",
      "Epoch 17/25\n",
      "Train accuracy = 10.000000149011612\n",
      "Validation accuracy = 36.666667461395264\n",
      "\n",
      "Epoch 18/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 18.333333482344948\n",
      "\n",
      "Epoch 19/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 21.666666865348816\n",
      "\n",
      "Epoch 20/25\n",
      "Train accuracy = 25.0\n",
      "Validation accuracy = 40.00000059604645\n",
      "\n",
      "Epoch 21/25\n",
      "Train accuracy = 5.000000074505806\n",
      "Validation accuracy = 40.00000009934108\n",
      "\n",
      "Epoch 22/25\n",
      "Train accuracy = 15.000000596046448\n",
      "Validation accuracy = 38.333334525426224\n",
      "\n",
      "Epoch 23/25\n",
      "Train accuracy = 20.000000298023224\n",
      "Validation accuracy = 36.66666646798451\n",
      "\n",
      "Epoch 24/25\n",
      "Train accuracy = 5.000000074505806\n",
      "Validation accuracy = 16.66666716337204\n",
      "\n",
      "Epoch 25/25\n",
      "Train accuracy = 50.0\n",
      "Validation accuracy = 23.333333929379783\n"
     ]
    }
   ],
   "source": [
    "model = train(model, num_epochs, batch_size, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
