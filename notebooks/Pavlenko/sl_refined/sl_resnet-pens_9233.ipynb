{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tfs\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from utils import kNN, AverageMeter, py_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"VGG\"\n",
    "# magic_dim = 2048\n",
    "\n",
    "model_name = \"ResNet\"\n",
    "magic_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"PenDigits/PenDigits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "datadir = \"/root/data/Multivariate_ts\"\n",
    "\n",
    "# optimization\n",
    "lamb = 1      # SK lambda-parameter\n",
    "nopts = 400    # number of SK-optimizations\n",
    "epochs = 400   # numbers of epochs\n",
    "momentum = 0.9 # sgd momentum\n",
    "exp = './resnet1d_exp' # experiments results dir\n",
    "\n",
    "\n",
    "# other\n",
    "devc='0'  # cuda device\n",
    "batch_size = 500\n",
    "lr=0.003     #learning rate\n",
    "alr=0.003    #starting learning rate\n",
    "\n",
    "knn_dim = 20\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:' + devc) if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"GPU device: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_torch(X):\n",
    "    X = X.applymap(np.array)\n",
    "    dimensions_lst = []\n",
    "\n",
    "    for dim in X.columns:\n",
    "        dimensions_lst.append(np.dstack(list(X[dim].values))[0])\n",
    "\n",
    "    dimensions_lst = np.array(dimensions_lst)\n",
    "    X = torch.from_numpy(np.array(dimensions_lst, dtype=np.float64))\n",
    "    X = X.transpose(0, 2)\n",
    "    X = X.transpose(1, 2)\n",
    "    X = F.normalize(X, dim=1)\n",
    "    return X.float()\n",
    "\n",
    "def answers_to_torch(y):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    y = torch.from_numpy(np.array(y, dtype=np.int32))\n",
    "    y = y.long()\n",
    "    return y\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt], excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_tsfile_to_dataframe(datadir + f'/{dataset_name}_TRAIN.ts')\n",
    "X_test, y_test = load_from_tsfile_to_dataframe(datadir + f'/{dataset_name}_TEST.ts')\n",
    "\n",
    "X_train = features_to_torch(X_train)\n",
    "X_test = features_to_torch(X_test)\n",
    "\n",
    "y_train = answers_to_torch(y_train)\n",
    "y_test = answers_to_torch(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps: 8\n",
      "train samples_num: 7494\n",
      "dims_num: 2\n",
      "num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "N = X_train.shape[0]\n",
    "time_steps = X_train.shape[2]\n",
    "dims_num = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print('time_steps:', time_steps)\n",
    "print('train samples_num:', N)\n",
    "print('dims_num:', dims_num)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters (AlexNet in that case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc=10                 # number of heads\n",
    "ncl=num_classes       # number of clusters\n",
    "\n",
    "numc = [ncl] * hc\n",
    "# # (number of filters, kernel size, stride, pad) for AlexNet, two vesions\n",
    "# CFG = {\n",
    "#     'big': [(96, 11, 4, 2), 'M', (256, 5, 1, 2), 'M', (384, 3, 1, 1), (384, 3, 1, 1), (256, 3, 1, 1), 'M'],\n",
    "#     'small': [(64, 11, 4, 2), 'M', (192, 5, 1, 2), 'M', (384, 3, 1, 1), (256, 3, 1, 1), (256, 3, 1, 1), 'M']\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['resnetv1','resnetv1_18']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, power=2):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(self.power).sum(1, keepdim=True).pow(1. / self.power)\n",
    "        out = x.div(norm)\n",
    "        return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, in_channel=3, width=1, num_classes=[1000]):\n",
    "        self.inplanes = 16\n",
    "        super(ResNet, self).__init__()\n",
    "        self.headcount = len(num_classes)\n",
    "        self.base = int(16 * width)\n",
    "        self.features = nn.Sequential(*[                                                     # [100, 8, 18]\n",
    "                            nn.Conv1d(in_channel, 16, kernel_size=3, padding=1, bias=False), # [100, 16, 36]\n",
    "                            nn.BatchNorm1d(16),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            self._make_layer(block, self.base, layers[0]),                   # [100, 16, 36]\n",
    "                            self._make_layer(block, self.base * 2, layers[1]),               # [100, 32, 36]\n",
    "                            self._make_layer(block, self.base * 4, layers[2]),               # [100, 64, 36]\n",
    "                            self._make_layer(block, self.base * 8, layers[3]),               # [100, 128, 36]\n",
    "                            nn.AvgPool1d(2),                                                 # [100, 128, 18]\n",
    "        ])\n",
    "    \n",
    "        if len(num_classes) == 1:\n",
    "            self.top_layer = nn.Sequential(nn.Linear(magic_dim, num_classes[0]))\n",
    "        else:\n",
    "            for a, i in enumerate(num_classes):\n",
    "                setattr(self, \"top_layer%d\" % a, nn.Linear(magic_dim, i))\n",
    "            self.top_layer = None\n",
    "        for m in self.features.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x.float())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        if self.headcount == 1:\n",
    "            if self.top_layer:\n",
    "                out = self.top_layer(out)\n",
    "            return out\n",
    "        else:\n",
    "            outp = []\n",
    "            for i in range(self.headcount):\n",
    "                outp.append(getattr(self, \"top_layer%d\" % i)(out))\n",
    "            return outp\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnetv1_18(num_classes=[1000]):\n",
    "    \"\"\"Encoder for instance discrimination and MoCo\"\"\"\n",
    "    return resnet18(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG, self).__init__()\n",
    "        self.headcount = len(num_classes)\n",
    "        \n",
    "        self.features = nn.Sequential(*[                                                     # [100, 8, 18]\n",
    "                            nn.Conv1d(dims_num, 64, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "#                             nn.Flatten(),\n",
    "#                             nn.Linear(in_features=512 * (time_steps // 2**5), out_features=fc_hidden_dim, bias=True),\n",
    "\n",
    "#                             nn.ReLU(inplace=True),\n",
    "#                             nn.Dropout(p=0.5, inplace=False),\n",
    "#                             nn.Linear(in_features=fc_hidden_dim, out_features=fc_hidden_dim, bias=True),\n",
    "#                             nn.ReLU(inplace=True),\n",
    "#                             nn.Dropout(p=0.5, inplace=False),\n",
    "#                             nn.Linear(in_features=fc_hidden_dim, out_features=num_classes, bias=True),\n",
    "#                             nn.Softmax()\n",
    "        ])\n",
    "        \n",
    "        if len(num_classes) == 1:\n",
    "            self.top_layer = nn.Sequential(nn.Linear(magic_dim, num_classes[0]))\n",
    "        else:\n",
    "            for a, i in enumerate(num_classes):\n",
    "                setattr(self, \"top_layer%d\" % a, nn.Linear(magic_dim, i))\n",
    "            self.top_layer = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x.float())  # [50, 10, 400] -> [50, 512, 12]\n",
    "        out = out.view(out.size(0), -1) # [50, magic_dim]\n",
    "        if self.headcount == 1:\n",
    "            if self.top_layer:\n",
    "                out = self.top_layer(out)\n",
    "                print (out.size())\n",
    "            return out\n",
    "        else:\n",
    "            outp = []\n",
    "            for i in range(self.headcount):\n",
    "                outp.append(getattr(self, \"top_layer%d\" % i)(out))\n",
    "            return outp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn-Knopp optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_L_sk(PS):\n",
    "    N, K = PS.shape\n",
    "    tt = time.time()\n",
    "    PS = PS.T  # now it is K x N\n",
    "    r = np.ones((K, 1)) / K\n",
    "    c = np.ones((N, 1)) / N\n",
    "    PS **= lamb  # K x N\n",
    "    inv_K = 1. / K\n",
    "    inv_N = 1. / N\n",
    "    err = 1e3\n",
    "    _counter = 0\n",
    "    while err > 1e-2:\n",
    "        r = inv_K / (PS @ c)  # (KxN)@(N,1) = K x 1\n",
    "        c_new = inv_N / (r.T @ PS).T  # ((1,K)@(KxN)).t() = N x 1\n",
    "        if _counter % 10 == 0:\n",
    "            err = np.nansum(np.abs(c / c_new - 1))\n",
    "        c = c_new\n",
    "        _counter += 1\n",
    "        \n",
    "    print(\"error: \", err, 'step ', _counter, flush=True)  # \" nonneg: \", sum(I), flush=True)\n",
    "    # inplace calculations.\n",
    "    PS *= np.squeeze(c)\n",
    "    PS = PS.T\n",
    "    PS *= np.squeeze(r)\n",
    "    PS = PS.T\n",
    "    argmaxes = np.nanargmax(PS, 0)  # size N\n",
    "    newL = torch.LongTensor(argmaxes)\n",
    "    selflabels = newL.to(device)\n",
    "    PS = PS.T\n",
    "    PS /= np.squeeze(r)\n",
    "    PS = PS.T\n",
    "    PS /= np.squeeze(c)\n",
    "    sol = PS[argmaxes, np.arange(N)]\n",
    "    np.log(sol, sol)\n",
    "    cost = -(1. / lamb) * np.nansum(sol) / N\n",
    "    print('cost: ', cost, flush=True)\n",
    "    print('opt took {0:.2f}min, {1:4d}iters'.format(((time.time() - tt) / 60.), _counter), flush=True)\n",
    "    return cost, selflabels\n",
    "\n",
    "def opt_sk(model, selflabels_in, epoch):\n",
    "    if hc == 1:\n",
    "        PS = np.zeros((N, ncl))\n",
    "    else:\n",
    "        PS_pre = np.zeros((N, magic_dim)) # knn_dim\n",
    "    \n",
    "    for batch_idx, (data, _, _selected) in enumerate(iterate_minibatches(X_train, y_train, batch_size, shuffle=True)):\n",
    "        data = data.to(device)#cuda()\n",
    "        if hc == 1:\n",
    "            p = nn.functional.softmax(model(data), 1)\n",
    "            PS[_selected, :] = p.detach().cpu().numpy()\n",
    "        else:\n",
    "            p = model(data.float())\n",
    "            PS_pre[_selected, :] = p.detach().cpu().numpy() # p: [20, magic_dim]\n",
    "    if hc == 1:\n",
    "        cost, selflabels = optimize_L_sk(PS)\n",
    "        _costs = [cost]\n",
    "    else:\n",
    "        _nmis = np.zeros(hc)\n",
    "        _costs = np.zeros(hc)\n",
    "        nh = epoch % hc  # np.random.randint(args.hc)\n",
    "        print(\"computing head %s \" % nh, end=\"\\r\", flush=True)\n",
    "        tl = getattr(model, \"top_layer%d\" % nh)\n",
    "        # do the forward pass:\n",
    "        PS = (PS_pre @ tl.weight.cpu().numpy().T\n",
    "                   + tl.bias.cpu().numpy())\n",
    "        PS = py_softmax(PS, 1)\n",
    "        c, selflabels_ = optimize_L_sk(PS)\n",
    "        _costs[nh] = c\n",
    "        selflabels_in[nh] = selflabels_\n",
    "        selflabels = selflabels_in\n",
    "    return selflabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = alr\n",
    "    if epochs == 200:\n",
    "        if epoch >= 80:\n",
    "            lr = alr * (0.1 ** ((epoch - 80) // 40))  # i.e. 120, 160\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    elif epochs == 400:\n",
    "        if epoch >= 160:\n",
    "            lr = alr * (0.1 ** ((epoch - 160) // 80))  # i.e. 240,320\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    elif epochs == 800:\n",
    "        if epoch >= 320:\n",
    "            lr = alr * (0.1 ** ((epoch - 320) // 160))  # i.e. 480, 640\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    elif epochs == 1600:\n",
    "        if epoch >= 640:\n",
    "            lr = alr * (0.1 ** ((epoch - 640) // 320))\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_return_switch(model, bool=True):\n",
    "    \"\"\"\n",
    "    switch between network output or conv5features\n",
    "        if True: changes switch s.t. forward pass returns post-conv5 features\n",
    "        if False: changes switch s.t. forward will give full network output\n",
    "    \"\"\"\n",
    "    if bool:\n",
    "        model.headcount = 1\n",
    "    else:\n",
    "        model.headcount = hc\n",
    "    model.return_feature = bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, selflabels):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    print(model_name)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train_loss = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets, indexes) in enumerate(iterate_minibatches(X_train, y_train, batch_size, shuffle=True)):\n",
    "        inputs = inputs.float().to(device)\n",
    "        niter = epoch * N // batch_size + batch_idx\n",
    "        if niter * batch_size >= optimize_times[-1]:\n",
    "            with torch.no_grad():\n",
    "                _ = optimize_times.pop()\n",
    "                if hc >1:\n",
    "                    feature_return_switch(model, True)\n",
    "                selflabels = opt_sk(model, selflabels, epoch)\n",
    "                if hc >1:\n",
    "                    feature_return_switch(model, False)\n",
    "        data_time.update(time.time() - end)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)#, indexes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        if hc == 1:\n",
    "            loss = criterion(outputs, selflabels[indexes])\n",
    "        else:\n",
    "            loss = torch.mean(torch.stack([criterion(outputs[h], selflabels[h, indexes]) for h in range(hc)]))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "#         if True:\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: [{}][{}/{}]'\n",
    "                  'Time: {batch_time.val:.3f} ({batch_time.avg:.3f}) '\n",
    "                  'Data: {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Loss: {train_loss.val:.4f} ({train_loss.avg:.4f})'.format(\n",
    "                epoch, batch_idx, N // batch_size, batch_time=batch_time, data_time=data_time, train_loss=train_loss))\n",
    "#             writer.add_scalar(\"loss\", loss.item(), batch_idx*512 +epoch*N/batch_size)\n",
    "    return selflabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet created\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"ResNet\":\n",
    "    model = resnet18(num_classes=numc, in_channel=dims_num)\n",
    "else:\n",
    "    model = VGG(num_classes=numc)\n",
    "print (model_name, \"created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will optimize L at epochs: [410.0, 401.0, 400.0, 398.99, 397.99, 396.98, 395.98, 394.97, 393.97, 392.96, 391.95, 390.95, 389.94, 388.94, 387.93, 386.93, 385.92, 384.92, 383.91, 382.91, 381.9, 380.9, 379.89, 378.89, 377.88, 376.88, 375.87, 374.87, 373.86, 372.86, 371.85, 370.85, 369.84, 368.84, 367.83, 366.83, 365.82, 364.82, 363.81, 362.81, 361.8, 360.8, 359.79, 358.79, 357.78, 356.78, 355.77, 354.77, 353.76, 352.76, 351.75, 350.75, 349.74, 348.74, 347.73, 346.73, 345.72, 344.72, 343.71, 342.71, 341.7, 340.7, 339.69, 338.69, 337.68, 336.68, 335.67, 334.67, 333.66, 332.66, 331.65, 330.65, 329.64, 328.64, 327.63, 326.63, 325.62, 324.62, 323.61, 322.61, 321.6, 320.6, 319.59, 318.59, 317.58, 316.58, 315.57, 314.57, 313.56, 312.56, 311.55, 310.55, 309.54, 308.54, 307.53, 306.53, 305.52, 304.52, 303.51, 302.51, 301.5, 300.5, 299.49, 298.49, 297.48, 296.48, 295.47, 294.47, 293.46, 292.46, 291.45, 290.45, 289.44, 288.44, 287.43, 286.43, 285.42, 284.42, 283.41, 282.41, 281.4, 280.4, 279.39, 278.39, 277.38, 276.38, 275.37, 274.37, 273.36, 272.36, 271.35, 270.35, 269.34, 268.34, 267.33, 266.33, 265.32, 264.32, 263.31, 262.31, 261.3, 260.3, 259.29, 258.29, 257.28, 256.28, 255.27, 254.27, 253.26, 252.26, 251.25, 250.25, 249.24, 248.24, 247.23, 246.23, 245.22, 244.22, 243.21, 242.21, 241.2, 240.2, 239.19, 238.19, 237.18, 236.18, 235.17, 234.17, 233.16, 232.16, 231.15, 230.15, 229.14, 228.14, 227.13, 226.13, 225.12, 224.12, 223.11, 222.11, 221.1, 220.1, 219.09, 218.09, 217.08, 216.08, 215.07, 214.07, 213.06, 212.06, 211.05, 210.05, 209.04, 208.04, 207.03, 206.03, 205.02, 204.02, 203.01, 202.01, 201.0, 200.0, 198.99, 197.99, 196.98, 195.98, 194.97, 193.97, 192.96, 191.96, 190.95, 189.95, 188.94, 187.94, 186.93, 185.93, 184.92, 183.92, 182.91, 181.91, 180.9, 179.9, 178.89, 177.89, 176.88, 175.88, 174.87, 173.87, 172.86, 171.86, 170.85, 169.85, 168.84, 167.84, 166.83, 165.83, 164.82, 163.82, 162.81, 161.81, 160.8, 159.8, 158.79, 157.79, 156.78, 155.78, 154.77, 153.77, 152.76, 151.76, 150.75, 149.75, 148.74, 147.74, 146.73, 145.73, 144.72, 143.72, 142.71, 141.71, 140.7, 139.7, 138.69, 137.69, 136.68, 135.68, 134.67, 133.67, 132.66, 131.66, 130.65, 129.65, 128.64, 127.64, 126.63, 125.63, 124.62, 123.62, 122.61, 121.61, 120.6, 119.6, 118.59, 117.59, 116.58, 115.58, 114.57, 113.57, 112.56, 111.56, 110.55, 109.55, 108.54, 107.54, 106.53, 105.53, 104.52, 103.52, 102.51, 101.51, 100.5, 99.5, 98.49, 97.49, 96.48, 95.48, 94.47, 93.47, 92.46, 91.46, 90.45, 89.45, 88.44, 87.44, 86.43, 85.43, 84.42, 83.42, 82.41, 81.41, 80.4, 79.4, 78.39, 77.39, 76.38, 75.38, 74.37, 73.37, 72.36, 71.36, 70.35, 69.35, 68.34, 67.34, 66.33, 65.33, 64.32, 63.32, 62.31, 61.31, 60.3, 59.3, 58.29, 57.29, 56.28, 55.28, 54.27, 53.27, 52.26, 51.26, 50.25, 49.25, 48.24, 47.24, 46.23, 45.23, 44.22, 43.22, 42.21, 41.21, 40.2, 39.2, 38.19, 37.19, 36.18, 35.18, 34.17, 33.17, 32.16, 31.16, 30.15, 29.15, 28.14, 27.14, 26.13, 25.13, 24.12, 23.12, 22.11, 21.11, 20.1, 19.1, 18.09, 17.09, 16.08, 15.08, 14.07, 13.07, 12.06, 11.06, 10.05, 9.05, 8.04, 7.04, 6.03, 5.03, 4.02, 3.02, 2.01, 1.01, 0.0]\n"
     ]
    }
   ],
   "source": [
    "optimize_times = ((epochs + 1.0001)*N*(np.linspace(0, 1, nopts))[::-1]).tolist()\n",
    "optimize_times = [(epochs +10)*N] + optimize_times\n",
    "print('We will optimize L at epochs:', [np.round(1.0*t/N, 2) for t in optimize_times], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init selflabels randomly\n",
    "if hc == 1:\n",
    "    selflabels = np.zeros(N, dtype=np.int32)\n",
    "    for qq in range(N):\n",
    "        selflabels[qq] = qq % ncl\n",
    "    selflabels = np.random.permutation(selflabels)\n",
    "    selflabels = torch.LongTensor(selflabels).to(device)\n",
    "else:\n",
    "    selflabels = np.zeros((hc, N), dtype=np.int32)\n",
    "    for nh in range(hc):\n",
    "        for _i in range(N):\n",
    "            selflabels[nh, _i] = _i % numc[nh]\n",
    "        selflabels[nh] = np.random.permutation(selflabels[nh])\n",
    "    selflabels = torch.LongTensor(selflabels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'./runs/{dataset_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training! \n",
    "Takes a couple of minutes per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kNN(net, K, sigma=0.1, dim=128, use_pca=False):\n",
    "    net.eval()\n",
    "    # this part is ugly but made to be backwards-compatible. there was a change in cifar dataset's structure.\n",
    "    trainLabels = y_train\n",
    "    LEN = N\n",
    "    C = trainLabels.max() + 1\n",
    "\n",
    "    trainFeatures = torch.zeros((magic_dim, LEN))  # , device='cuda:0') # dim\n",
    "    normalize = Normalize()\n",
    "    for batch_idx, (inputs, targets, _) in enumerate(iterate_minibatches(X_train, y_train, batch_size, shuffle=False)):\n",
    "        batchSize = batch_size\n",
    "        inputs = inputs.cuda()\n",
    "        features = net(inputs.float())\n",
    "        if not use_pca:\n",
    "            features = normalize(features)\n",
    "        trainFeatures[:, batch_idx * batchSize:batch_idx * batchSize + batchSize] = features.data.t().cpu()\n",
    "        \n",
    "    if use_pca:\n",
    "        comps = 128\n",
    "        print('doing PCA with %s components'%comps, end=' ')\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=comps, whiten=False)\n",
    "        trainFeatures = pca.fit_transform(trainFeatures.numpy().T)\n",
    "        trainFeatures = torch.Tensor(trainFeatures)\n",
    "        trainFeatures = normalize(trainFeatures).t()\n",
    "        print('..done')\n",
    "    def eval_k_s(K_,sigma_):\n",
    "        total = 0\n",
    "        top1 = 0.\n",
    "#         top5 = 0.\n",
    "\n",
    "        with torch.no_grad():\n",
    "            retrieval_one_hot = torch.zeros(K_, C)# .cuda()\n",
    "            for batch_idx, (inputs, targets, _) in enumerate(iterate_minibatches(X_test, y_test, batch_size, shuffle=False)):\n",
    "                targets = targets # .cuda(async=True) # or without async for py3.7\n",
    "                inputs = inputs.cuda()\n",
    "                batchSize = batch_size\n",
    "                features = net(inputs)\n",
    "                if use_pca:\n",
    "                    features = pca.transform(features.cpu().numpy())\n",
    "                    features = torch.Tensor(features).cuda()\n",
    "                features = normalize(features).cpu()\n",
    "\n",
    "                dist = torch.mm(features, trainFeatures)\n",
    "\n",
    "                yd, yi = dist.topk(K_, dim=1, largest=True, sorted=True)\n",
    "                candidates = trainLabels.view(1, -1).expand(batchSize, -1)\n",
    "                retrieval = torch.gather(candidates, 1, yi).long()\n",
    "\n",
    "                retrieval_one_hot.resize_(batchSize * K_, C).zero_()\n",
    "                retrieval_one_hot.scatter_(1, retrieval.view(-1, 1), 1.)\n",
    "                \n",
    "                yd_transform = yd.clone().div_(sigma_).exp_()\n",
    "                probs = torch.sum(torch.mul(retrieval_one_hot.view(batchSize, -1, C),\n",
    "                                            yd_transform.view(batchSize, -1, 1)),\n",
    "                                  1)\n",
    "                _, predictions = probs.sort(1, True)\n",
    "\n",
    "                # Find which predictions match the target\n",
    "                correct = predictions.eq(targets.data.view(-1, 1))\n",
    "\n",
    "                top1 = top1 + correct.narrow(1, 0, 1).sum().item()\n",
    "#                 top5 = top5 + correct.narrow(1, 0, 5).sum().item()\n",
    "\n",
    "                total += targets.size(0)\n",
    "\n",
    "        print(f\"{K_}-NN,s={sigma_}: TOP1: \", top1 * 100. / total)\n",
    "        return top1 / total\n",
    "\n",
    "    if isinstance(K, list):\n",
    "        res = []\n",
    "        for K_ in K:\n",
    "            for sigma_ in sigma:\n",
    "                res.append(eval_k_s(K_, sigma_))\n",
    "        return res\n",
    "    else:\n",
    "        res = eval_k_s(K, sigma)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "ResNet\n",
      "error:  2.198907722572585e-12 step  11\n",
      "cost:  1.8309918499843867\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [0][0/14]Time: 0.242 (0.242) Data: 0.166 (0.166) Loss: 2.4481 (2.4481)\n",
      "Epoch: [0][10/14]Time: 0.033 (0.054) Data: 0.000 (0.016) Loss: 2.3291 (2.4108)\n",
      "10-NN,s=0.1: TOP1:  90.43333333333334\n",
      "Saving..\n",
      "Saving..\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  88.36666666666666\n",
      "50-NN,s=0.5: TOP1:  85.1\n",
      "10-NN,s=0.1: TOP1:  90.9\n",
      "10-NN,s=0.5: TOP1:  90.0\n",
      "best accuracy: 90.43\n",
      "\n",
      "Epoch: 1\n",
      "ResNet\n",
      "Epoch: [1][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 2.2700 (2.2700)\n",
      "error:  2.540190280342358e-13 step  11\n",
      "cost:  2.0304588050026444\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [1][10/14]Time: 0.026 (0.044) Data: 0.000 (0.014) Loss: 2.1883 (2.2219)\n",
      "10-NN,s=0.1: TOP1:  90.23333333333333\n",
      "best accuracy: 90.43\n",
      "\n",
      "Epoch: 2\n",
      "ResNet\n",
      "Epoch: [2][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 2.1442 (2.1442)\n",
      "error:  3.239630785856207e-13 step  11\n",
      "cost:  1.9740387419476242\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [2][10/14]Time: 0.025 (0.040) Data: 0.000 (0.011) Loss: 2.0379 (2.0811)\n",
      "10-NN,s=0.1: TOP1:  90.16666666666667\n",
      "best accuracy: 90.43\n",
      "\n",
      "Epoch: 3\n",
      "ResNet\n",
      "Epoch: [3][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 1.9695 (1.9695)\n",
      "error:  0.0 step  11\n",
      "cost:  1.9251992854620585\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [3][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 1.8951 (1.9349)\n",
      "10-NN,s=0.1: TOP1:  90.06666666666666\n",
      "best accuracy: 90.43\n",
      "\n",
      "Epoch: 4\n",
      "ResNet\n",
      "Epoch: [4][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 1.8593 (1.8593)\n",
      "error:  1.7743584379559252e-12 step  11\n",
      "cost:  1.8951502814317072\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [4][10/14]Time: 0.026 (0.038) Data: 0.000 (0.009) Loss: 1.7507 (1.7857)\n",
      "10-NN,s=0.1: TOP1:  90.06666666666666\n",
      "best accuracy: 90.43\n",
      "\n",
      "Epoch: 5\n",
      "ResNet\n",
      "Epoch: [5][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 1.6746 (1.6746)\n",
      "error:  8.004708007547379e-13 step  11\n",
      "cost:  1.8240662296713468\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [5][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 1.6314 (1.6383)\n",
      "10-NN,s=0.1: TOP1:  90.36666666666666\n",
      "best accuracy: 90.43\n",
      "\n",
      "Epoch: 6\n",
      "ResNet\n",
      "Epoch: [6][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 1.5453 (1.5453)\n",
      "error:  1.9828583219805296e-13 step  11\n",
      "cost:  1.779447086316219\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [6][10/14]Time: 0.027 (0.043) Data: 0.000 (0.011) Loss: 1.4426 (1.4818)\n",
      "10-NN,s=0.1: TOP1:  90.5\n",
      "Saving..\n",
      "best accuracy: 90.50\n",
      "\n",
      "Epoch: 7\n",
      "ResNet\n",
      "Epoch: [7][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 1.3664 (1.3664)\n",
      "error:  8.93285445613401e-13 step  11\n",
      "cost:  1.7676992377759346\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [7][10/14]Time: 0.028 (0.040) Data: 0.000 (0.010) Loss: 1.2921 (1.3371)\n",
      "10-NN,s=0.1: TOP1:  89.96666666666667\n",
      "best accuracy: 90.50\n",
      "\n",
      "Epoch: 8\n",
      "ResNet\n",
      "Epoch: [8][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 1.2224 (1.2224)\n",
      "error:  3.3673064336881e-13 step  11\n",
      "cost:  1.7192985330916315\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [8][10/14]Time: 0.025 (0.040) Data: 0.000 (0.011) Loss: 1.1647 (1.1968)\n",
      "10-NN,s=0.1: TOP1:  90.36666666666666\n",
      "best accuracy: 90.50\n",
      "\n",
      "Epoch: 9\n",
      "ResNet\n",
      "Epoch: [9][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 1.0864 (1.0864)\n",
      "error:  3.4489078259980488e-12 step  11\n",
      "cost:  1.6895368341499413\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [9][10/14]Time: 0.034 (0.046) Data: 0.000 (0.012) Loss: 1.0635 (1.0527)\n",
      "10-NN,s=0.1: TOP1:  90.93333333333334\n",
      "Saving..\n",
      "best accuracy: 90.93\n",
      "\n",
      "Epoch: 10\n",
      "ResNet\n",
      "Epoch: [10][0/14]Time: 0.044 (0.044) Data: 0.001 (0.001) Loss: 0.9372 (0.9372)\n",
      "error:  0.0018219066635815073 step  21\n",
      "cost:  0.657034983192567\n",
      "opt took 0.00min,   21iters\n",
      "Epoch: [10][10/14]Time: 0.031 (0.053) Data: 0.000 (0.014) Loss: 0.9331 (0.9321)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "Saving..\n",
      "best accuracy: 91.33\n",
      "\n",
      "Epoch: 11\n",
      "ResNet\n",
      "Epoch: [11][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.8302 (0.8302)\n",
      "error:  0.0010276375694548978 step  31\n",
      "cost:  0.5376077015738797\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [11][10/14]Time: 0.027 (0.043) Data: 0.000 (0.012) Loss: 0.8767 (0.8611)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "Saving..\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 12\n",
      "ResNet\n",
      "Epoch: [12][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.8124 (0.8124)\n",
      "error:  0.0015567728759702248 step  31\n",
      "cost:  0.5216489815024359\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [12][10/14]Time: 0.033 (0.044) Data: 0.000 (0.011) Loss: 0.8143 (0.8008)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 13\n",
      "ResNet\n",
      "Epoch: [13][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.7309 (0.7309)\n",
      "error:  0.0030585931760738205 step  31\n",
      "cost:  0.5078568683479485\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [13][10/14]Time: 0.027 (0.042) Data: 0.000 (0.011) Loss: 0.7856 (0.7553)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 14\n",
      "ResNet\n",
      "Epoch: [14][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.7009 (0.7009)\n",
      "error:  0.0004143141349866042 step  31\n",
      "cost:  0.5034135114182279\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [14][10/14]Time: 0.031 (0.047) Data: 0.000 (0.012) Loss: 0.7492 (0.7104)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 15\n",
      "ResNet\n",
      "Epoch: [15][0/14]Time: 0.030 (0.030) Data: 0.002 (0.002) Loss: 0.6644 (0.6644)\n",
      "error:  0.00010105621739409099 step  31\n",
      "cost:  0.5185168295374969\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [15][10/14]Time: 0.025 (0.044) Data: 0.000 (0.013) Loss: 0.6942 (0.6801)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 16\n",
      "ResNet\n",
      "Epoch: [16][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.6053 (0.6053)\n",
      "error:  0.00018839956038108063 step  31\n",
      "cost:  0.5564232697720602\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [16][10/14]Time: 0.028 (0.041) Data: 0.000 (0.011) Loss: 0.6279 (0.6300)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 17\n",
      "ResNet\n",
      "Epoch: [17][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.5733 (0.5733)\n",
      "error:  0.0001270085052722525 step  31\n",
      "cost:  0.5280113858092409\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [17][10/14]Time: 0.028 (0.040) Data: 0.000 (0.011) Loss: 0.5971 (0.5852)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 18\n",
      "ResNet\n",
      "Epoch: [18][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.5192 (0.5192)\n",
      "error:  0.0036904471360993396 step  21\n",
      "cost:  0.5818058350953467\n",
      "opt took 0.00min,   21iters\n",
      "Epoch: [18][10/14]Time: 0.034 (0.042) Data: 0.000 (0.010) Loss: 0.5874 (0.5511)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 91.63\n",
      "\n",
      "Epoch: 19\n",
      "ResNet\n",
      "Epoch: [19][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.5015 (0.5015)\n",
      "error:  6.676429628715841e-05 step  31\n",
      "cost:  0.517047349989276\n",
      "opt took 0.00min,   31iters\n",
      "Epoch: [19][10/14]Time: 0.026 (0.040) Data: 0.000 (0.010) Loss: 0.5731 (0.5355)\n",
      "10-NN,s=0.1: TOP1:  91.83333333333333\n",
      "Saving..\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 20\n",
      "ResNet\n",
      "Epoch: [20][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4865 (0.4865)\n",
      "error:  0.0015186321213445098 step  41\n",
      "cost:  0.40348030174926186\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [20][10/14]Time: 0.030 (0.043) Data: 0.000 (0.012) Loss: 0.5407 (0.5243)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 21\n",
      "ResNet\n",
      "Epoch: [21][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4649 (0.4649)\n",
      "error:  0.000881548891339401 step  51\n",
      "cost:  0.3473540696573245\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [21][10/14]Time: 0.028 (0.043) Data: 0.000 (0.012) Loss: 0.5511 (0.5184)\n",
      "10-NN,s=0.1: TOP1:  91.8\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 22\n",
      "ResNet\n",
      "Epoch: [22][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4610 (0.4610)\n",
      "error:  0.008304255670436134 step  41\n",
      "cost:  0.4060830933551543\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [22][10/14]Time: 0.028 (0.045) Data: 0.000 (0.012) Loss: 0.5391 (0.5141)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 23\n",
      "ResNet\n",
      "Epoch: [23][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4707 (0.4707)\n",
      "error:  0.0017956845466104987 step  51\n",
      "cost:  0.36552312048332114\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [23][10/14]Time: 0.029 (0.046) Data: 0.000 (0.017) Loss: 0.5318 (0.4917)\n",
      "10-NN,s=0.1: TOP1:  91.8\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 24\n",
      "ResNet\n",
      "Epoch: [24][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.4429 (0.4429)\n",
      "error:  0.0013350659709201462 step  51\n",
      "cost:  0.37619590713486495\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [24][10/14]Time: 0.028 (0.041) Data: 0.000 (0.011) Loss: 0.4999 (0.4681)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 25\n",
      "ResNet\n",
      "Epoch: [25][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.4093 (0.4093)\n",
      "error:  0.0009347666629488938 step  41\n",
      "cost:  0.3614874941491231\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [25][10/14]Time: 0.027 (0.044) Data: 0.000 (0.011) Loss: 0.4791 (0.4525)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 26\n",
      "ResNet\n",
      "Epoch: [26][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3788 (0.3788)\n",
      "error:  0.002172176825272931 step  41\n",
      "cost:  0.39722994005044127\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [26][10/14]Time: 0.029 (0.044) Data: 0.000 (0.012) Loss: 0.4770 (0.4465)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 91.83\n",
      "\n",
      "Epoch: 27\n",
      "ResNet\n",
      "Epoch: [27][0/14]Time: 0.036 (0.036) Data: 0.002 (0.002) Loss: 0.4019 (0.4019)\n",
      "error:  0.0009022594514704885 step  41\n",
      "cost:  0.378622813870011\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [27][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.4844 (0.4577)\n",
      "10-NN,s=0.1: TOP1:  91.93333333333334\n",
      "Saving..\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 28\n",
      "ResNet\n",
      "Epoch: [28][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.4023 (0.4023)\n",
      "error:  0.0005652676765377507 step  41\n",
      "cost:  0.4114380907468882\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [28][10/14]Time: 0.026 (0.039) Data: 0.000 (0.010) Loss: 0.4588 (0.4474)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 29\n",
      "ResNet\n",
      "Epoch: [29][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3997 (0.3997)\n",
      "error:  0.0006781376998475919 step  41\n",
      "cost:  0.40542954133965564\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [29][10/14]Time: 0.028 (0.044) Data: 0.000 (0.014) Loss: 0.4502 (0.4231)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 30\n",
      "ResNet\n",
      "Epoch: [30][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3891 (0.3891)\n",
      "error:  0.0017854870858232674 step  51\n",
      "cost:  0.3429057279592886\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [30][10/14]Time: 0.033 (0.047) Data: 0.000 (0.013) Loss: 0.4810 (0.4292)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 31\n",
      "ResNet\n",
      "Epoch: [31][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3676 (0.3676)\n",
      "error:  0.005839346017060931 step  61\n",
      "cost:  0.3188512790715559\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [31][10/14]Time: 0.026 (0.046) Data: 0.000 (0.016) Loss: 0.4461 (0.4312)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 32\n",
      "ResNet\n",
      "Epoch: [32][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3714 (0.3714)\n",
      "error:  0.006706708124865068 step  51\n",
      "cost:  0.34175214577790286\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [32][10/14]Time: 0.025 (0.042) Data: 0.000 (0.013) Loss: 0.4298 (0.4107)\n",
      "10-NN,s=0.1: TOP1:  91.76666666666667\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 33\n",
      "ResNet\n",
      "Epoch: [33][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3987 (0.3987)\n",
      "error:  0.003528329968955579 step  51\n",
      "cost:  0.34629325727414695\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [33][10/14]Time: 0.026 (0.038) Data: 0.000 (0.010) Loss: 0.4237 (0.4057)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 34\n",
      "ResNet\n",
      "Epoch: [34][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3582 (0.3582)\n",
      "error:  0.002458301702768728 step  61\n",
      "cost:  0.3356356180378348\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [34][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 0.4457 (0.3972)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 35\n",
      "ResNet\n",
      "Epoch: [35][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3503 (0.3503)\n",
      "error:  0.0012148962234885818 step  51\n",
      "cost:  0.3186695875955677\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [35][10/14]Time: 0.029 (0.041) Data: 0.000 (0.010) Loss: 0.4153 (0.3969)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 36\n",
      "ResNet\n",
      "Epoch: [36][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3427 (0.3427)\n",
      "error:  0.002832549848809207 step  41\n",
      "cost:  0.3305086511856117\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [36][10/14]Time: 0.039 (0.043) Data: 0.001 (0.011) Loss: 0.4763 (0.4083)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 37\n",
      "ResNet\n",
      "Epoch: [37][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3832 (0.3832)\n",
      "error:  0.009257186860094246 step  41\n",
      "cost:  0.3640605300027964\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [37][10/14]Time: 0.025 (0.042) Data: 0.000 (0.013) Loss: 0.4421 (0.4067)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 38\n",
      "ResNet\n",
      "Epoch: [38][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3837 (0.3837)\n",
      "error:  0.003024718160500539 step  41\n",
      "cost:  0.3419028149237525\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [38][10/14]Time: 0.025 (0.039) Data: 0.000 (0.010) Loss: 0.4467 (0.4187)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 39\n",
      "ResNet\n",
      "Epoch: [39][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3718 (0.3718)\n",
      "error:  0.0017804763406976676 step  41\n",
      "cost:  0.32870059835999726\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [39][10/14]Time: 0.032 (0.046) Data: 0.000 (0.015) Loss: 0.4442 (0.4122)\n",
      "10-NN,s=0.1: TOP1:  90.93333333333334\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 40\n",
      "ResNet\n",
      "Epoch: [40][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3858 (0.3858)\n",
      "error:  0.002563889808777864 step  51\n",
      "cost:  0.33147849701455673\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [40][10/14]Time: 0.025 (0.044) Data: 0.000 (0.012) Loss: 0.4496 (0.4143)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 41\n",
      "ResNet\n",
      "Epoch: [41][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3739 (0.3739)\n",
      "error:  0.005863906833709853 step  61\n",
      "cost:  0.3291675439284215\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [41][10/14]Time: 0.028 (0.043) Data: 0.000 (0.011) Loss: 0.4322 (0.4147)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 42\n",
      "ResNet\n",
      "Epoch: [42][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3930 (0.3930)\n",
      "error:  0.0053882689576886245 step  61\n",
      "cost:  0.3130146464288022\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [42][10/14]Time: 0.024 (0.042) Data: 0.000 (0.012) Loss: 0.4593 (0.4181)\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 43\n",
      "ResNet\n",
      "Epoch: [43][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3834 (0.3834)\n",
      "error:  0.009125358889185087 step  41\n",
      "cost:  0.30093127307457085\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [43][10/14]Time: 0.028 (0.041) Data: 0.000 (0.010) Loss: 0.4369 (0.4115)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 44\n",
      "ResNet\n",
      "Epoch: [44][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3642 (0.3642)\n",
      "error:  0.0013513866842644884 step  51\n",
      "cost:  0.32558055781481565\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [44][10/14]Time: 0.029 (0.057) Data: 0.000 (0.020) Loss: 0.4408 (0.4026)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 45\n",
      "ResNet\n",
      "Epoch: [45][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3569 (0.3569)\n",
      "error:  0.008747207710469329 step  51\n",
      "cost:  0.33528450545550786\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [45][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.4050 (0.3752)\n",
      "10-NN,s=0.1: TOP1:  91.76666666666667\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 46\n",
      "ResNet\n",
      "Epoch: [46][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3239 (0.3239)\n",
      "error:  0.0014831874396064038 step  51\n",
      "cost:  0.3400871830749046\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [46][10/14]Time: 0.028 (0.047) Data: 0.000 (0.015) Loss: 0.4062 (0.3763)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 47\n",
      "ResNet\n",
      "Epoch: [47][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3165 (0.3165)\n",
      "error:  0.002826979341256086 step  51\n",
      "cost:  0.32334440228096367\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [47][10/14]Time: 0.028 (0.043) Data: 0.000 (0.012) Loss: 0.4176 (0.3693)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 48\n",
      "ResNet\n",
      "Epoch: [48][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3401 (0.3401)\n",
      "error:  0.007963566583634285 step  41\n",
      "cost:  0.3464731048441267\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [48][10/14]Time: 0.029 (0.045) Data: 0.000 (0.012) Loss: 0.3997 (0.3784)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 49\n",
      "ResNet\n",
      "Epoch: [49][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3661 (0.3661)\n",
      "error:  0.005786965844516878 step  41\n",
      "cost:  0.35103498064671224\n",
      "opt took 0.00min,   41iters\n",
      "Epoch: [49][10/14]Time: 0.028 (0.042) Data: 0.000 (0.011) Loss: 0.4303 (0.3887)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 91.93\n",
      "\n",
      "Epoch: 50\n",
      "ResNet\n",
      "Epoch: [50][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3752 (0.3752)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.005148393146534147 step  61\n",
      "cost:  0.3447144059996935\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [50][10/14]Time: 0.026 (0.044) Data: 0.000 (0.011) Loss: 0.3961 (0.3817)\n",
      "10-NN,s=0.1: TOP1:  92.0\n",
      "Saving..\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  91.43333333333334\n",
      "50-NN,s=0.5: TOP1:  88.26666666666667\n",
      "10-NN,s=0.1: TOP1:  92.0\n",
      "10-NN,s=0.5: TOP1:  91.2\n",
      "best accuracy: 92.00\n",
      "\n",
      "Epoch: 51\n",
      "ResNet\n",
      "Epoch: [51][0/14]Time: 0.025 (0.025) Data: 0.000 (0.000) Loss: 0.3438 (0.3438)\n",
      "error:  0.0037355490285561066 step  61\n",
      "cost:  0.28045033764155164\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [51][10/14]Time: 0.029 (0.040) Data: 0.000 (0.011) Loss: 0.4089 (0.3737)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.00\n",
      "\n",
      "Epoch: 52\n",
      "ResNet\n",
      "Epoch: [52][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.3253 (0.3253)\n",
      "error:  0.007414812827390205 step  61\n",
      "cost:  0.3604442449746548\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [52][10/14]Time: 0.025 (0.040) Data: 0.000 (0.010) Loss: 0.4462 (0.3718)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.00\n",
      "\n",
      "Epoch: 53\n",
      "ResNet\n",
      "Epoch: [53][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3459 (0.3459)\n",
      "error:  0.004521493921159303 step  51\n",
      "cost:  0.3155430485395839\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [53][10/14]Time: 0.028 (0.042) Data: 0.000 (0.011) Loss: 0.4098 (0.3670)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.00\n",
      "\n",
      "Epoch: 54\n",
      "ResNet\n",
      "Epoch: [54][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3238 (0.3238)\n",
      "error:  0.005869621129674152 step  51\n",
      "cost:  0.36099145630315865\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [54][10/14]Time: 0.028 (0.042) Data: 0.000 (0.011) Loss: 0.3999 (0.3658)\n",
      "10-NN,s=0.1: TOP1:  91.96666666666667\n",
      "best accuracy: 92.00\n",
      "\n",
      "Epoch: 55\n",
      "ResNet\n",
      "Epoch: [55][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3355 (0.3355)\n",
      "error:  0.0054282803465874885 step  51\n",
      "cost:  0.29295350020516037\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [55][10/14]Time: 0.025 (0.047) Data: 0.000 (0.015) Loss: 0.4571 (0.3681)\n",
      "10-NN,s=0.1: TOP1:  92.16666666666667\n",
      "Saving..\n",
      "best accuracy: 92.17\n",
      "\n",
      "Epoch: 56\n",
      "ResNet\n",
      "Epoch: [56][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3679 (0.3679)\n",
      "error:  0.0015157594757246873 step  51\n",
      "cost:  0.31507269084929235\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [56][10/14]Time: 0.025 (0.042) Data: 0.000 (0.010) Loss: 0.4036 (0.3772)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.17\n",
      "\n",
      "Epoch: 57\n",
      "ResNet\n",
      "Epoch: [57][0/14]Time: 0.047 (0.047) Data: 0.002 (0.002) Loss: 0.3167 (0.3167)\n",
      "error:  0.0011529201207413076 step  51\n",
      "cost:  0.3619061428062044\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [57][10/14]Time: 0.025 (0.042) Data: 0.000 (0.010) Loss: 0.3998 (0.3753)\n",
      "10-NN,s=0.1: TOP1:  92.0\n",
      "best accuracy: 92.17\n",
      "\n",
      "Epoch: 58\n",
      "ResNet\n",
      "Epoch: [58][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3570 (0.3570)\n",
      "error:  0.0029773530551090444 step  51\n",
      "cost:  0.3098488927565969\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [58][10/14]Time: 0.028 (0.039) Data: 0.000 (0.010) Loss: 0.4519 (0.3848)\n",
      "10-NN,s=0.1: TOP1:  91.73333333333333\n",
      "best accuracy: 92.17\n",
      "\n",
      "Epoch: 59\n",
      "ResNet\n",
      "Epoch: [59][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4039 (0.4039)\n",
      "error:  0.0009251582054058405 step  51\n",
      "cost:  0.34922516166065143\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [59][10/14]Time: 0.028 (0.044) Data: 0.000 (0.013) Loss: 0.4339 (0.3770)\n",
      "10-NN,s=0.1: TOP1:  92.2\n",
      "Saving..\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 60\n",
      "ResNet\n",
      "Epoch: [60][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3545 (0.3545)\n",
      "error:  0.006728717858683897 step  51\n",
      "cost:  0.28552560262475635\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [60][10/14]Time: 0.028 (0.047) Data: 0.000 (0.015) Loss: 0.4409 (0.3704)\n",
      "10-NN,s=0.1: TOP1:  91.96666666666667\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 61\n",
      "ResNet\n",
      "Epoch: [61][0/14]Time: 0.035 (0.035) Data: 0.002 (0.002) Loss: 0.3277 (0.3277)\n",
      "error:  0.005812662371439514 step  71\n",
      "cost:  0.32401638488125856\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [61][10/14]Time: 0.027 (0.042) Data: 0.000 (0.011) Loss: 0.4079 (0.3676)\n",
      "10-NN,s=0.1: TOP1:  92.13333333333334\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 62\n",
      "ResNet\n",
      "Epoch: [62][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3272 (0.3272)\n",
      "error:  0.003124670745173086 step  61\n",
      "cost:  0.27368974312421673\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [62][10/14]Time: 0.025 (0.040) Data: 0.000 (0.010) Loss: 0.3927 (0.3536)\n",
      "10-NN,s=0.1: TOP1:  92.0\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 63\n",
      "ResNet\n",
      "Epoch: [63][0/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.3169 (0.3169)\n",
      "error:  0.002416498301633929 step  61\n",
      "cost:  0.31353974079652835\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [63][10/14]Time: 0.026 (0.047) Data: 0.000 (0.018) Loss: 0.3745 (0.3446)\n",
      "10-NN,s=0.1: TOP1:  92.1\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 64\n",
      "ResNet\n",
      "Epoch: [64][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3019 (0.3019)\n",
      "error:  0.006220599455377007 step  51\n",
      "cost:  0.3200754329979958\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [64][10/14]Time: 0.028 (0.052) Data: 0.000 (0.020) Loss: 0.3753 (0.3362)\n",
      "10-NN,s=0.1: TOP1:  91.96666666666667\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 65\n",
      "ResNet\n",
      "Epoch: [65][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3035 (0.3035)\n",
      "error:  0.003792600952834402 step  61\n",
      "cost:  0.29652349661364585\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [65][10/14]Time: 0.028 (0.042) Data: 0.000 (0.010) Loss: 0.3667 (0.3383)\n",
      "10-NN,s=0.1: TOP1:  91.96666666666667\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 66\n",
      "ResNet\n",
      "Epoch: [66][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.2986 (0.2986)\n",
      "error:  0.004424845294827562 step  51\n",
      "cost:  0.2894015833512139\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [66][10/14]Time: 0.032 (0.045) Data: 0.000 (0.011) Loss: 0.3928 (0.3321)\n",
      "10-NN,s=0.1: TOP1:  92.1\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 67\n",
      "ResNet\n",
      "Epoch: [67][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.2960 (0.2960)\n",
      "error:  0.002564191087250256 step  51\n",
      "cost:  0.2954488680218602\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [67][10/14]Time: 0.029 (0.045) Data: 0.000 (0.011) Loss: 0.3612 (0.3341)\n",
      "10-NN,s=0.1: TOP1:  92.06666666666666\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 68\n",
      "ResNet\n",
      "Epoch: [68][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3306 (0.3306)\n",
      "error:  0.0044280542157675296 step  51\n",
      "cost:  0.3122107956489178\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [68][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.3600 (0.3368)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 69\n",
      "ResNet\n",
      "Epoch: [69][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2984 (0.2984)\n",
      "error:  0.004317883673825573 step  51\n",
      "cost:  0.34763935276740576\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [69][10/14]Time: 0.029 (0.041) Data: 0.000 (0.012) Loss: 0.3825 (0.3371)\n",
      "10-NN,s=0.1: TOP1:  91.8\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 70\n",
      "ResNet\n",
      "Epoch: [70][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3105 (0.3105)\n",
      "error:  0.004330829707173245 step  61\n",
      "cost:  0.30916520611367687\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [70][10/14]Time: 0.033 (0.043) Data: 0.000 (0.012) Loss: 0.3606 (0.3348)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 71\n",
      "ResNet\n",
      "Epoch: [71][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.2705 (0.2705)\n",
      "error:  0.006542656494340715 step  81\n",
      "cost:  0.2867911273266155\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [71][10/14]Time: 0.024 (0.040) Data: 0.000 (0.012) Loss: 0.3879 (0.3357)\n",
      "10-NN,s=0.1: TOP1:  92.0\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 72\n",
      "ResNet\n",
      "Epoch: [72][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3289 (0.3289)\n",
      "error:  0.0027721548973017596 step  61\n",
      "cost:  0.3091463286438934\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [72][10/14]Time: 0.024 (0.038) Data: 0.000 (0.010) Loss: 0.4264 (0.3529)\n",
      "10-NN,s=0.1: TOP1:  91.73333333333333\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 73\n",
      "ResNet\n",
      "Epoch: [73][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3457 (0.3457)\n",
      "error:  0.004010959778606105 step  61\n",
      "cost:  0.31647676714745\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [73][10/14]Time: 0.032 (0.047) Data: 0.000 (0.015) Loss: 0.4066 (0.3644)\n",
      "10-NN,s=0.1: TOP1:  91.8\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 74\n",
      "ResNet\n",
      "Epoch: [74][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3453 (0.3453)\n",
      "error:  0.002892438777998052 step  61\n",
      "cost:  0.31582559364082974\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [74][10/14]Time: 0.029 (0.043) Data: 0.000 (0.012) Loss: 0.4033 (0.3650)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 75\n",
      "ResNet\n",
      "Epoch: [75][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3540 (0.3540)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.006752546034266671 step  51\n",
      "cost:  0.3386933764928414\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [75][10/14]Time: 0.028 (0.039) Data: 0.000 (0.010) Loss: 0.4205 (0.3667)\n",
      "10-NN,s=0.1: TOP1:  92.1\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 76\n",
      "ResNet\n",
      "Epoch: [76][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3310 (0.3310)\n",
      "error:  0.0018670471228658947 step  61\n",
      "cost:  0.3075058156901782\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [76][10/14]Time: 0.029 (0.042) Data: 0.000 (0.012) Loss: 0.3656 (0.3467)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 77\n",
      "ResNet\n",
      "Epoch: [77][0/14]Time: 0.035 (0.035) Data: 0.001 (0.001) Loss: 0.3367 (0.3367)\n",
      "error:  0.0019264120935602591 step  51\n",
      "cost:  0.29955323587117744\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [77][10/14]Time: 0.028 (0.044) Data: 0.000 (0.011) Loss: 0.3841 (0.3430)\n",
      "10-NN,s=0.1: TOP1:  92.1\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 78\n",
      "ResNet\n",
      "Epoch: [78][0/14]Time: 0.043 (0.043) Data: 0.001 (0.001) Loss: 0.2981 (0.2981)\n",
      "error:  0.0036132586067197936 step  51\n",
      "cost:  0.32333142719536084\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [78][10/14]Time: 0.038 (0.049) Data: 0.001 (0.013) Loss: 0.3708 (0.3408)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 79\n",
      "ResNet\n",
      "Epoch: [79][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3229 (0.3229)\n",
      "error:  0.005529941176394382 step  51\n",
      "cost:  0.3302351676239375\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [79][10/14]Time: 0.028 (0.048) Data: 0.000 (0.015) Loss: 0.3532 (0.3437)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.20\n",
      "\n",
      "Epoch: 80\n",
      "ResNet\n",
      "Epoch: [80][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3163 (0.3163)\n",
      "error:  0.008370036459992125 step  51\n",
      "cost:  0.3062756209902268\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [80][10/14]Time: 0.027 (0.043) Data: 0.000 (0.012) Loss: 0.3783 (0.3581)\n",
      "10-NN,s=0.1: TOP1:  92.33333333333333\n",
      "Saving..\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 81\n",
      "ResNet\n",
      "Epoch: [81][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3454 (0.3454)\n",
      "error:  0.006712824579546139 step  71\n",
      "cost:  0.31983609245124417\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [81][10/14]Time: 0.025 (0.043) Data: 0.000 (0.012) Loss: 0.4065 (0.3645)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 82\n",
      "ResNet\n",
      "Epoch: [82][0/14]Time: 0.038 (0.038) Data: 0.001 (0.001) Loss: 0.3042 (0.3042)\n",
      "error:  0.0033509584058988295 step  61\n",
      "cost:  0.32369010745748616\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [82][10/14]Time: 0.025 (0.050) Data: 0.000 (0.014) Loss: 0.3769 (0.3544)\n",
      "10-NN,s=0.1: TOP1:  91.76666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 83\n",
      "ResNet\n",
      "Epoch: [83][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3288 (0.3288)\n",
      "error:  0.00405587700663812 step  61\n",
      "cost:  0.29033472617223255\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [83][10/14]Time: 0.029 (0.042) Data: 0.000 (0.011) Loss: 0.3735 (0.3491)\n",
      "10-NN,s=0.1: TOP1:  91.86666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 84\n",
      "ResNet\n",
      "Epoch: [84][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2845 (0.2845)\n",
      "error:  0.007732052720158311 step  51\n",
      "cost:  0.2942360254069462\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [84][10/14]Time: 0.033 (0.042) Data: 0.000 (0.012) Loss: 0.4168 (0.3386)\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 85\n",
      "ResNet\n",
      "Epoch: [85][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3187 (0.3187)\n",
      "error:  0.0024138174868042483 step  61\n",
      "cost:  0.3016156456792702\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [85][10/14]Time: 0.045 (0.044) Data: 0.000 (0.012) Loss: 0.3981 (0.3528)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 86\n",
      "ResNet\n",
      "Epoch: [86][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3245 (0.3245)\n",
      "error:  0.0035069255661404064 step  61\n",
      "cost:  0.3121411058765643\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [86][10/14]Time: 0.033 (0.040) Data: 0.000 (0.011) Loss: 0.4075 (0.3450)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 87\n",
      "ResNet\n",
      "Epoch: [87][0/14]Time: 0.036 (0.036) Data: 0.001 (0.001) Loss: 0.3160 (0.3160)\n",
      "error:  0.0025063317611976332 step  51\n",
      "cost:  0.29048622941503754\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [87][10/14]Time: 0.047 (0.046) Data: 0.000 (0.011) Loss: 0.3942 (0.3418)\n",
      "10-NN,s=0.1: TOP1:  91.73333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 88\n",
      "ResNet\n",
      "Epoch: [88][0/14]Time: 0.031 (0.031) Data: 0.000 (0.000) Loss: 0.3383 (0.3383)\n",
      "error:  0.0012663762625821917 step  51\n",
      "cost:  0.30474111279574145\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [88][10/14]Time: 0.038 (0.042) Data: 0.000 (0.010) Loss: 0.3953 (0.3551)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 89\n",
      "ResNet\n",
      "Epoch: [89][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3546 (0.3546)\n",
      "error:  0.0031124939662207085 step  51\n",
      "cost:  0.3094182988574457\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [89][10/14]Time: 0.038 (0.041) Data: 0.000 (0.012) Loss: 0.3767 (0.3415)\n",
      "10-NN,s=0.1: TOP1:  91.83333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 90\n",
      "ResNet\n",
      "Epoch: [90][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3138 (0.3138)\n",
      "error:  0.007459037910644728 step  51\n",
      "cost:  0.2784494464103334\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [90][10/14]Time: 0.031 (0.047) Data: 0.000 (0.016) Loss: 0.3819 (0.3333)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 91\n",
      "ResNet\n",
      "Epoch: [91][0/14]Time: 0.028 (0.028) Data: 0.000 (0.000) Loss: 0.2871 (0.2871)\n",
      "error:  0.008584721264597417 step  61\n",
      "cost:  0.2901140215087657\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [91][10/14]Time: 0.034 (0.050) Data: 0.000 (0.013) Loss: 0.3665 (0.3326)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 92\n",
      "ResNet\n",
      "Epoch: [92][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3283 (0.3283)\n",
      "error:  0.0018591420826327143 step  61\n",
      "cost:  0.3020888233729993\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [92][10/14]Time: 0.039 (0.046) Data: 0.000 (0.012) Loss: 0.3859 (0.3387)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 93\n",
      "ResNet\n",
      "Epoch: [93][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.2800 (0.2800)\n",
      "error:  0.0027752626229492483 step  61\n",
      "cost:  0.29185391143251543\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [93][10/14]Time: 0.034 (0.045) Data: 0.000 (0.011) Loss: 0.3859 (0.3286)\n",
      "10-NN,s=0.1: TOP1:  91.76666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 94\n",
      "ResNet\n",
      "Epoch: [94][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3305 (0.3305)\n",
      "error:  0.006902380815075881 step  51\n",
      "cost:  0.3227885438024897\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [94][10/14]Time: 0.033 (0.037) Data: 0.000 (0.010) Loss: 0.4237 (0.3437)\n",
      "10-NN,s=0.1: TOP1:  91.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 95\n",
      "ResNet\n",
      "Epoch: [95][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2843 (0.2843)\n",
      "error:  0.009926733898746765 step  51\n",
      "cost:  0.28878237350417046\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [95][10/14]Time: 0.034 (0.043) Data: 0.000 (0.013) Loss: 0.4095 (0.3368)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 96\n",
      "ResNet\n",
      "Epoch: [96][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2784 (0.2784)\n",
      "error:  0.005541087841721581 step  51\n",
      "cost:  0.30238408557554364\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [96][10/14]Time: 0.036 (0.041) Data: 0.000 (0.010) Loss: 0.3714 (0.3219)\n",
      "10-NN,s=0.1: TOP1:  91.93333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 97\n",
      "ResNet\n",
      "Epoch: [97][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3092 (0.3092)\n",
      "error:  0.0012512405410243232 step  51\n",
      "cost:  0.30856950093746827\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [97][10/14]Time: 0.036 (0.038) Data: 0.000 (0.012) Loss: 0.3951 (0.3246)\n",
      "10-NN,s=0.1: TOP1:  91.93333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 98\n",
      "ResNet\n",
      "Epoch: [98][0/14]Time: 0.029 (0.029) Data: 0.000 (0.000) Loss: 0.3580 (0.3580)\n",
      "error:  0.004533711218784986 step  51\n",
      "cost:  0.3015607918267234\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [98][10/14]Time: 0.035 (0.043) Data: 0.000 (0.012) Loss: 0.3677 (0.3445)\n",
      "10-NN,s=0.1: TOP1:  92.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 99\n",
      "ResNet\n",
      "Epoch: [99][0/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.3031 (0.3031)\n",
      "error:  0.001953545063907658 step  51\n",
      "cost:  0.3168932838209939\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [99][10/14]Time: 0.046 (0.040) Data: 0.000 (0.012) Loss: 0.3700 (0.3366)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 100\n",
      "ResNet\n",
      "Epoch: [100][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3148 (0.3148)\n",
      "error:  0.0067869849517328 step  51\n",
      "cost:  0.29405103357536744\n",
      "opt took 0.00min,   51iters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][10/14]Time: 0.031 (0.036) Data: 0.000 (0.010) Loss: 0.4145 (0.3355)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "Saving..\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  91.23333333333333\n",
      "50-NN,s=0.5: TOP1:  88.33333333333333\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "10-NN,s=0.5: TOP1:  90.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 101\n",
      "ResNet\n",
      "Epoch: [101][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.3028 (0.3028)\n",
      "error:  0.003216293524476388 step  71\n",
      "cost:  0.2752938780967142\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [101][10/14]Time: 0.033 (0.039) Data: 0.000 (0.014) Loss: 0.3635 (0.3236)\n",
      "10-NN,s=0.1: TOP1:  91.76666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 102\n",
      "ResNet\n",
      "Epoch: [102][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.2837 (0.2837)\n",
      "error:  0.009005086695802578 step  61\n",
      "cost:  0.3216443318318398\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [102][10/14]Time: 0.029 (0.036) Data: 0.000 (0.010) Loss: 0.3864 (0.3225)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 103\n",
      "ResNet\n",
      "Epoch: [103][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3164 (0.3164)\n",
      "error:  0.004505013087023668 step  61\n",
      "cost:  0.31233562189623887\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [103][10/14]Time: 0.053 (0.040) Data: 0.000 (0.011) Loss: 0.3839 (0.3222)\n",
      "10-NN,s=0.1: TOP1:  91.83333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 104\n",
      "ResNet\n",
      "Epoch: [104][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2749 (0.2749)\n",
      "error:  0.0014525539454942615 step  61\n",
      "cost:  0.3129310181032928\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [104][10/14]Time: 0.053 (0.041) Data: 0.000 (0.011) Loss: 0.3852 (0.3169)\n",
      "10-NN,s=0.1: TOP1:  91.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 105\n",
      "ResNet\n",
      "Epoch: [105][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2922 (0.2922)\n",
      "error:  0.005380704942511305 step  51\n",
      "cost:  0.3031763181773675\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [105][10/14]Time: 0.030 (0.040) Data: 0.000 (0.011) Loss: 0.4010 (0.3292)\n",
      "10-NN,s=0.1: TOP1:  92.0\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 106\n",
      "ResNet\n",
      "Epoch: [106][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3202 (0.3202)\n",
      "error:  0.00948170096064449 step  51\n",
      "cost:  0.28343867959603725\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [106][10/14]Time: 0.025 (0.035) Data: 0.000 (0.010) Loss: 0.3768 (0.3408)\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 107\n",
      "ResNet\n",
      "Epoch: [107][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3115 (0.3115)\n",
      "error:  0.007532205401391323 step  51\n",
      "cost:  0.3352473264697159\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [107][10/14]Time: 0.038 (0.042) Data: 0.000 (0.012) Loss: 0.3894 (0.3413)\n",
      "10-NN,s=0.1: TOP1:  92.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 108\n",
      "ResNet\n",
      "Epoch: [108][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3000 (0.3000)\n",
      "error:  0.004439199111129999 step  51\n",
      "cost:  0.3124491803352722\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [108][10/14]Time: 0.035 (0.046) Data: 0.000 (0.013) Loss: 0.4119 (0.3332)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 109\n",
      "ResNet\n",
      "Epoch: [109][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3470 (0.3470)\n",
      "error:  0.0021013633164800316 step  51\n",
      "cost:  0.3218457455156056\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [109][10/14]Time: 0.034 (0.036) Data: 0.000 (0.010) Loss: 0.3854 (0.3399)\n",
      "10-NN,s=0.1: TOP1:  91.83333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 110\n",
      "ResNet\n",
      "Epoch: [110][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3152 (0.3152)\n",
      "error:  0.0025532216335646396 step  61\n",
      "cost:  0.28953164514031515\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [110][10/14]Time: 0.035 (0.037) Data: 0.000 (0.010) Loss: 0.3683 (0.3373)\n",
      "10-NN,s=0.1: TOP1:  91.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 111\n",
      "ResNet\n",
      "Epoch: [111][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3193 (0.3193)\n",
      "error:  0.0032443479327318725 step  61\n",
      "cost:  0.31659205037732946\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [111][10/14]Time: 0.188 (0.047) Data: 0.130 (0.012) Loss: 0.3838 (0.3362)\n",
      "10-NN,s=0.1: TOP1:  91.8\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 112\n",
      "ResNet\n",
      "Epoch: [112][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3135 (0.3135)\n",
      "error:  0.002385888496268085 step  61\n",
      "cost:  0.30375764553717793\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [112][10/14]Time: 0.148 (0.036) Data: 0.112 (0.010) Loss: 0.3929 (0.3400)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 113\n",
      "ResNet\n",
      "Epoch: [113][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.3304 (0.3304)\n",
      "error:  0.008645107162239873 step  51\n",
      "cost:  0.3017916286196595\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [113][10/14]Time: 0.171 (0.045) Data: 0.127 (0.012) Loss: 0.3897 (0.3379)\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 114\n",
      "ResNet\n",
      "Epoch: [114][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3281 (0.3281)\n",
      "error:  0.007371303608190494 step  51\n",
      "cost:  0.30618537093034576\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [114][10/14]Time: 0.188 (0.042) Data: 0.151 (0.014) Loss: 0.3708 (0.3250)\n",
      "10-NN,s=0.1: TOP1:  91.86666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 115\n",
      "ResNet\n",
      "Epoch: [115][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2825 (0.2825)\n",
      "error:  0.007031091732650485 step  51\n",
      "cost:  0.3254910186279568\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [115][10/14]Time: 0.162 (0.041) Data: 0.127 (0.012) Loss: 0.4180 (0.3257)\n",
      "10-NN,s=0.1: TOP1:  91.73333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 116\n",
      "ResNet\n",
      "Epoch: [116][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3060 (0.3060)\n",
      "error:  0.005424794827035839 step  61\n",
      "cost:  0.2727913415176429\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [116][10/14]Time: 0.144 (0.038) Data: 0.106 (0.010) Loss: 0.3724 (0.3429)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 117\n",
      "ResNet\n",
      "Epoch: [117][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3252 (0.3252)\n",
      "error:  0.001928031144237785 step  51\n",
      "cost:  0.2878433573328026\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [117][10/14]Time: 0.217 (0.043) Data: 0.176 (0.016) Loss: 0.3903 (0.3338)\n",
      "10-NN,s=0.1: TOP1:  91.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 118\n",
      "ResNet\n",
      "Epoch: [118][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3054 (0.3054)\n",
      "error:  0.006721528424193379 step  51\n",
      "cost:  0.31523419430150545\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [118][10/14]Time: 0.143 (0.041) Data: 0.103 (0.010) Loss: 0.3690 (0.3187)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 119\n",
      "ResNet\n",
      "Epoch: [119][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2892 (0.2892)\n",
      "error:  0.009852001210777672 step  51\n",
      "cost:  0.28300078032078324\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [119][10/14]Time: 0.181 (0.041) Data: 0.132 (0.012) Loss: 0.3730 (0.3126)\n",
      "10-NN,s=0.1: TOP1:  91.96666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 120\n",
      "ResNet\n",
      "Epoch: [120][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3085 (0.3085)\n",
      "error:  0.005374992803555911 step  51\n",
      "cost:  0.2714479988228788\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [120][10/14]Time: 0.149 (0.037) Data: 0.109 (0.010) Loss: 0.4116 (0.3182)\n",
      "10-NN,s=0.1: TOP1:  91.86666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 121\n",
      "ResNet\n",
      "Epoch: [121][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3148 (0.3148)\n",
      "error:  0.0041924179789950555 step  71\n",
      "cost:  0.2684294749738693\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [121][10/14]Time: 0.150 (0.037) Data: 0.113 (0.011) Loss: 0.4025 (0.3233)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 122\n",
      "ResNet\n",
      "Epoch: [122][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3351 (0.3351)\n",
      "error:  0.0024473367730402096 step  61\n",
      "cost:  0.3054630302310575\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [122][10/14]Time: 0.178 (0.051) Data: 0.136 (0.013) Loss: 0.3950 (0.3287)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 123\n",
      "ResNet\n",
      "Epoch: [123][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3051 (0.3051)\n",
      "error:  0.00516603744787314 step  61\n",
      "cost:  0.30727209080367396\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [123][10/14]Time: 0.165 (0.043) Data: 0.125 (0.012) Loss: 0.4176 (0.3236)\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 124\n",
      "ResNet\n",
      "Epoch: [124][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3413 (0.3413)\n",
      "error:  0.006841675892247268 step  51\n",
      "cost:  0.29477540856600676\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [124][10/14]Time: 0.194 (0.041) Data: 0.149 (0.014) Loss: 0.3703 (0.3396)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 125\n",
      "ResNet\n",
      "Epoch: [125][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3185 (0.3185)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.007411465062156175 step  51\n",
      "cost:  0.28770299651677167\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [125][10/14]Time: 0.155 (0.040) Data: 0.119 (0.011) Loss: 0.4349 (0.3365)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 126\n",
      "ResNet\n",
      "Epoch: [126][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2949 (0.2949)\n",
      "error:  0.002998945670608877 step  51\n",
      "cost:  0.30162929021905166\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [126][10/14]Time: 0.150 (0.040) Data: 0.112 (0.011) Loss: 0.3867 (0.3304)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 127\n",
      "ResNet\n",
      "Epoch: [127][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3185 (0.3185)\n",
      "Epoch: [127][10/14]Time: 0.032 (0.029) Data: 0.000 (0.000) Loss: 0.3906 (0.3418)\n",
      "error:  0.00497027377463688 step  51\n",
      "cost:  0.3046205298156236\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.93333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 128\n",
      "ResNet\n",
      "Epoch: [128][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3014 (0.3014)\n",
      "Epoch: [128][10/14]Time: 0.031 (0.029) Data: 0.000 (0.000) Loss: 0.3543 (0.3310)\n",
      "error:  0.003753236296332507 step  51\n",
      "cost:  0.3022172146434764\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.83333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 129\n",
      "ResNet\n",
      "Epoch: [129][0/14]Time: 0.042 (0.042) Data: 0.001 (0.001) Loss: 0.3010 (0.3010)\n",
      "Epoch: [129][10/14]Time: 0.029 (0.035) Data: 0.000 (0.000) Loss: 0.3032 (0.3110)\n",
      "error:  0.0025110305800976063 step  61\n",
      "cost:  0.29655707871960135\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 130\n",
      "ResNet\n",
      "Epoch: [130][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2844 (0.2844)\n",
      "Epoch: [130][10/14]Time: 0.030 (0.030) Data: 0.000 (0.000) Loss: 0.3308 (0.3101)\n",
      "error:  0.0018570569687561544 step  61\n",
      "cost:  0.317891047874794\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 131\n",
      "ResNet\n",
      "Epoch: [131][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2980 (0.2980)\n",
      "Epoch: [131][10/14]Time: 0.029 (0.027) Data: 0.000 (0.000) Loss: 0.3066 (0.3106)\n",
      "error:  0.004336571983857951 step  71\n",
      "cost:  0.2742479680202214\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 132\n",
      "ResNet\n",
      "Epoch: [132][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2917 (0.2917)\n",
      "Epoch: [132][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.3467 (0.3103)\n",
      "error:  0.004549317668281705 step  61\n",
      "cost:  0.3172361231234951\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.8\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 133\n",
      "ResNet\n",
      "Epoch: [133][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.2716 (0.2716)\n",
      "Epoch: [133][10/14]Time: 0.025 (0.026) Data: 0.000 (0.000) Loss: 0.3456 (0.3105)\n",
      "error:  0.009841953713323415 step  51\n",
      "cost:  0.30861334658162864\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 134\n",
      "ResNet\n",
      "Epoch: [134][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3032 (0.3032)\n",
      "Epoch: [134][10/14]Time: 0.033 (0.031) Data: 0.000 (0.000) Loss: 0.3056 (0.3131)\n",
      "error:  0.007069110524332789 step  51\n",
      "cost:  0.28077631402489384\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.06666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 135\n",
      "ResNet\n",
      "Epoch: [135][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.3491 (0.3491)\n",
      "Epoch: [135][10/14]Time: 0.032 (0.032) Data: 0.000 (0.000) Loss: 0.3368 (0.3244)\n",
      "error:  0.0047515881456137166 step  51\n",
      "cost:  0.30222100677425123\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 136\n",
      "ResNet\n",
      "Epoch: [136][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3110 (0.3110)\n",
      "Epoch: [136][10/14]Time: 0.028 (0.028) Data: 0.000 (0.000) Loss: 0.3296 (0.3166)\n",
      "error:  0.002971251705438105 step  51\n",
      "cost:  0.2873650185753052\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 137\n",
      "ResNet\n",
      "Epoch: [137][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2900 (0.2900)\n",
      "Epoch: [137][10/14]Time: 0.025 (0.025) Data: 0.000 (0.000) Loss: 0.3274 (0.3068)\n",
      "error:  0.0046269162993071156 step  51\n",
      "cost:  0.2893288370063526\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 138\n",
      "ResNet\n",
      "Epoch: [138][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2831 (0.2831)\n",
      "Epoch: [138][10/14]Time: 0.032 (0.029) Data: 0.000 (0.000) Loss: 0.3287 (0.3037)\n",
      "error:  0.00633326477843954 step  51\n",
      "cost:  0.297788787322702\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 139\n",
      "ResNet\n",
      "Epoch: [139][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3180 (0.3180)\n",
      "Epoch: [139][10/14]Time: 0.024 (0.024) Data: 0.000 (0.000) Loss: 0.3439 (0.3294)\n",
      "error:  0.004457793560377343 step  61\n",
      "cost:  0.3065171946663428\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 140\n",
      "ResNet\n",
      "Epoch: [140][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3246 (0.3246)\n",
      "Epoch: [140][10/14]Time: 0.030 (0.028) Data: 0.000 (0.000) Loss: 0.3638 (0.3266)\n",
      "error:  0.004834069741860181 step  61\n",
      "cost:  0.3063628879300843\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 141\n",
      "ResNet\n",
      "Epoch: [141][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.2772 (0.2772)\n",
      "Epoch: [141][10/14]Time: 0.028 (0.028) Data: 0.000 (0.000) Loss: 0.3368 (0.3209)\n",
      "error:  0.009822704622490575 step  61\n",
      "cost:  0.2999346798367718\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 142\n",
      "ResNet\n",
      "Epoch: [142][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3284 (0.3284)\n",
      "Epoch: [142][10/14]Time: 0.028 (0.028) Data: 0.000 (0.000) Loss: 0.3284 (0.3109)\n",
      "error:  0.0033192597934927903 step  71\n",
      "cost:  0.2681412382755437\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.76666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 143\n",
      "ResNet\n",
      "Epoch: [143][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2859 (0.2859)\n",
      "Epoch: [143][10/14]Time: 0.025 (0.025) Data: 0.000 (0.000) Loss: 0.3501 (0.3162)\n",
      "error:  0.009797874064289447 step  51\n",
      "cost:  0.3479077148638033\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 144\n",
      "ResNet\n",
      "Epoch: [144][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3189 (0.3189)\n",
      "Epoch: [144][10/14]Time: 0.027 (0.028) Data: 0.000 (0.000) Loss: 0.3063 (0.3218)\n",
      "error:  0.007920488119675828 step  51\n",
      "cost:  0.31118394575786257\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 145\n",
      "ResNet\n",
      "Epoch: [145][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.2916 (0.2916)\n",
      "Epoch: [145][10/14]Time: 0.032 (0.033) Data: 0.000 (0.000) Loss: 0.3161 (0.3146)\n",
      "error:  0.0015164850022869603 step  61\n",
      "cost:  0.31503414280200126\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 146\n",
      "ResNet\n",
      "Epoch: [146][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2935 (0.2935)\n",
      "Epoch: [146][10/14]Time: 0.028 (0.029) Data: 0.000 (0.000) Loss: 0.3393 (0.3266)\n",
      "error:  0.008719872444710286 step  51\n",
      "cost:  0.2996703178902485\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 147\n",
      "ResNet\n",
      "Epoch: [147][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3097 (0.3097)\n",
      "Epoch: [147][10/14]Time: 0.027 (0.028) Data: 0.000 (0.000) Loss: 0.3274 (0.3261)\n",
      "error:  0.0019764939979748375 step  61\n",
      "cost:  0.2987777881166651\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 148\n",
      "ResNet\n",
      "Epoch: [148][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.2927 (0.2927)\n",
      "Epoch: [148][10/14]Time: 0.028 (0.029) Data: 0.000 (0.000) Loss: 0.3293 (0.3264)\n",
      "error:  0.0021514673655441685 step  51\n",
      "cost:  0.2807550720487451\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 149\n",
      "ResNet\n",
      "Epoch: [149][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3367 (0.3367)\n",
      "Epoch: [149][10/14]Time: 0.029 (0.028) Data: 0.000 (0.000) Loss: 0.3216 (0.3406)\n",
      "error:  0.0029306694939410516 step  51\n",
      "cost:  0.29197732368580104\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 150\n",
      "ResNet\n",
      "Epoch: [150][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3319 (0.3319)\n",
      "Epoch: [150][10/14]Time: 0.032 (0.030) Data: 0.000 (0.000) Loss: 0.3703 (0.3461)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.00205480829841842 step  61\n",
      "cost:  0.31182026859410444\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  90.7\n",
      "50-NN,s=0.5: TOP1:  88.3\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "10-NN,s=0.5: TOP1:  90.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 151\n",
      "ResNet\n",
      "Epoch: [151][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3108 (0.3108)\n",
      "Epoch: [151][10/14]Time: 0.025 (0.026) Data: 0.000 (0.000) Loss: 0.3372 (0.3333)\n",
      "error:  0.007477776459692831 step  71\n",
      "cost:  0.29037501755251527\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 152\n",
      "ResNet\n",
      "Epoch: [152][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.2935 (0.2935)\n",
      "Epoch: [152][10/14]Time: 0.025 (0.025) Data: 0.000 (0.000) Loss: 0.3546 (0.3295)\n",
      "error:  0.00441029115443603 step  51\n",
      "cost:  0.28480646550765876\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 153\n",
      "ResNet\n",
      "Epoch: [153][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.3081 (0.3081)\n",
      "Epoch: [153][10/14]Time: 0.027 (0.027) Data: 0.000 (0.000) Loss: 0.3381 (0.3268)\n",
      "error:  0.00914004696280224 step  71\n",
      "cost:  0.29566834857861213\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 154\n",
      "ResNet\n",
      "Epoch: [154][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3241 (0.3241)\n",
      "Epoch: [154][10/14]Time: 0.031 (0.030) Data: 0.000 (0.000) Loss: 0.3496 (0.3298)\n",
      "error:  0.0017582405036798976 step  51\n",
      "cost:  0.2855504871163562\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 155\n",
      "ResNet\n",
      "Epoch: [155][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3028 (0.3028)\n",
      "Epoch: [155][10/14]Time: 0.028 (0.028) Data: 0.000 (0.000) Loss: 0.3094 (0.3158)\n",
      "error:  0.004181094667614738 step  51\n",
      "cost:  0.29450984421549525\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 156\n",
      "ResNet\n",
      "Epoch: [156][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2782 (0.2782)\n",
      "Epoch: [156][10/14]Time: 0.032 (0.030) Data: 0.000 (0.000) Loss: 0.3364 (0.3145)\n",
      "error:  0.0029860169978112028 step  51\n",
      "cost:  0.3000043263652589\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 157\n",
      "ResNet\n",
      "Epoch: [157][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2846 (0.2846)\n",
      "Epoch: [157][10/14]Time: 0.029 (0.031) Data: 0.000 (0.000) Loss: 0.3466 (0.3282)\n",
      "error:  0.005983955404333274 step  51\n",
      "cost:  0.31283465079995443\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 158\n",
      "ResNet\n",
      "Epoch: [158][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3129 (0.3129)\n",
      "Epoch: [158][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.3509 (0.3361)\n",
      "error:  0.0016083761387044593 step  51\n",
      "cost:  0.3066106463826412\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.0\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 159\n",
      "ResNet\n",
      "Epoch: [159][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3206 (0.3206)\n",
      "Epoch: [159][10/14]Time: 0.028 (0.029) Data: 0.000 (0.000) Loss: 0.3289 (0.3319)\n",
      "error:  0.0018890279142609323 step  61\n",
      "cost:  0.29801643923421356\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 160\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [160][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3182 (0.3182)\n",
      "Epoch: [160][10/14]Time: 0.033 (0.031) Data: 0.000 (0.000) Loss: 0.3590 (0.3338)\n",
      "error:  0.005180609196418495 step  51\n",
      "cost:  0.3067392436080323\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.63333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 161\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [161][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3190 (0.3190)\n",
      "Epoch: [161][10/14]Time: 0.024 (0.027) Data: 0.000 (0.000) Loss: 0.3755 (0.3328)\n",
      "error:  0.004493991441707479 step  61\n",
      "cost:  0.3053941845953447\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 162\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [162][0/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.2791 (0.2791)\n",
      "Epoch: [162][10/14]Time: 0.025 (0.025) Data: 0.000 (0.000) Loss: 0.3561 (0.3171)\n",
      "error:  0.0015077284468995034 step  61\n",
      "cost:  0.30547384795449084\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 163\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [163][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2835 (0.2835)\n",
      "Epoch: [163][10/14]Time: 0.029 (0.029) Data: 0.000 (0.000) Loss: 0.3359 (0.3215)\n",
      "error: ng head 3  0.006914975382302568 step  61\n",
      "cost:  0.3036118689125212\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 164\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [164][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3121 (0.3121)\n",
      "Epoch: [164][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.3398 (0.3256)\n",
      "error:  0.0038694432833626946 step  51\n",
      "cost:  0.3216273047258473\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.06666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 165\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [165][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3063 (0.3063)\n",
      "Epoch: [165][10/14]Time: 0.030 (0.027) Data: 0.000 (0.000) Loss: 0.3474 (0.3371)\n",
      "error:  0.0052345773227004955 step  51\n",
      "cost:  0.3182498634005515\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 166\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [166][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3106 (0.3106)\n",
      "Epoch: [166][10/14]Time: 0.029 (0.029) Data: 0.000 (0.000) Loss: 0.3338 (0.3236)\n",
      "error:  0.0032799657127097204 step  51\n",
      "cost:  0.27863545423039066\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 167\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [167][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3087 (0.3087)\n",
      "Epoch: [167][10/14]Time: 0.033 (0.031) Data: 0.000 (0.000) Loss: 0.3235 (0.3238)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 168\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.009044244853927963 step  51\n",
      "cost:  0.28125147033024894\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [168][0/14]Time: 0.179 (0.179) Data: 0.123 (0.123) Loss: 0.2965 (0.2965)\n",
      "Epoch: [168][10/14]Time: 0.029 (0.045) Data: 0.000 (0.012) Loss: 0.3735 (0.3335)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 169\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.0018336438828717716 step  61\n",
      "cost:  0.29510660286508844\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [169][0/14]Time: 0.196 (0.196) Data: 0.158 (0.158) Loss: 0.3684 (0.3684)\n",
      "Epoch: [169][10/14]Time: 0.025 (0.044) Data: 0.000 (0.015) Loss: 0.3330 (0.3394)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 170\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.0018031671694929141 step  61\n",
      "cost:  0.32983753660422893\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [170][0/14]Time: 0.138 (0.138) Data: 0.103 (0.103) Loss: 0.3262 (0.3262)\n",
      "Epoch: [170][10/14]Time: 0.033 (0.045) Data: 0.000 (0.010) Loss: 0.3115 (0.3330)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 171\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.009867462950223782 step  51\n",
      "cost:  0.26249477298444407\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [171][0/14]Time: 0.163 (0.163) Data: 0.122 (0.122) Loss: 0.3265 (0.3265)\n",
      "Epoch: [171][10/14]Time: 0.028 (0.043) Data: 0.000 (0.011) Loss: 0.3184 (0.3204)\n",
      "10-NN,s=0.1: TOP1:  90.93333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 172\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.004199673558480943 step  51\n",
      "cost:  0.27861224205058954\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [172][0/14]Time: 0.166 (0.166) Data: 0.122 (0.122) Loss: 0.2977 (0.2977)\n",
      "Epoch: [172][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.3328 (0.3270)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 173\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.003151753172828675 step  71\n",
      "cost:  0.2850177491609753\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [173][0/14]Time: 0.175 (0.175) Data: 0.137 (0.137) Loss: 0.3421 (0.3421)\n",
      "Epoch: [173][10/14]Time: 0.026 (0.043) Data: 0.000 (0.013) Loss: 0.3531 (0.3365)\n",
      "10-NN,s=0.1: TOP1:  91.06666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 174\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.00844506225594488 step  51\n",
      "cost:  0.27863952075239273\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [174][0/14]Time: 0.149 (0.149) Data: 0.109 (0.109) Loss: 0.3168 (0.3168)\n",
      "Epoch: [174][10/14]Time: 0.026 (0.039) Data: 0.000 (0.010) Loss: 0.3456 (0.3301)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 175\n",
      "ResNet\n",
      "0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.002494882264269749 step  51\n",
      "cost:  0.3012658503987256\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [175][0/14]Time: 0.147 (0.147) Data: 0.107 (0.107) Loss: 0.3173 (0.3173)\n",
      "Epoch: [175][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 0.3430 (0.3146)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 176\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.007733262654044948 step  51\n",
      "cost:  0.3215927834385026\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [176][0/14]Time: 0.163 (0.163) Data: 0.124 (0.124) Loss: 0.2916 (0.2916)\n",
      "Epoch: [176][10/14]Time: 0.025 (0.039) Data: 0.000 (0.012) Loss: 0.3114 (0.3140)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 177\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.002506954764264435 step  61\n",
      "cost:  0.29787617570584607\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [177][0/14]Time: 0.166 (0.166) Data: 0.130 (0.130) Loss: 0.3011 (0.3011)\n",
      "Epoch: [177][10/14]Time: 0.028 (0.042) Data: 0.000 (0.012) Loss: 0.3288 (0.3138)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 178\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.003807610289459862 step  51\n",
      "cost:  0.2950157754996101\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [178][0/14]Time: 0.212 (0.212) Data: 0.163 (0.163) Loss: 0.3186 (0.3186)\n",
      "Epoch: [178][10/14]Time: 0.029 (0.048) Data: 0.000 (0.016) Loss: 0.3330 (0.3234)\n",
      "10-NN,s=0.1: TOP1:  90.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 179\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.0019030809100496482 step  51\n",
      "cost:  0.28365162952502837\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [179][0/14]Time: 0.198 (0.198) Data: 0.146 (0.146) Loss: 0.3018 (0.3018)\n",
      "Epoch: [179][10/14]Time: 0.025 (0.043) Data: 0.000 (0.014) Loss: 0.3534 (0.3160)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 180\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.006346021427949156 step  51\n",
      "cost:  0.3238739196750151\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [180][0/14]Time: 0.145 (0.145) Data: 0.109 (0.109) Loss: 0.3334 (0.3334)\n",
      "Epoch: [180][10/14]Time: 0.025 (0.039) Data: 0.000 (0.010) Loss: 0.3910 (0.3304)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 181\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.0038181250707367553 step  61\n",
      "cost:  0.24981595035073315\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [181][0/14]Time: 0.143 (0.143) Data: 0.108 (0.108) Loss: 0.3495 (0.3495)\n",
      "Epoch: [181][10/14]Time: 0.028 (0.040) Data: 0.000 (0.010) Loss: 0.3665 (0.3511)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 182\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.00398919640582196 step  51\n",
      "cost:  0.2775281154266542\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [182][0/14]Time: 0.170 (0.170) Data: 0.129 (0.129) Loss: 0.3601 (0.3601)\n",
      "Epoch: [182][10/14]Time: 0.033 (0.044) Data: 0.000 (0.012) Loss: 0.3421 (0.3398)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 183\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.006291209395322128 step  51\n",
      "cost:  0.31841151070680634\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [183][0/14]Time: 0.162 (0.162) Data: 0.122 (0.122) Loss: 0.3186 (0.3186)\n",
      "Epoch: [183][10/14]Time: 0.025 (0.041) Data: 0.000 (0.011) Loss: 0.3428 (0.3400)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 184\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.005552968111711354 step  51\n",
      "cost:  0.310591021091959\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [184][0/14]Time: 0.156 (0.156) Data: 0.103 (0.103) Loss: 0.3325 (0.3325)\n",
      "Epoch: [184][10/14]Time: 0.028 (0.040) Data: 0.000 (0.010) Loss: 0.3185 (0.3284)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 185\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.005641835580318499 step  51\n",
      "cost:  0.32688213683748735\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [185][0/14]Time: 0.149 (0.149) Data: 0.111 (0.111) Loss: 0.3497 (0.3497)\n",
      "Epoch: [185][10/14]Time: 0.027 (0.041) Data: 0.000 (0.010) Loss: 0.3887 (0.3346)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 186\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.006207883630594657 step  51\n",
      "cost:  0.32530363710226856\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [186][0/14]Time: 0.178 (0.178) Data: 0.135 (0.135) Loss: 0.2854 (0.2854)\n",
      "Epoch: [186][10/14]Time: 0.030 (0.044) Data: 0.000 (0.013) Loss: 0.3212 (0.3232)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 187\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.005222931245476237 step  51\n",
      "cost:  0.2837382165774601\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [187][0/14]Time: 0.177 (0.177) Data: 0.126 (0.126) Loss: 0.2840 (0.2840)\n",
      "Epoch: [187][10/14]Time: 0.025 (0.042) Data: 0.000 (0.012) Loss: 0.3192 (0.3195)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 188\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.00329030976012723 step  51\n",
      "cost:  0.3077033677244636\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [188][0/14]Time: 0.150 (0.150) Data: 0.110 (0.110) Loss: 0.3143 (0.3143)\n",
      "Epoch: [188][10/14]Time: 0.028 (0.041) Data: 0.000 (0.010) Loss: 0.3287 (0.3251)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 189\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.002213152686088793 step  51\n",
      "cost:  0.307053947460732\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [189][0/14]Time: 0.166 (0.166) Data: 0.120 (0.120) Loss: 0.3161 (0.3161)\n",
      "Epoch: [189][10/14]Time: 0.030 (0.043) Data: 0.000 (0.011) Loss: 0.3427 (0.3280)\n",
      "10-NN,s=0.1: TOP1:  91.7\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 190\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.006106808912409556 step  51\n",
      "cost:  0.295826161804366\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [190][0/14]Time: 0.164 (0.164) Data: 0.120 (0.120) Loss: 0.3344 (0.3344)\n",
      "Epoch: [190][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.3363 (0.3309)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 191\n",
      "ResNet\n",
      "0.003\n",
      "error:  0.00394306238936426 step  61\n",
      "cost:  0.3049905343420696\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [191][0/14]Time: 0.173 (0.173) Data: 0.110 (0.110) Loss: 0.3130 (0.3130)\n",
      "Epoch: [191][10/14]Time: 0.033 (0.047) Data: 0.000 (0.011) Loss: 0.3174 (0.3216)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 192\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [192][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2540 (0.2540)\n",
      "error:  0.00277507150885814 step  61\n",
      "cost:  0.3047006032876139\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [192][10/14]Time: 0.025 (0.042) Data: 0.000 (0.011) Loss: 0.3324 (0.3167)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 193\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [193][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2458 (0.2458)\n",
      "error:  0.005380255750964347 step  61\n",
      "cost:  0.28686697385694176\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [193][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 0.3527 (0.3225)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 194\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [194][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2756 (0.2756)\n",
      "error:  0.006942864105535351 step  51\n",
      "cost:  0.29150793663207003\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [194][10/14]Time: 0.026 (0.038) Data: 0.000 (0.010) Loss: 0.3521 (0.3274)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 195\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [195][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2674 (0.2674)\n",
      "error:  0.0050375493854588616 step  51\n",
      "cost:  0.30016982701925893\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [195][10/14]Time: 0.029 (0.042) Data: 0.000 (0.011) Loss: 0.3314 (0.3377)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 196\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [196][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2580 (0.2580)\n",
      "error:  0.007336957486668183 step  51\n",
      "cost:  0.2950417416437735\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [196][10/14]Time: 0.029 (0.046) Data: 0.000 (0.015) Loss: 0.3843 (0.3319)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 197\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [197][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2454 (0.2454)\n",
      "error:  0.005328024989078695 step  51\n",
      "cost:  0.3080411114620628\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [197][10/14]Time: 0.031 (0.044) Data: 0.000 (0.011) Loss: 0.3686 (0.3334)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 198\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [198][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2642 (0.2642)\n",
      "error:  0.002495013363459364 step  51\n",
      "cost:  0.30967901508894174\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [198][10/14]Time: 0.028 (0.042) Data: 0.000 (0.012) Loss: 0.3759 (0.3473)\n",
      "10-NN,s=0.1: TOP1:  90.96666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 199\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [199][0/14]Time: 0.038 (0.038) Data: 0.002 (0.002) Loss: 0.2916 (0.2916)\n",
      "error:  0.003080156168325021 step  51\n",
      "cost:  0.2950889810441455\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [199][10/14]Time: 0.030 (0.047) Data: 0.000 (0.015) Loss: 0.3982 (0.3715)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 200\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [200][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.3079 (0.3079)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.004904018901487062 step  51\n",
      "cost:  0.31797674414212657\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [200][10/14]Time: 0.030 (0.047) Data: 0.000 (0.013) Loss: 0.4041 (0.3634)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "Saving..\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  90.13333333333334\n",
      "50-NN,s=0.5: TOP1:  87.86666666666666\n",
      "10-NN,s=0.1: TOP1:  90.6\n",
      "10-NN,s=0.5: TOP1:  89.8\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 201\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [201][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.2691 (0.2691)\n",
      "error:  0.0018094229189777877 step  61\n",
      "cost:  0.3029298649519557\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [201][10/14]Time: 0.024 (0.039) Data: 0.000 (0.011) Loss: 0.3868 (0.3499)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 202\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [202][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2698 (0.2698)\n",
      "error:  0.0046750247013612745 step  51\n",
      "cost:  0.3057319560589804\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [202][10/14]Time: 0.028 (0.040) Data: 0.000 (0.010) Loss: 0.3692 (0.3466)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 203\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [203][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.2768 (0.2768)\n",
      "error:  0.009983204401061152 step  61\n",
      "cost:  0.3192084998709308\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [203][10/14]Time: 0.027 (0.044) Data: 0.000 (0.013) Loss: 0.3412 (0.3418)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 204\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [204][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2769 (0.2769)\n",
      "error:  0.0038198019352977397 step  51\n",
      "cost:  0.3003532945665789\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [204][10/14]Time: 0.028 (0.040) Data: 0.000 (0.011) Loss: 0.3385 (0.3362)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 205\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [205][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.2737 (0.2737)\n",
      "error:  0.0040721111271820876 step  51\n",
      "cost:  0.2933430659561852\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [205][10/14]Time: 0.031 (0.045) Data: 0.000 (0.013) Loss: 0.3491 (0.3349)\n",
      "10-NN,s=0.1: TOP1:  91.03333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 206\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [206][0/14]Time: 0.032 (0.032) Data: 0.001 (0.001) Loss: 0.2797 (0.2797)\n",
      "error:  0.00484232536824003 step  51\n",
      "cost:  0.29669778706640254\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [206][10/14]Time: 0.027 (0.049) Data: 0.000 (0.016) Loss: 0.3453 (0.3522)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 207\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [207][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2679 (0.2679)\n",
      "error:  0.008989777660060483 step  51\n",
      "cost:  0.2863075292707379\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [207][10/14]Time: 0.028 (0.045) Data: 0.000 (0.014) Loss: 0.3466 (0.3291)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 208\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [208][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2882 (0.2882)\n",
      "error:  0.005453591660502521 step  51\n",
      "cost:  0.28968701339120817\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [208][10/14]Time: 0.030 (0.045) Data: 0.000 (0.011) Loss: 0.3661 (0.3227)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 209\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [209][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2860 (0.2860)\n",
      "error:  0.006023282251206963 step  51\n",
      "cost:  0.29878289779513395\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [209][10/14]Time: 0.032 (0.042) Data: 0.000 (0.011) Loss: 0.3407 (0.3171)\n",
      "10-NN,s=0.1: TOP1:  90.63333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 210\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [210][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2760 (0.2760)\n",
      "error:  0.0019822036865076997 step  61\n",
      "cost:  0.3075577764957512\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [210][10/14]Time: 0.033 (0.050) Data: 0.000 (0.014) Loss: 0.3322 (0.3297)\n",
      "10-NN,s=0.1: TOP1:  91.0\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 211\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [211][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2416 (0.2416)\n",
      "error:  0.002526143639220879 step  61\n",
      "cost:  0.3054489541246666\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [211][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.3242 (0.3215)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 212\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [212][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2858 (0.2858)\n",
      "error:  0.0024444842623796426 step  61\n",
      "cost:  0.30514477056603045\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [212][10/14]Time: 0.025 (0.048) Data: 0.000 (0.014) Loss: 0.3802 (0.3353)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 213\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [213][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2901 (0.2901)\n",
      "error:  0.0035449818578384695 step  71\n",
      "cost:  0.2905665597773899\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [213][10/14]Time: 0.029 (0.042) Data: 0.000 (0.011) Loss: 0.3667 (0.3253)\n",
      "10-NN,s=0.1: TOP1:  90.9\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 214\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [214][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2777 (0.2777)\n",
      "error:  0.0033396080855142563 step  51\n",
      "cost:  0.28897944061147524\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [214][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.3698 (0.3384)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 215\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [215][0/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.2878 (0.2878)\n",
      "error:  0.0016230620474333435 step  61\n",
      "cost:  0.32069758955355\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [215][10/14]Time: 0.029 (0.048) Data: 0.000 (0.014) Loss: 0.3600 (0.3382)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 216\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [216][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2677 (0.2677)\n",
      "error:  0.004967720793674246 step  51\n",
      "cost:  0.3031764026333528\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [216][10/14]Time: 0.033 (0.045) Data: 0.000 (0.012) Loss: 0.3418 (0.3347)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 217\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [217][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.2630 (0.2630)\n",
      "error:  0.0058132711694485195 step  51\n",
      "cost:  0.3266950528539043\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [217][10/14]Time: 0.025 (0.042) Data: 0.000 (0.012) Loss: 0.3552 (0.3265)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 218\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [218][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2609 (0.2609)\n",
      "error:  0.005294837869148528 step  51\n",
      "cost:  0.318924034302618\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [218][10/14]Time: 0.030 (0.054) Data: 0.000 (0.024) Loss: 0.3638 (0.3296)\n",
      "10-NN,s=0.1: TOP1:  91.0\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 219\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [219][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2804 (0.2804)\n",
      "error:  0.0044030668024431785 step  51\n",
      "cost:  0.348079331482266\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [219][10/14]Time: 0.031 (0.050) Data: 0.000 (0.016) Loss: 0.4316 (0.3513)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 220\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [220][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2989 (0.2989)\n",
      "error:  0.0051356705374477896 step  51\n",
      "cost:  0.3049160134757321\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [220][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 0.3227 (0.3325)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 221\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [221][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.2712 (0.2712)\n",
      "error:  0.002764008899098336 step  61\n",
      "cost:  0.267272975459038\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [221][10/14]Time: 0.028 (0.041) Data: 0.000 (0.010) Loss: 0.3443 (0.3292)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 222\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [222][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.2779 (0.2779)\n",
      "error:  0.007951712746585349 step  51\n",
      "cost:  0.30538483747746364\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [222][10/14]Time: 0.025 (0.041) Data: 0.000 (0.011) Loss: 0.3821 (0.3248)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 223\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [223][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2872 (0.2872)\n",
      "error:  0.006632760708928931 step  61\n",
      "cost:  0.3010512884671296\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [223][10/14]Time: 0.025 (0.043) Data: 0.000 (0.012) Loss: 0.3531 (0.3238)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 224\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [224][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2865 (0.2865)\n",
      "error:  0.007643934476849523 step  51\n",
      "cost:  0.31459786490246633\n",
      "opt took 0.00min,   51iters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [224][10/14]Time: 0.030 (0.039) Data: 0.000 (0.010) Loss: 0.3572 (0.3196)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 225\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [225][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.2405 (0.2405)\n",
      "error:  0.0035753076955579166 step  51\n",
      "cost:  0.2996226808285213\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [225][10/14]Time: 0.026 (0.042) Data: 0.000 (0.011) Loss: 0.3279 (0.3067)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 226\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [226][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2593 (0.2593)\n",
      "error:  0.0048759629591292875 step  51\n",
      "cost:  0.336519994192355\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [226][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 0.3196 (0.3062)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 227\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [227][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2744 (0.2744)\n",
      "error:  0.006222198611916641 step  51\n",
      "cost:  0.28075532368053024\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [227][10/14]Time: 0.026 (0.039) Data: 0.000 (0.011) Loss: 0.3523 (0.3076)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 228\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [228][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2681 (0.2681)\n",
      "error:  0.006621945536727014 step  51\n",
      "cost:  0.3193137314947743\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [228][10/14]Time: 0.031 (0.042) Data: 0.000 (0.010) Loss: 0.3298 (0.3060)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 229\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [229][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2835 (0.2835)\n",
      "error:  0.005825319219824543 step  51\n",
      "cost:  0.31452740903042326\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [229][10/14]Time: 0.028 (0.042) Data: 0.000 (0.012) Loss: 0.3334 (0.3091)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 230\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [230][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.2606 (0.2606)\n",
      "error:  0.007023663509623357 step  51\n",
      "cost:  0.30277981147223865\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [230][10/14]Time: 0.028 (0.047) Data: 0.000 (0.017) Loss: 0.3330 (0.3189)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 231\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [231][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2541 (0.2541)\n",
      "error:  0.00534696509446797 step  61\n",
      "cost:  0.29796214605426474\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [231][10/14]Time: 0.032 (0.048) Data: 0.000 (0.013) Loss: 0.3312 (0.3095)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 232\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [232][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.2690 (0.2690)\n",
      "error:  0.007697046075160863 step  51\n",
      "cost:  0.29048328406697166\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [232][10/14]Time: 0.028 (0.042) Data: 0.000 (0.012) Loss: 0.3719 (0.3109)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 233\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [233][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2734 (0.2734)\n",
      "error:  0.009407512279006158 step  51\n",
      "cost:  0.2902487656974206\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [233][10/14]Time: 0.025 (0.039) Data: 0.000 (0.011) Loss: 0.3475 (0.3195)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 234\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [234][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2624 (0.2624)\n",
      "error:  0.006563113550280275 step  51\n",
      "cost:  0.32857182319808004\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [234][10/14]Time: 0.025 (0.039) Data: 0.000 (0.011) Loss: 0.3278 (0.3286)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 235\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [235][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.2966 (0.2966)\n",
      "error:  0.0019102796660479537 step  51\n",
      "cost:  0.3032192199259533\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [235][10/14]Time: 0.025 (0.039) Data: 0.000 (0.010) Loss: 0.3615 (0.3327)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 236\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [236][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2848 (0.2848)\n",
      "error: ng head 6  0.004354107009725161 step  51\n",
      "cost:  0.3016591374796374\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [236][10/14]Time: 0.032 (0.042) Data: 0.000 (0.012) Loss: 0.3580 (0.3362)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 237\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [237][0/14]Time: 0.031 (0.031) Data: 0.002 (0.002) Loss: 0.2720 (0.2720)\n",
      "error:  0.005775773563218345 step  51\n",
      "cost:  0.31665896516923003\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [237][10/14]Time: 0.033 (0.058) Data: 0.000 (0.024) Loss: 0.3451 (0.3318)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 238\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [238][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3119 (0.3119)\n",
      "error:  0.001868736207531252 step  51\n",
      "cost:  0.3140700982296788\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [238][10/14]Time: 0.029 (0.041) Data: 0.000 (0.010) Loss: 0.3621 (0.3481)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 239\n",
      "ResNet\n",
      "0.003\n",
      "Epoch: [239][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.2565 (0.2565)\n",
      "error:  0.0029129943493699795 step  51\n",
      "cost:  0.2871778151606498\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [239][10/14]Time: 0.024 (0.040) Data: 0.000 (0.011) Loss: 0.3646 (0.3150)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 240\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [240][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.3053 (0.3053)\n",
      "error:  0.005810989426088264 step  51\n",
      "cost:  0.30605582010275884\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [240][10/14]Time: 0.025 (0.040) Data: 0.000 (0.010) Loss: 0.2797 (0.2995)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 241\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [241][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2463 (0.2463)\n",
      "error:  0.004060724663975779 step  61\n",
      "cost:  0.2619479630475597\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [241][10/14]Time: 0.027 (0.039) Data: 0.000 (0.010) Loss: 0.3071 (0.2853)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 242\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [242][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.2655 (0.2655)\n",
      "error:  0.0026632424102756014 step  61\n",
      "cost:  0.27482790341280633\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [242][10/14]Time: 0.026 (0.040) Data: 0.000 (0.010) Loss: 0.3280 (0.3086)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 243\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [243][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3009 (0.3009)\n",
      "error:  0.001898503308232602 step  61\n",
      "cost:  0.27450369904422317\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [243][10/14]Time: 0.024 (0.037) Data: 0.000 (0.010) Loss: 0.3343 (0.3277)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 244\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [244][0/14]Time: 0.035 (0.035) Data: 0.001 (0.001) Loss: 0.2960 (0.2960)\n",
      "error:  0.0023345602027844414 step  61\n",
      "cost:  0.27302192193428915\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [244][10/14]Time: 0.024 (0.040) Data: 0.000 (0.010) Loss: 0.3701 (0.3498)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 245\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [245][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3216 (0.3216)\n",
      "error:  0.008059315537290224 step  51\n",
      "cost:  0.2784477822093847\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [245][10/14]Time: 0.029 (0.039) Data: 0.000 (0.010) Loss: 0.3372 (0.3522)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 246\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [246][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3309 (0.3309)\n",
      "error:  0.0024712884971519467 step  61\n",
      "cost:  0.27870918834029423\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [246][10/14]Time: 0.029 (0.041) Data: 0.000 (0.012) Loss: 0.3754 (0.3763)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 247\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [247][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3743 (0.3743)\n",
      "error:  0.009257390880001881 step  51\n",
      "cost:  0.2833856493867409\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [247][10/14]Time: 0.029 (0.039) Data: 0.000 (0.010) Loss: 0.3952 (0.3872)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 248\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [248][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3676 (0.3676)\n",
      "error:  0.006881870902795906 step  51\n",
      "cost:  0.28731572268920136\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [248][10/14]Time: 0.027 (0.039) Data: 0.000 (0.011) Loss: 0.4036 (0.3951)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 249\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [249][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3927 (0.3927)\n",
      "error:  0.005695443976102665 step  51\n",
      "cost:  0.30556763084752825\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [249][10/14]Time: 0.025 (0.044) Data: 0.000 (0.013) Loss: 0.4111 (0.4123)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 250\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [250][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3923 (0.3923)\n",
      "error:  0.0021228849862532373 step  61\n",
      "cost:  0.2776446334997077\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [250][10/14]Time: 0.027 (0.039) Data: 0.000 (0.011) Loss: 0.4451 (0.3998)\n",
      "10-NN,s=0.1: TOP1:  91.06666666666666\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  90.46666666666667\n",
      "50-NN,s=0.5: TOP1:  87.2\n",
      "10-NN,s=0.1: TOP1:  90.7\n",
      "10-NN,s=0.5: TOP1:  90.06666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 251\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [251][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3570 (0.3570)\n",
      "error:  0.007873651049516983 step  61\n",
      "cost:  0.28001621067312793\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [251][10/14]Time: 0.024 (0.040) Data: 0.000 (0.010) Loss: 0.3812 (0.3866)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 252\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [252][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.3584 (0.3584)\n",
      "error:  0.0070061164288725 step  61\n",
      "cost:  0.28138741851071314\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [252][10/14]Time: 0.027 (0.037) Data: 0.000 (0.010) Loss: 0.3954 (0.3934)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 253\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [253][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3350 (0.3350)\n",
      "error:  0.006173877561906904 step  61\n",
      "cost:  0.2993308122492968\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [253][10/14]Time: 0.025 (0.045) Data: 0.000 (0.013) Loss: 0.4379 (0.3976)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 254\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [254][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3571 (0.3571)\n",
      "error:  0.003763577747935676 step  61\n",
      "cost:  0.28847097635606067\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [254][10/14]Time: 0.030 (0.042) Data: 0.000 (0.011) Loss: 0.3868 (0.3880)\n",
      "10-NN,s=0.1: TOP1:  91.0\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 255\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [255][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3434 (0.3434)\n",
      "error:  0.007867189581744594 step  51\n",
      "cost:  0.29287619328893\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [255][10/14]Time: 0.028 (0.042) Data: 0.000 (0.012) Loss: 0.4377 (0.3823)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 256\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [256][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3899 (0.3899)\n",
      "error:  0.001568087748512359 step  61\n",
      "cost:  0.30387264527400054\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [256][10/14]Time: 0.028 (0.039) Data: 0.000 (0.010) Loss: 0.3827 (0.3793)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 257\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [257][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4055 (0.4055)\n",
      "error:  0.001998476495265633 step  61\n",
      "cost:  0.2955868088687154\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [257][10/14]Time: 0.027 (0.044) Data: 0.000 (0.013) Loss: 0.4100 (0.3826)\n",
      "10-NN,s=0.1: TOP1:  91.06666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 258\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [258][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3752 (0.3752)\n",
      "error:  0.0020085648860668215 step  61\n",
      "cost:  0.2969681101252906\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [258][10/14]Time: 0.028 (0.040) Data: 0.000 (0.011) Loss: 0.3934 (0.3791)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 259\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [259][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3599 (0.3599)\n",
      "error:  0.0017987775281164131 step  61\n",
      "cost:  0.3043792776901206\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [259][10/14]Time: 0.026 (0.046) Data: 0.000 (0.014) Loss: 0.4273 (0.3818)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 260\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [260][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3890 (0.3890)\n",
      "error:  0.009287063165994258 step  51\n",
      "cost:  0.28513131515600404\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [260][10/14]Time: 0.026 (0.039) Data: 0.000 (0.010) Loss: 0.3977 (0.3777)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 261\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [261][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3627 (0.3627)\n",
      "error:  0.0029633150132646335 step  71\n",
      "cost:  0.28825171318724113\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [261][10/14]Time: 0.025 (0.038) Data: 0.000 (0.010) Loss: 0.4051 (0.3842)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 262\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [262][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3747 (0.3747)\n",
      "error:  0.0018335503275171972 step  61\n",
      "cost:  0.28019167828529096\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [262][10/14]Time: 0.033 (0.046) Data: 0.000 (0.014) Loss: 0.3692 (0.3735)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 263\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [263][0/14]Time: 0.031 (0.031) Data: 0.002 (0.002) Loss: 0.3615 (0.3615)\n",
      "error:  0.004182553937411959 step  61\n",
      "cost:  0.28235021326130766\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [263][10/14]Time: 0.029 (0.054) Data: 0.000 (0.022) Loss: 0.4101 (0.3764)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 264\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [264][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3526 (0.3526)\n",
      "error:  0.009480176655288552 step  61\n",
      "cost:  0.28653999861752333\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [264][10/14]Time: 0.029 (0.043) Data: 0.000 (0.012) Loss: 0.3715 (0.3753)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 265\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [265][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.3572 (0.3572)\n",
      "error:  0.0038484717782798494 step  61\n",
      "cost:  0.2946579718433098\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [265][10/14]Time: 0.026 (0.039) Data: 0.000 (0.011) Loss: 0.4043 (0.3764)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 266\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [266][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3957 (0.3957)\n",
      "error:  0.003992345442472067 step  61\n",
      "cost:  0.29177651275744526\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [266][10/14]Time: 0.029 (0.041) Data: 0.000 (0.010) Loss: 0.3856 (0.3766)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 267\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [267][0/14]Time: 0.030 (0.030) Data: 0.002 (0.002) Loss: 0.3940 (0.3940)\n",
      "error:  0.00924529012219899 step  51\n",
      "cost:  0.2880770826343299\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [267][10/14]Time: 0.028 (0.045) Data: 0.000 (0.012) Loss: 0.3708 (0.3810)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 268\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [268][0/14]Time: 0.034 (0.034) Data: 0.002 (0.002) Loss: 0.3722 (0.3722)\n",
      "error:  0.003949325500927636 step  61\n",
      "cost:  0.30467666684612255\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [268][10/14]Time: 0.028 (0.041) Data: 0.000 (0.010) Loss: 0.4118 (0.3766)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 269\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [269][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3878 (0.3878)\n",
      "error:  0.0022990072759782043 step  61\n",
      "cost:  0.2930492500654665\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [269][10/14]Time: 0.036 (0.043) Data: 0.000 (0.010) Loss: 0.4162 (0.3910)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 270\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [270][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3945 (0.3945)\n",
      "error:  0.002240849540613321 step  61\n",
      "cost:  0.2934090909706609\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [270][10/14]Time: 0.028 (0.047) Data: 0.000 (0.013) Loss: 0.3855 (0.3826)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 271\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [271][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3892 (0.3892)\n",
      "error:  0.004762888686739242 step  61\n",
      "cost:  0.26968399974485374\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [271][10/14]Time: 0.029 (0.041) Data: 0.000 (0.012) Loss: 0.4171 (0.3810)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 272\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [272][0/14]Time: 0.033 (0.033) Data: 0.001 (0.001) Loss: 0.3846 (0.3846)\n",
      "error:  0.004127501231825703 step  61\n",
      "cost:  0.27978680391679916\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [272][10/14]Time: 0.031 (0.046) Data: 0.000 (0.013) Loss: 0.4337 (0.3794)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 273\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [273][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3731 (0.3731)\n",
      "error:  0.004501032349469192 step  61\n",
      "cost:  0.28355751188502903\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [273][10/14]Time: 0.025 (0.040) Data: 0.000 (0.011) Loss: 0.3764 (0.3818)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 274\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [274][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3696 (0.3696)\n",
      "error:  0.0019222251995107964 step  61\n",
      "cost:  0.2868969891365834\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [274][10/14]Time: 0.025 (0.040) Data: 0.000 (0.010) Loss: 0.4141 (0.3735)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 275\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [275][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.4060 (0.4060)\n",
      "error:  0.00321702812520519 step  61\n",
      "cost:  0.28847618399067326\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [275][10/14]Time: 0.029 (0.040) Data: 0.000 (0.011) Loss: 0.4389 (0.3750)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 276\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [276][0/14]Time: 0.034 (0.034) Data: 0.001 (0.001) Loss: 0.3775 (0.3775)\n",
      "error:  0.008706576042714409 step  51\n",
      "cost:  0.2858110868061592\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [276][10/14]Time: 0.027 (0.044) Data: 0.000 (0.011) Loss: 0.3867 (0.3740)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 277\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [277][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3434 (0.3434)\n",
      "error:  0.003226988790320351 step  61\n",
      "cost:  0.2948834723806457\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [277][10/14]Time: 0.029 (0.046) Data: 0.000 (0.012) Loss: 0.4216 (0.3741)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 278\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [278][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3353 (0.3353)\n",
      "error:  0.0018385129873438322 step  61\n",
      "cost:  0.28633022728476837\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [278][10/14]Time: 0.029 (0.043) Data: 0.000 (0.013) Loss: 0.4213 (0.3666)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 279\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [279][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4006 (0.4006)\n",
      "error:  0.0028044239675129035 step  61\n",
      "cost:  0.29814274168017013\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [279][10/14]Time: 0.026 (0.051) Data: 0.000 (0.018) Loss: 0.4108 (0.3767)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 280\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [280][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3680 (0.3680)\n",
      "error:  0.003297217947774045 step  61\n",
      "cost:  0.2919429830479542\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [280][10/14]Time: 0.030 (0.050) Data: 0.000 (0.021) Loss: 0.4177 (0.3769)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 281\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [281][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3710 (0.3710)\n",
      "error:  0.0034180591282410022 step  61\n",
      "cost:  0.27714600133960066\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [281][10/14]Time: 0.027 (0.041) Data: 0.000 (0.011) Loss: 0.4341 (0.3728)\n",
      "10-NN,s=0.1: TOP1:  91.66666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 282\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [282][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3701 (0.3701)\n",
      "error:  0.007763756785716391 step  61\n",
      "cost:  0.28501515885576933\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [282][10/14]Time: 0.027 (0.040) Data: 0.000 (0.010) Loss: 0.4012 (0.3743)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 283\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [283][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3687 (0.3687)\n",
      "error:  0.0031953125305583807 step  61\n",
      "cost:  0.2880127679448015\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [283][10/14]Time: 0.036 (0.041) Data: 0.000 (0.011) Loss: 0.3857 (0.3783)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 284\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [284][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3621 (0.3621)\n",
      "error:  0.0014103305850680092 step  61\n",
      "cost:  0.2893860952873343\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [284][10/14]Time: 0.029 (0.047) Data: 0.000 (0.013) Loss: 0.4070 (0.3791)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 285\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [285][0/14]Time: 0.044 (0.044) Data: 0.002 (0.002) Loss: 0.3701 (0.3701)\n",
      "error:  0.0038201897064329415 step  61\n",
      "cost:  0.2826408041446105\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [285][10/14]Time: 0.025 (0.043) Data: 0.000 (0.010) Loss: 0.3540 (0.3722)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 286\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [286][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3665 (0.3665)\n",
      "error:  0.0019022283276253216 step  61\n",
      "cost:  0.3042743525506686\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [286][10/14]Time: 0.030 (0.047) Data: 0.000 (0.018) Loss: 0.3796 (0.3575)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 287\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [287][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3484 (0.3484)\n",
      "error:  0.009622960479461207 step  51\n",
      "cost:  0.29076239352515204\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [287][10/14]Time: 0.030 (0.046) Data: 0.000 (0.014) Loss: 0.3781 (0.3504)\n",
      "10-NN,s=0.1: TOP1:  91.53333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 288\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [288][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3535 (0.3535)\n",
      "error:  0.0014938616436284136 step  61\n",
      "cost:  0.2887970236888093\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [288][10/14]Time: 0.037 (0.041) Data: 0.000 (0.012) Loss: 0.4105 (0.3517)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 289\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [289][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3426 (0.3426)\n",
      "error:  0.0041474111437567185 step  61\n",
      "cost:  0.2814777680883524\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [289][10/14]Time: 0.046 (0.048) Data: 0.000 (0.017) Loss: 0.3673 (0.3466)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 290\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [290][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3335 (0.3335)\n",
      "error:  0.0015331962547875388 step  61\n",
      "cost:  0.29444236281431485\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [290][10/14]Time: 0.027 (0.045) Data: 0.000 (0.013) Loss: 0.3541 (0.3479)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 291\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [291][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3519 (0.3519)\n",
      "error:  0.003075545890044329 step  71\n",
      "cost:  0.2809288905080465\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [291][10/14]Time: 0.043 (0.042) Data: 0.000 (0.011) Loss: 0.3834 (0.3530)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 292\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [292][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3545 (0.3545)\n",
      "error:  0.006453879424405562 step  61\n",
      "cost:  0.278717652186742\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [292][10/14]Time: 0.041 (0.044) Data: 0.000 (0.014) Loss: 0.3874 (0.3519)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 293\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [293][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3399 (0.3399)\n",
      "error:  0.008915378233879223 step  61\n",
      "cost:  0.28332439214254823\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [293][10/14]Time: 0.039 (0.046) Data: 0.000 (0.016) Loss: 0.3807 (0.3511)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 294\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [294][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3727 (0.3727)\n",
      "error:  0.0016295168036256635 step  61\n",
      "cost:  0.2802058595506751\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [294][10/14]Time: 0.034 (0.051) Data: 0.000 (0.021) Loss: 0.3656 (0.3449)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 295\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [295][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3293 (0.3293)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.0015553165471404728 step  61\n",
      "cost:  0.2850630219527449\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [295][10/14]Time: 0.044 (0.039) Data: 0.000 (0.011) Loss: 0.3974 (0.3485)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 296\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [296][0/14]Time: 0.032 (0.032) Data: 0.001 (0.001) Loss: 0.3540 (0.3540)\n",
      "error:  0.0026644919555683932 step  61\n",
      "cost:  0.28077146166698536\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [296][10/14]Time: 0.039 (0.047) Data: 0.000 (0.014) Loss: 0.3943 (0.3544)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 297\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [297][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3657 (0.3657)\n",
      "error:  0.005641892992788056 step  51\n",
      "cost:  0.28325124266111845\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [297][10/14]Time: 0.033 (0.039) Data: 0.000 (0.011) Loss: 0.3723 (0.3602)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 298\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [298][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4001 (0.4001)\n",
      "error:  0.002219673485696405 step  61\n",
      "cost:  0.2894163916333368\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [298][10/14]Time: 0.036 (0.046) Data: 0.000 (0.012) Loss: 0.3536 (0.3595)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 299\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [299][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3750 (0.3750)\n",
      "error:  0.004871373280429636 step  51\n",
      "cost:  0.2844848606315792\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [299][10/14]Time: 0.035 (0.042) Data: 0.000 (0.011) Loss: 0.3618 (0.3548)\n",
      "10-NN,s=0.1: TOP1:  91.56666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 300\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [300][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3349 (0.3349)\n",
      "error:  0.001405900364237045 step  61\n",
      "cost:  0.28155840195483933\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [300][10/14]Time: 0.038 (0.043) Data: 0.000 (0.012) Loss: 0.3784 (0.3510)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "Saving..\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  90.5\n",
      "50-NN,s=0.5: TOP1:  88.0\n",
      "10-NN,s=0.1: TOP1:  90.8\n",
      "10-NN,s=0.5: TOP1:  89.96666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 301\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [301][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.3276 (0.3276)\n",
      "error:  0.009044718351707393 step  61\n",
      "cost:  0.2750842922748237\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [301][10/14]Time: 0.031 (0.041) Data: 0.000 (0.014) Loss: 0.3564 (0.3439)\n",
      "10-NN,s=0.1: TOP1:  91.5\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 302\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [302][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3469 (0.3469)\n",
      "error:  0.00768345052357744 step  61\n",
      "cost:  0.28292282608656577\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [302][10/14]Time: 0.049 (0.043) Data: 0.001 (0.011) Loss: 0.3919 (0.3418)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 303\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [303][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3198 (0.3198)\n",
      "error:  0.0017346698251735626 step  61\n",
      "cost:  0.2780644570025781\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [303][10/14]Time: 0.059 (0.051) Data: 0.000 (0.017) Loss: 0.3552 (0.3348)\n",
      "10-NN,s=0.1: TOP1:  91.6\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 304\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [304][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3559 (0.3559)\n",
      "error:  0.0019123726137715291 step  61\n",
      "cost:  0.28124238105789906\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [304][10/14]Time: 0.036 (0.039) Data: 0.000 (0.010) Loss: 0.3922 (0.3418)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 305\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [305][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3555 (0.3555)\n",
      "error:  0.003228557266600318 step  61\n",
      "cost:  0.2901602352955041\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [305][10/14]Time: 0.037 (0.040) Data: 0.000 (0.012) Loss: 0.3788 (0.3488)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 306\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [306][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3283 (0.3283)\n",
      "error:  0.0015195527546948417 step  61\n",
      "cost:  0.29211611341504723\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [306][10/14]Time: 0.056 (0.047) Data: 0.000 (0.014) Loss: 0.3521 (0.3362)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 307\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [307][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.3377 (0.3377)\n",
      "error:  0.0042815897239841805 step  61\n",
      "cost:  0.2889991769306021\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [307][10/14]Time: 0.055 (0.051) Data: 0.000 (0.019) Loss: 0.3989 (0.3356)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 308\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [308][0/14]Time: 0.027 (0.027) Data: 0.002 (0.002) Loss: 0.3523 (0.3523)\n",
      "error:  0.008428490888084617 step  51\n",
      "cost:  0.28993744105191743\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [308][10/14]Time: 0.050 (0.040) Data: 0.000 (0.011) Loss: 0.3919 (0.3392)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 309\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [309][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3461 (0.3461)\n",
      "error:  0.0072517703581184145 step  51\n",
      "cost:  0.2872258088768195\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [309][10/14]Time: 0.034 (0.040) Data: 0.000 (0.012) Loss: 0.3605 (0.3383)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 310\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [310][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3452 (0.3452)\n",
      "error:  0.005243046091607417 step  51\n",
      "cost:  0.2643032268827604\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [310][10/14]Time: 0.030 (0.036) Data: 0.000 (0.010) Loss: 0.3891 (0.3453)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 311\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [311][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3530 (0.3530)\n",
      "error:  0.004581802452000683 step  61\n",
      "cost:  0.2729500061832579\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [311][10/14]Time: 0.040 (0.047) Data: 0.000 (0.013) Loss: 0.3915 (0.3449)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 312\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [312][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3614 (0.3614)\n",
      "error:  0.005852355360653427 step  51\n",
      "cost:  0.27902270269582163\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [312][10/14]Time: 0.040 (0.045) Data: 0.000 (0.014) Loss: 0.3738 (0.3397)\n",
      "10-NN,s=0.1: TOP1:  91.03333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 313\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [313][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3112 (0.3112)\n",
      "error:  0.00327431947933543 step  61\n",
      "cost:  0.2693370980047975\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [313][10/14]Time: 0.039 (0.045) Data: 0.000 (0.015) Loss: 0.3861 (0.3373)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 314\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [314][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3084 (0.3084)\n",
      "error:  0.0016369267277471788 step  61\n",
      "cost:  0.27243933420462213\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [314][10/14]Time: 0.035 (0.044) Data: 0.000 (0.013) Loss: 0.3556 (0.3311)\n",
      "10-NN,s=0.1: TOP1:  91.0\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 315\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [315][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.3266 (0.3266)\n",
      "error:  0.009110655385328847 step  51\n",
      "cost:  0.27770438030167344\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [315][10/14]Time: 0.040 (0.049) Data: 0.000 (0.016) Loss: 0.3515 (0.3324)\n",
      "10-NN,s=0.1: TOP1:  91.13333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 316\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [316][0/14]Time: 0.032 (0.032) Data: 0.001 (0.001) Loss: 0.3203 (0.3203)\n",
      "error:  0.008611509270208262 step  51\n",
      "cost:  0.28255554066312816\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [316][10/14]Time: 0.061 (0.051) Data: 0.000 (0.016) Loss: 0.3695 (0.3329)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 317\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [317][0/14]Time: 0.030 (0.030) Data: 0.002 (0.002) Loss: 0.3311 (0.3311)\n",
      "error:  0.0036821290944588636 step  61\n",
      "cost:  0.28543271354792604\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [317][10/14]Time: 0.042 (0.048) Data: 0.000 (0.016) Loss: 0.3942 (0.3364)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 318\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [318][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3916 (0.3916)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.0017660190282490218 step  61\n",
      "cost:  0.27044680062156823\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [318][10/14]Time: 0.143 (0.037) Data: 0.109 (0.010) Loss: 0.3860 (0.3432)\n",
      "10-NN,s=0.1: TOP1:  91.06666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 319\n",
      "ResNet\n",
      "0.00030000000000000003\n",
      "Epoch: [319][0/14]Time: 0.031 (0.031) Data: 0.002 (0.002) Loss: 0.3280 (0.3280)\n",
      "error:  0.008351360773628302 step  51\n",
      "cost:  0.2937300209042977\n",
      "opt took 0.00min,   51iters\n",
      "Epoch: [319][10/14]Time: 0.171 (0.041) Data: 0.125 (0.012) Loss: 0.3635 (0.3438)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 320\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [320][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.3428 (0.3428)\n",
      "error:  0.003423353980988808 step  61\n",
      "cost:  0.2777131657980529\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [320][10/14]Time: 0.153 (0.041) Data: 0.121 (0.011) Loss: 0.3969 (0.3514)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 321\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [321][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.3717 (0.3717)\n",
      "error:  0.0021344546809037857 step  71\n",
      "cost:  0.267903837404544\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [321][10/14]Time: 0.256 (0.049) Data: 0.207 (0.019) Loss: 0.4087 (0.3783)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 322\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [322][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4120 (0.4120)\n",
      "error:  0.003094987155248363 step  61\n",
      "cost:  0.275375665444352\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [322][10/14]Time: 0.213 (0.045) Data: 0.139 (0.013) Loss: 0.4594 (0.4158)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 323\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [323][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4386 (0.4386)\n",
      "error:  0.003392645617780632 step  61\n",
      "cost:  0.2695465185354415\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [323][10/14]Time: 0.260 (0.048) Data: 0.213 (0.020) Loss: 0.4530 (0.4303)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 324\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [324][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4667 (0.4667)\n",
      "error:  0.003152287607796067 step  61\n",
      "cost:  0.2742582630556275\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [324][10/14]Time: 0.163 (0.043) Data: 0.120 (0.011) Loss: 0.4539 (0.4430)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 325\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [325][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4563 (0.4563)\n",
      "error:  0.0038367522343599747 step  61\n",
      "cost:  0.2783429339030004\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [325][10/14]Time: 0.186 (0.045) Data: 0.147 (0.014) Loss: 0.4922 (0.4511)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 326\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [326][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4643 (0.4643)\n",
      "error:  0.00373711907241403 step  71\n",
      "cost:  0.29060506710399725\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [326][10/14]Time: 0.155 (0.038) Data: 0.121 (0.011) Loss: 0.4769 (0.4664)\n",
      "10-NN,s=0.1: TOP1:  91.2\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 327\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [327][0/14]Time: 0.025 (0.025) Data: 0.001 (0.001) Loss: 0.4928 (0.4928)\n",
      "error:  0.007266377114167111 step  71\n",
      "cost:  0.28229178704165286\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [327][10/14]Time: 0.207 (0.041) Data: 0.144 (0.013) Loss: 0.5005 (0.4682)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 328\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [328][0/14]Time: 0.027 (0.027) Data: 0.002 (0.002) Loss: 0.4779 (0.4779)\n",
      "error:  0.0058981128250815695 step  71\n",
      "cost:  0.2841512232193171\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [328][10/14]Time: 0.181 (0.039) Data: 0.135 (0.013) Loss: 0.4665 (0.4745)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 329\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [329][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4775 (0.4775)\n",
      "error:  0.004566473317615949 step  71\n",
      "cost:  0.2827866375997722\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [329][10/14]Time: 0.161 (0.043) Data: 0.123 (0.012) Loss: 0.4832 (0.4751)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 330\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [330][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4539 (0.4539)\n",
      "error:  0.0045660908085285445 step  71\n",
      "cost:  0.2862366707807467\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [330][10/14]Time: 0.177 (0.042) Data: 0.135 (0.013) Loss: 0.5067 (0.4711)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 331\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [331][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.4851 (0.4851)\n",
      "error:  0.0037527506137207123 step  91\n",
      "cost:  0.28106736459749715\n",
      "opt took 0.00min,   91iters\n",
      "Epoch: [331][10/14]Time: 0.179 (0.040) Data: 0.130 (0.012) Loss: 0.5161 (0.4805)\n",
      "10-NN,s=0.1: TOP1:  91.1\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 332\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [332][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4744 (0.4744)\n",
      "error:  0.006309483884100242 step  71\n",
      "cost:  0.27127639664996145\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [332][10/14]Time: 0.226 (0.050) Data: 0.185 (0.017) Loss: 0.4747 (0.4624)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 333\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [333][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4409 (0.4409)\n",
      "error:  0.002948891849487545 step  81\n",
      "cost:  0.27221768917022277\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [333][10/14]Time: 0.153 (0.040) Data: 0.118 (0.011) Loss: 0.5024 (0.4772)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 334\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [334][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.5119 (0.5119)\n",
      "Epoch: [334][10/14]Time: 0.030 (0.032) Data: 0.000 (0.000) Loss: 0.4510 (0.4972)\n",
      "error:  0.00564247764033432 step  61\n",
      "cost:  0.26977102047486595\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 335\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [335][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.5210 (0.5210)\n",
      "Epoch: [335][10/14]Time: 0.025 (0.029) Data: 0.000 (0.000) Loss: 0.4916 (0.4815)\n",
      "error:  0.004322229748607187 step  71\n",
      "cost:  0.27782028462935093\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 336\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [336][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.5063 (0.5063)\n",
      "Epoch: [336][10/14]Time: 0.030 (0.033) Data: 0.000 (0.000) Loss: 0.4594 (0.4859)\n",
      "error:  0.003883352019884545 step  71\n",
      "cost:  0.2757792573717305\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 337\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [337][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4416 (0.4416)\n",
      "Epoch: [337][10/14]Time: 0.030 (0.030) Data: 0.000 (0.000) Loss: 0.4946 (0.4726)\n",
      "error:  0.006608135559429962 step  61\n",
      "cost:  0.2765960000248616\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 338\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [338][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4738 (0.4738)\n",
      "Epoch: [338][10/14]Time: 0.028 (0.028) Data: 0.000 (0.000) Loss: 0.4613 (0.4663)\n",
      "error:  0.00625655793949631 step  61\n",
      "cost:  0.27426293777901184\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 339\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [339][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4503 (0.4503)\n",
      "Epoch: [339][10/14]Time: 0.029 (0.031) Data: 0.000 (0.000) Loss: 0.4555 (0.4627)\n",
      "error:  0.002627970082142772 step  61\n",
      "cost:  0.27683836942009327\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 340\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [340][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.4615 (0.4615)\n",
      "Epoch: [340][10/14]Time: 0.030 (0.029) Data: 0.000 (0.000) Loss: 0.4691 (0.4690)\n",
      "error:  0.007537352692585375 step  71\n",
      "cost:  0.27356141237594056\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 341\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [341][0/14]Time: 0.028 (0.028) Data: 0.001 (0.001) Loss: 0.4523 (0.4523)\n",
      "Epoch: [341][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.4683 (0.4690)\n",
      "error:  0.003438962133872403 step  71\n",
      "cost:  0.2766519807173123\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 342\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [342][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4786 (0.4786)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [342][10/14]Time: 0.024 (0.025) Data: 0.000 (0.000) Loss: 0.4458 (0.4739)\n",
      "error:  0.005871620894301155 step  81\n",
      "cost:  0.27551968809111305\n",
      "opt took 0.00min,   81iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 343\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [343][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4842 (0.4842)\n",
      "Epoch: [343][10/14]Time: 0.033 (0.029) Data: 0.000 (0.000) Loss: 0.4546 (0.4689)\n",
      "error:  0.0069183696383608995 step  91\n",
      "cost:  0.2794524909093491\n",
      "opt took 0.00min,   91iters\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 344\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [344][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4910 (0.4910)\n",
      "Epoch: [344][10/14]Time: 0.034 (0.031) Data: 0.000 (0.000) Loss: 0.4515 (0.4524)\n",
      "error:  0.006310756788409977 step  61\n",
      "cost:  0.2733570136235062\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 345\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [345][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4371 (0.4371)\n",
      "Epoch: [345][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.4748 (0.4566)\n",
      "error:  0.005038473131985466 step  71\n",
      "cost:  0.284243735797981\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 346\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [346][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4976 (0.4976)\n",
      "Epoch: [346][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.4335 (0.4610)\n",
      "error:  0.007342980676132926 step  51\n",
      "cost:  0.27507237216471186\n",
      "opt took 0.00min,   51iters\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 347\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [347][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4498 (0.4498)\n",
      "Epoch: [347][10/14]Time: 0.028 (0.031) Data: 0.000 (0.000) Loss: 0.4677 (0.4619)\n",
      "error:  0.007378402117999561 step  61\n",
      "cost:  0.27979776181503696\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 348\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [348][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4751 (0.4751)\n",
      "Epoch: [348][10/14]Time: 0.032 (0.030) Data: 0.000 (0.000) Loss: 0.4292 (0.4688)\n",
      "error:  0.008026927915978033 step  61\n",
      "cost:  0.2709445203745824\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 349\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [349][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4812 (0.4812)\n",
      "Epoch: [349][10/14]Time: 0.034 (0.033) Data: 0.000 (0.000) Loss: 0.4898 (0.4645)\n",
      "error:  0.008947481072784202 step  71\n",
      "cost:  0.28323280496583275\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 350\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [350][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4777 (0.4777)\n",
      "Epoch: [350][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.4353 (0.4590)\n",
      "error:  0.002525174141328246 step  71\n",
      "cost:  0.27774942892524673\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "doing PCA with 128 components ..done\n",
      "50-NN,s=0.1: TOP1:  90.1\n",
      "50-NN,s=0.5: TOP1:  87.53333333333333\n",
      "10-NN,s=0.1: TOP1:  90.5\n",
      "10-NN,s=0.5: TOP1:  89.73333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 351\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [351][0/14]Time: 0.035 (0.035) Data: 0.001 (0.001) Loss: 0.4926 (0.4926)\n",
      "Epoch: [351][10/14]Time: 0.025 (0.027) Data: 0.000 (0.000) Loss: 0.4607 (0.4766)\n",
      "error:  0.004468416055078306 step  91\n",
      "cost:  0.26911600198212743\n",
      "opt took 0.00min,   91iters\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 352\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [352][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.4923 (0.4923)\n",
      "Epoch: [352][10/14]Time: 0.030 (0.028) Data: 0.000 (0.000) Loss: 0.4409 (0.4711)\n",
      "error:  0.007316015157622813 step  71\n",
      "cost:  0.27120000651759407\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 353\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [353][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4801 (0.4801)\n",
      "Epoch: [353][10/14]Time: 0.026 (0.029) Data: 0.000 (0.000) Loss: 0.4637 (0.4793)\n",
      "error:  0.005399980495328971 step  71\n",
      "cost:  0.2692175249640828\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 354\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [354][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.4490 (0.4490)\n",
      "Epoch: [354][10/14]Time: 0.031 (0.031) Data: 0.000 (0.000) Loss: 0.4372 (0.4666)\n",
      "error:  0.008836028709615973 step  71\n",
      "cost:  0.27446750600589165\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 355\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [355][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4524 (0.4524)\n",
      "Epoch: [355][10/14]Time: 0.034 (0.032) Data: 0.000 (0.000) Loss: 0.4491 (0.4636)\n",
      "error:  0.004575775807118987 step  71\n",
      "cost:  0.27556086008923525\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 356\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [356][0/14]Time: 0.031 (0.031) Data: 0.001 (0.001) Loss: 0.5262 (0.5262)\n",
      "Epoch: [356][10/14]Time: 0.034 (0.032) Data: 0.000 (0.000) Loss: 0.4543 (0.4775)\n",
      "error:  0.004443164447283987 step  61\n",
      "cost:  0.2799449831423429\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 357\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [357][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4627 (0.4627)\n",
      "Epoch: [357][10/14]Time: 0.033 (0.032) Data: 0.000 (0.000) Loss: 0.5267 (0.4644)\n",
      "error:  0.005503505054043734 step  71\n",
      "cost:  0.27304402071573863\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 358\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [358][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.5299 (0.5299)\n",
      "Epoch: [358][10/14]Time: 0.031 (0.031) Data: 0.000 (0.000) Loss: 0.4495 (0.4731)\n",
      "error:  0.0014168850214578699 step  61\n",
      "cost:  0.2791844881831186\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 359\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [359][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.5243 (0.5243)\n",
      "Epoch: [359][10/14]Time: 0.028 (0.029) Data: 0.000 (0.000) Loss: 0.4489 (0.4773)\n",
      "error:  0.003808890131849818 step  81\n",
      "cost:  0.2777911147467329\n",
      "opt took 0.00min,   81iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 360\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [360][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.5032 (0.5032)\n",
      "Epoch: [360][10/14]Time: 0.027 (0.030) Data: 0.000 (0.000) Loss: 0.4484 (0.4776)\n",
      "error:  0.0036353717960067033 step  81\n",
      "cost:  0.2778963329275421\n",
      "opt took 0.00min,   81iters\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 361\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [361][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4367 (0.4367)\n",
      "Epoch: [361][10/14]Time: 0.029 (0.030) Data: 0.000 (0.000) Loss: 0.4947 (0.4671)\n",
      "error:  0.007437150746911758 step  71\n",
      "cost:  0.27213906314783487\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 362\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [362][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4539 (0.4539)\n",
      "Epoch: [362][10/14]Time: 0.034 (0.027) Data: 0.000 (0.000) Loss: 0.4712 (0.4610)\n",
      "error:  0.0068160031456970804 step  71\n",
      "cost:  0.26926838650940427\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 363\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [363][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4804 (0.4804)\n",
      "Epoch: [363][10/14]Time: 0.025 (0.025) Data: 0.000 (0.000) Loss: 0.4398 (0.4570)\n",
      "error:  0.005259210909391854 step  61\n",
      "cost:  0.2696855264624007\n",
      "opt took 0.00min,   61iters\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 364\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [364][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4588 (0.4588)\n",
      "Epoch: [364][10/14]Time: 0.026 (0.026) Data: 0.000 (0.000) Loss: 0.4381 (0.4537)\n",
      "error:  0.006195707487268276 step  81\n",
      "cost:  0.2707413639808153\n",
      "opt took 0.00min,   81iters\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 365\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [365][0/14]Time: 0.027 (0.027) Data: 0.001 (0.001) Loss: 0.4599 (0.4599)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [365][10/14]Time: 0.025 (0.026) Data: 0.000 (0.000) Loss: 0.4421 (0.4510)\n",
      "error:  0.005347178979924316 step  71\n",
      "cost:  0.27208878423752514\n",
      "opt took 0.00min,   71iters\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 366\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [366][0/14]Time: 0.029 (0.029) Data: 0.001 (0.001) Loss: 0.4495 (0.4495)\n",
      "Epoch: [366][10/14]Time: 0.030 (0.028) Data: 0.000 (0.000) Loss: 0.4819 (0.4509)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 367\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0023623632613387624 step  81\n",
      "cost:  0.27774631308983094\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [367][0/14]Time: 0.192 (0.192) Data: 0.151 (0.151) Loss: 0.4199 (0.4199)\n",
      "Epoch: [367][10/14]Time: 0.031 (0.050) Data: 0.000 (0.014) Loss: 0.4950 (0.4580)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 368\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.007793321068916281 step  71\n",
      "cost:  0.2713796938509746\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [368][0/14]Time: 0.220 (0.220) Data: 0.169 (0.169) Loss: 0.4842 (0.4842)\n",
      "Epoch: [368][10/14]Time: 0.033 (0.052) Data: 0.000 (0.017) Loss: 0.4588 (0.4556)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 369\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.002906406287382368 step  61\n",
      "cost:  0.27541429295530595\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [369][0/14]Time: 0.180 (0.180) Data: 0.145 (0.145) Loss: 0.4376 (0.4376)\n",
      "Epoch: [369][10/14]Time: 0.029 (0.044) Data: 0.000 (0.014) Loss: 0.4444 (0.4711)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 370\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0023182489888295965 step  71\n",
      "cost:  0.26919379040963015\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [370][0/14]Time: 0.235 (0.235) Data: 0.187 (0.187) Loss: 0.4635 (0.4635)\n",
      "Epoch: [370][10/14]Time: 0.029 (0.048) Data: 0.000 (0.017) Loss: 0.4954 (0.4658)\n",
      "10-NN,s=0.1: TOP1:  91.16666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 371\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0027669674792081267 step  71\n",
      "cost:  0.265394812429606\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [371][0/14]Time: 0.169 (0.169) Data: 0.127 (0.127) Loss: 0.5237 (0.5237)\n",
      "Epoch: [371][10/14]Time: 0.029 (0.044) Data: 0.000 (0.012) Loss: 0.4562 (0.4836)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 372\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.005398204807301243 step  61\n",
      "cost:  0.26377466442328806\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [372][0/14]Time: 0.198 (0.198) Data: 0.141 (0.141) Loss: 0.4687 (0.4687)\n",
      "Epoch: [372][10/14]Time: 0.026 (0.045) Data: 0.000 (0.014) Loss: 0.4693 (0.4683)\n",
      "10-NN,s=0.1: TOP1:  91.33333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 373\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.002628148266509145 step  71\n",
      "cost:  0.25995205117663406\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [373][0/14]Time: 0.245 (0.245) Data: 0.173 (0.173) Loss: 0.4730 (0.4730)\n",
      "Epoch: [373][10/14]Time: 0.028 (0.050) Data: 0.000 (0.016) Loss: 0.4739 (0.4729)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 374\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0063426703490835346 step  61\n",
      "cost:  0.264262185969316\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [374][0/14]Time: 0.184 (0.184) Data: 0.147 (0.147) Loss: 0.4692 (0.4692)\n",
      "Epoch: [374][10/14]Time: 0.028 (0.050) Data: 0.000 (0.015) Loss: 0.4874 (0.4770)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 375\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0037860808566222426 step  61\n",
      "cost:  0.27013121468450085\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [375][0/14]Time: 0.168 (0.168) Data: 0.125 (0.125) Loss: 0.4281 (0.4281)\n",
      "Epoch: [375][10/14]Time: 0.025 (0.042) Data: 0.000 (0.012) Loss: 0.4604 (0.4629)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 376\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.005623681282424631 step  71\n",
      "cost:  0.2815790998467369\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [376][0/14]Time: 0.148 (0.148) Data: 0.113 (0.113) Loss: 0.4360 (0.4360)\n",
      "Epoch: [376][10/14]Time: 0.028 (0.043) Data: 0.000 (0.011) Loss: 0.4897 (0.4711)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 377\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.005656799666028389 step  91\n",
      "cost:  0.28358366615264397\n",
      "opt took 0.00min,   91iters\n",
      "Epoch: [377][0/14]Time: 0.397 (0.397) Data: 0.364 (0.364) Loss: 0.4855 (0.4855)\n",
      "Epoch: [377][10/14]Time: 0.028 (0.062) Data: 0.000 (0.033) Loss: 0.4660 (0.4660)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 378\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.004574751420557854 step  61\n",
      "cost:  0.2670941627581716\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [378][0/14]Time: 0.158 (0.158) Data: 0.120 (0.120) Loss: 0.4486 (0.4486)\n",
      "Epoch: [378][10/14]Time: 0.024 (0.039) Data: 0.000 (0.011) Loss: 0.4684 (0.4679)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 379\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.00624376899701129 step  81\n",
      "cost:  0.281322771692848\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [379][0/14]Time: 0.167 (0.167) Data: 0.129 (0.129) Loss: 0.4806 (0.4806)\n",
      "Epoch: [379][10/14]Time: 0.028 (0.045) Data: 0.000 (0.012) Loss: 0.4243 (0.4593)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 380\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.006739439845900197 step  81\n",
      "cost:  0.2797124821289143\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [380][0/14]Time: 0.319 (0.319) Data: 0.266 (0.266) Loss: 0.4405 (0.4405)\n",
      "Epoch: [380][10/14]Time: 0.030 (0.059) Data: 0.000 (0.025) Loss: 0.4493 (0.4572)\n",
      "10-NN,s=0.1: TOP1:  91.23333333333333\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 381\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0031677206860933893 step  81\n",
      "cost:  0.26380618070514955\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [381][0/14]Time: 0.285 (0.285) Data: 0.227 (0.227) Loss: 0.5112 (0.5112)\n",
      "Epoch: [381][10/14]Time: 0.032 (0.054) Data: 0.000 (0.021) Loss: 0.4566 (0.4648)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 382\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.006732644539983124 step  71\n",
      "cost:  0.266476634110603\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [382][0/14]Time: 0.189 (0.189) Data: 0.133 (0.133) Loss: 0.4802 (0.4802)\n",
      "Epoch: [382][10/14]Time: 0.030 (0.045) Data: 0.000 (0.014) Loss: 0.4670 (0.4625)\n",
      "10-NN,s=0.1: TOP1:  91.3\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 383\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0031486331802964562 step  81\n",
      "cost:  0.2678301885104119\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [383][0/14]Time: 0.270 (0.270) Data: 0.229 (0.229) Loss: 0.5015 (0.5015)\n",
      "Epoch: [383][10/14]Time: 0.033 (0.053) Data: 0.000 (0.021) Loss: 0.4967 (0.4668)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 384\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.004877960650012891 step  61\n",
      "cost:  0.265689819035708\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [384][0/14]Time: 0.148 (0.148) Data: 0.119 (0.119) Loss: 0.4557 (0.4557)\n",
      "Epoch: [384][10/14]Time: 0.031 (0.041) Data: 0.000 (0.011) Loss: 0.5024 (0.4686)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 385\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.006136151027780312 step  71\n",
      "cost:  0.27292749518323056\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [385][0/14]Time: 0.282 (0.282) Data: 0.225 (0.225) Loss: 0.4548 (0.4548)\n",
      "Epoch: [385][10/14]Time: 0.028 (0.055) Data: 0.000 (0.021) Loss: 0.5082 (0.4735)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 386\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.004037332269582694 step  71\n",
      "cost:  0.27267268071896905\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [386][0/14]Time: 0.168 (0.168) Data: 0.128 (0.128) Loss: 0.4586 (0.4586)\n",
      "Epoch: [386][10/14]Time: 0.024 (0.041) Data: 0.000 (0.012) Loss: 0.5130 (0.4695)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 387\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.002624098733614577 step  81\n",
      "cost:  0.2753422551816391\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [387][0/14]Time: 0.255 (0.255) Data: 0.215 (0.215) Loss: 0.4778 (0.4778)\n",
      "Epoch: [387][10/14]Time: 0.028 (0.051) Data: 0.000 (0.020) Loss: 0.4753 (0.4722)\n",
      "10-NN,s=0.1: TOP1:  91.46666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 388\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.0038829964835093156 step  71\n",
      "cost:  0.2705166808215562\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [388][0/14]Time: 0.182 (0.182) Data: 0.133 (0.133) Loss: 0.4696 (0.4696)\n",
      "Epoch: [388][10/14]Time: 0.026 (0.043) Data: 0.000 (0.013) Loss: 0.4693 (0.4697)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 389\n",
      "ResNet\n",
      "3.0000000000000008e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.0024078123960702413 step  81\n",
      "cost:  0.2732226627849644\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [389][0/14]Time: 0.421 (0.421) Data: 0.366 (0.366) Loss: 0.4816 (0.4816)\n",
      "Epoch: [389][10/14]Time: 0.032 (0.070) Data: 0.000 (0.034) Loss: 0.4417 (0.4596)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 390\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.004654838614108536 step  71\n",
      "cost:  0.26581286031465806\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [390][0/14]Time: 0.202 (0.202) Data: 0.137 (0.137) Loss: 0.4623 (0.4623)\n",
      "Epoch: [390][10/14]Time: 0.024 (0.044) Data: 0.000 (0.013) Loss: 0.4352 (0.4494)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 391\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.004075086013492046 step  81\n",
      "cost:  0.25839084234923426\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [391][0/14]Time: 0.146 (0.146) Data: 0.108 (0.108) Loss: 0.4664 (0.4664)\n",
      "Epoch: [391][10/14]Time: 0.029 (0.042) Data: 0.000 (0.010) Loss: 0.4088 (0.4428)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 392\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.004228244353114641 step  61\n",
      "cost:  0.2618594729738553\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [392][0/14]Time: 0.151 (0.151) Data: 0.112 (0.112) Loss: 0.4901 (0.4901)\n",
      "Epoch: [392][10/14]Time: 0.027 (0.040) Data: 0.000 (0.010) Loss: 0.4393 (0.4482)\n",
      "10-NN,s=0.1: TOP1:  91.43333333333334\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 393\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.003621817924785997 step  81\n",
      "cost:  0.27561572203023726\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [393][0/14]Time: 0.181 (0.181) Data: 0.129 (0.129) Loss: 0.4640 (0.4640)\n",
      "Epoch: [393][10/14]Time: 0.030 (0.046) Data: 0.000 (0.013) Loss: 0.4508 (0.4449)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 394\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.003611921708546628 step  81\n",
      "cost:  0.2795623126861143\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [394][0/14]Time: 0.185 (0.185) Data: 0.130 (0.130) Loss: 0.4520 (0.4520)\n",
      "Epoch: [394][10/14]Time: 0.034 (0.049) Data: 0.000 (0.012) Loss: 0.4427 (0.4383)\n",
      "10-NN,s=0.1: TOP1:  91.4\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 395\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.006195144791397933 step  71\n",
      "cost:  0.2677223576273397\n",
      "opt took 0.00min,   71iters\n",
      "Epoch: [395][0/14]Time: 0.162 (0.162) Data: 0.125 (0.125) Loss: 0.4748 (0.4748)\n",
      "Epoch: [395][10/14]Time: 0.029 (0.042) Data: 0.000 (0.012) Loss: 0.4202 (0.4410)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 396\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.003036039981905825 step  81\n",
      "cost:  0.271357848112687\n",
      "opt took 0.00min,   81iters\n",
      "Epoch: [396][0/14]Time: 0.152 (0.152) Data: 0.114 (0.114) Loss: 0.4456 (0.4456)\n",
      "Epoch: [396][10/14]Time: 0.026 (0.041) Data: 0.000 (0.011) Loss: 0.3809 (0.4355)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 397\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "error:  0.00935872374431368 step  61\n",
      "cost:  0.2734753000705392\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [397][0/14]Time: 0.149 (0.149) Data: 0.110 (0.110) Loss: 0.4514 (0.4514)\n",
      "Epoch: [397][10/14]Time: 0.042 (0.054) Data: 0.000 (0.011) Loss: 0.4268 (0.4480)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 398\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [398][0/14]Time: 0.030 (0.030) Data: 0.001 (0.001) Loss: 0.4513 (0.4513)\n",
      "error:  0.006375518469912689 step  61\n",
      "cost:  0.26394988625676974\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [398][10/14]Time: 0.030 (0.043) Data: 0.000 (0.012) Loss: 0.4312 (0.4425)\n",
      "10-NN,s=0.1: TOP1:  91.36666666666666\n",
      "best accuracy: 92.33\n",
      "\n",
      "Epoch: 399\n",
      "ResNet\n",
      "3.0000000000000008e-05\n",
      "Epoch: [399][0/14]Time: 0.026 (0.026) Data: 0.001 (0.001) Loss: 0.3986 (0.3986)\n",
      "error:  0.003969499745313021 step  61\n",
      "cost:  0.2697891690653402\n",
      "opt took 0.00min,   61iters\n",
      "Epoch: [399][10/14]Time: 0.028 (0.043) Data: 0.000 (0.014) Loss: 0.4458 (0.4429)\n",
      "10-NN,s=0.1: TOP1:  91.26666666666667\n",
      "best accuracy: 92.33\n",
      "doing PCA with 128 components ..done\n",
      "10-NN,s=0.1: TOP1:  92.03333333333333\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    selflabels = train(epoch, selflabels)\n",
    "    feature_return_switch(model, True)\n",
    "    \n",
    "    acc = my_kNN(model, K=10, sigma=0.1, dim=knn_dim)\n",
    "    feature_return_switch(model, False)\n",
    "#     writer.add_scalar(\"accuracy kNN\", acc, epoch)\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'opt': optimizer.state_dict(),\n",
    "            'L': selflabels,\n",
    "        }\n",
    "        if not os.path.isdir(exp):\n",
    "            os.mkdir(exp)\n",
    "        torch.save(state, '%s/best_ckpt.t7' % (exp))\n",
    "        best_acc = acc\n",
    "    if epoch % 100 == 0:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'opt': optimizer.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'L': selflabels,\n",
    "        }\n",
    "        if not os.path.isdir(exp):\n",
    "            os.mkdir(exp)\n",
    "        torch.save(state, '%s/ep%s.t7' % (exp, epoch))\n",
    "    if epoch % 50 == 0:\n",
    "        feature_return_switch(model, True)\n",
    "        acc = my_kNN(model, K=[50, 10], sigma=[0.1, 0.5], dim=knn_dim, use_pca=True)\n",
    "        i = 0\n",
    "#         for num_nn in [50, 10]:\n",
    "#             for sig in [0.1, 0.5]:\n",
    "#                 writer.add_scalar('knn%s-%s' % (num_nn, sig), acc[i], epoch)\n",
    "#                 i += 1\n",
    "        feature_return_switch(model, False)\n",
    "    print('best accuracy: {:.2f}'.format(best_acc * 100))\n",
    "end = time.time()\n",
    "\n",
    "checkpoint = torch.load('%s'%exp+'/best_ckpt.t7' )\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "feature_return_switch(model, True)\n",
    "acc = my_kNN(model, K=10, sigma=0.1, dim=knn_dim, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.9845130443573\n"
     ]
    }
   ],
   "source": [
    "print (end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
