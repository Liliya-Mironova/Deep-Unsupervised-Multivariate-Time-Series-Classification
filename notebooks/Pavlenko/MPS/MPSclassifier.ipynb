{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  7 12:00:49 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "|  0%   37C    P8     8W / 250W |  10325MiB / 11177MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "|  0%   44C    P2   162W / 250W |   7192MiB / 11178MiB |     70%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "|  0%   37C    P8    10W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "|  0%   40C    P8     9W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     17411      C   /opt/conda/bin/python                        643MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "chi = 10 # MPS bond dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /files/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8e1f5ea159463781caf451a6ed4261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /files/MNIST/raw/train-images-idx3-ubyte.gz to /files/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /files/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ecdb9cd9224ba38e727f81dc396f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /files/MNIST/raw/train-labels-idx1-ubyte.gz to /files/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /files/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5df4245775d44cb8a26698f37824409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /files/MNIST/raw/t10k-images-idx3-ubyte.gz to /files/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28147ce6874f4939b659ce6c2a656352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /files/MNIST/raw/t10k-labels-idx1-ubyte.gz to /files/MNIST/raw\n",
      "Processing...\n",
      "\n",
      "\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.MNIST('/files/', download=True, train=True, transform=transforms.ToTensor())\n",
    "valset = datasets.MNIST('/files/', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val dataloaders have 938 and 157 batches\n"
     ]
    }
   ],
   "source": [
    "trainset.data = trainset.data.view(-1, 784)\n",
    "valset.data = valset.data.view(-1, 784)\n",
    "\n",
    "XX = trainset.data/255.\n",
    "X = torch.zeros(XX.size()[0], XX.size()[1], 2)\n",
    "X[:, :, 0] = XX\n",
    "X[:, :, 1] = 1 - XX\n",
    "y = trainset.targets\n",
    "tensor_trainset = torch.utils.data.TensorDataset(X, y)\n",
    "\n",
    "XX = valset.data/255.\n",
    "X = torch.zeros(XX.size()[0], XX.size()[1], 2)\n",
    "X[:, :, 0] = XX\n",
    "X[:, :, 1] = 1 - XX\n",
    "y = valset.targets\n",
    "tensor_valset = torch.utils.data.TensorDataset(X, y)\n",
    "\n",
    "num_workers = 3\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    tensor_trainset, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=True, pin_memory=True)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    tensor_valset, batch_size=batch_size,\n",
    "    num_workers=num_workers, shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"Train/val dataloaders have {len(train_dataloader)} and {len(val_dataloader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784, 2])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(val_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index - 1][:, 1].numpy().squeeze().reshape(28, 28), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_learning_rate(optimizer, new_learning_rate):\n",
    "    \"\"\"Set learning rates of the optimizer to `new_learning_rate`.\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_learning_rate\n",
    "        \n",
    "def validate(model, dataloader):\n",
    "    \"\"\"Compute accuracy on the `dataloader` dataset.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            labels = labels.to(DEVICE)\n",
    "            probabilities = model(images.to(DEVICE))\n",
    "            predictions = probabilities.max(1)[1]\n",
    "\n",
    "            total += len(labels)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sites = 784\n",
    "torch.manual_seed(0)\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "images, labels= images.to(DEVICE), labels.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPS without isometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPSLayer(torch.nn.Module):\n",
    "  def __init__(self, n_sites, chi, n_output):\n",
    "    super(MPSLayer, self).__init__()\n",
    "    if n_sites % 2:\n",
    "      raise NotImplementedError(\"Number of sites should be even but is \"\n",
    "                                  \"{}.\".format(n_sites))\n",
    "    self.n_half = n_sites // 2\n",
    "    self.left = nn.Parameter(self._initializer(self.n_half, 2, chi))\n",
    "    self.right = nn.Parameter(self._initializer(self.n_half, 2, chi))\n",
    "    self.middle = nn.Parameter(self._initializer(n_output, 1, chi)[0])\n",
    "\n",
    "  @staticmethod\n",
    "  def _initializer(n_sites, d_phys, chi):\n",
    "    w = torch.stack(d_phys * n_sites * (torch.eye(chi),))\n",
    "    w = w.view(d_phys, n_sites, chi, chi)\n",
    "    return w + torch.empty(d_phys, n_sites, chi, chi).normal_(mean=0,std=1e-2)\n",
    "\n",
    "  @staticmethod\n",
    "  def reduction(tensor):\n",
    "    length = tensor.size()[0]\n",
    "    while length > 1:\n",
    "      half_length = length // 2\n",
    "      nice_length = 2*half_length\n",
    "      leftover = tensor[nice_length:]\n",
    "      tensor = torch.matmul(tensor[0:nice_length:2], tensor[1:nice_length:2])\n",
    "      tensor = torch.cat((tensor, leftover), axis=0)\n",
    "      length = half_length + int(length % 2 == 1)\n",
    "    return tensor[0]  \n",
    "\n",
    "  def forward(self, inputs):\n",
    "    left = torch.einsum(\"slij,bls->lbij\", self.left, inputs[:, :self.n_half])\n",
    "    right = torch.einsum(\"slij,bls->lbij\", self.right, inputs[:, self.n_half:])\n",
    "    left = self.reduction(left)\n",
    "    right = self.reduction(right)\n",
    "    return torch.einsum(\"bij,cjk,bki->bc\", left, self.middle, right)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    MPSLayer(n_sites, chi, n_classes),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_parameters = model.parameters()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainable_parameters, lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch, return accuracy and average loss.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        probabilities = model(images.to(DEVICE))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            labels = labels.to(DEVICE)\n",
    "            predictions = probabilities.max(1)[1]\n",
    "            \n",
    "            total += len(labels)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "        loss_value = criterion(probabilities, labels)\n",
    "        total_loss += loss_value.item() * len(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "    return correct / total, total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 0\n",
    "train_accuracy, val_accuracy, train_loss = float('nan'), float('nan'), float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epochs, training accuracy: nan% (loss nan), validation accuracy: 8.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eb86f0dadc4a4490caaf07deb78c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 1 epochs, training accuracy: 90.94% (loss 0.2983), validation accuracy: 95.78%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f20b8bce4304641b6a97ceaefd44991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 2 epochs, training accuracy: 95.99% (loss 0.1409), validation accuracy: 96.05%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767cee137c9e4fdaa0109b1c8ae1eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 3 epochs, training accuracy: 96.68% (loss 0.1146), validation accuracy: 96.70%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87cc490f1fe421eb3c2e1c42c75e20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 4 epochs, training accuracy: 97.00% (loss 0.1062), validation accuracy: 96.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce515c1a8da4c6da2b19f9856afe7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 5 epochs, training accuracy: 97.26% (loss 0.0981), validation accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    # Compute validation accuracy\n",
    "    val_accuracy = validate(model, val_dataloader)\n",
    "    print(\n",
    "        f\"After {epochs} epochs, training accuracy: {train_accuracy * 100:.2f}%\"\n",
    "        f\" (loss {train_loss:.4f}), validation accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Train for one epoch\n",
    "    train_accuracy, train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    epochs += 1\n",
    "\n",
    "    # Decrease learning rate sometimes\n",
    "    if epochs in (8, 13, 16):\n",
    "        learning_rate /= 10\n",
    "        set_learning_rate(optimizer, learning_rate)\n",
    "        print(f\"Decreasing the learning rate to {learning_rate}\")\n",
    "\n",
    "# Compute final validation accuracy\n",
    "val_accuracy = validate(model, val_dataloader)\n",
    "print(\n",
    "    f\"After {epochs} epochs, training accuracy: {train_accuracy * 100:.2f}%\"\n",
    "    f\" (loss {train_loss:.4f}), validation accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPS with isometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoMPSLayer(torch.nn.Module):\n",
    "  def __init__(self, n_sites, chi, n_output):\n",
    "    super(IsoMPSLayer, self).__init__()\n",
    "    if n_sites % 2:\n",
    "      raise NotImplementedError(\"Number of sites should be even but is \"\n",
    "                                  \"{}.\".format(n_sites))\n",
    "    self.n_half = n_sites // 2\n",
    "    self.left = nn.Parameter(self._initializer(self.n_half, 2, chi))\n",
    "    self.right = nn.Parameter(self._initializer(self.n_half, 2, chi))\n",
    "    self.middle = nn.Parameter(self._initializer(n_output, 1, chi)[0])\n",
    "\n",
    "  @staticmethod\n",
    "  def _initializer(n_sites, d_phys, chi):\n",
    "    w = torch.stack(d_phys * n_sites * (torch.eye(chi),))\n",
    "    w = w.view(d_phys, n_sites, chi, chi)\n",
    "    #return w + torch.empty(d_phys, n_sites, chi, chi).normal_(mean=0,std=1e-2)\n",
    "    w = w.permute(1, 0, 2, 3)\n",
    "    w = w.reshape(n_sites, d_phys*chi, chi)\n",
    "    U, D, V = torch.svd(w)\n",
    "    # Ids = torch.stack(D.shape[0]*(torch.eye(D.shape[1]), ))\n",
    "    # pr = torch.einsum('nij, njk, nlk -> nil', U, Ids, V)\n",
    "    # pr = pr.reshape(n_sites, d_phys, chi, chi)\n",
    "    # pr = pr.permute(1, 0, 2, 3) #+ torch.empty(d_phys, n_sites, chi, chi).normal_(mean=0,std=1e-2)\n",
    "    # return pr\n",
    "    # q, _ = torch.qr(torch.empty(n_sites, d_phys*chi, chi).normal_(mean=0,std=1))\n",
    "    # q = q.reshape(n_sites, d_phys, chi, chi)\n",
    "    # q = q.permute(1, 0, 2, 3)\n",
    "    # return q #+ torch.empty(d_phys, n_sites, chi, chi).normal_(mean=0,std=1e-3)\n",
    "\n",
    "  @staticmethod\n",
    "  def reduction(tensor):\n",
    "    length = tensor.size()[0]\n",
    "    while length > 1:\n",
    "      half_length = length // 2\n",
    "      nice_length = 2*half_length\n",
    "      leftover = tensor[nice_length:]\n",
    "      tensor = torch.matmul(tensor[0:nice_length:2], tensor[1:nice_length:2])\n",
    "      tensor = torch.cat((tensor, leftover), axis=0)\n",
    "      length = half_length + int(length % 2 == 1)\n",
    "    return tensor[0]  \n",
    "\n",
    "  def forward(self, inputs):\n",
    "    left = torch.einsum(\"slij,bls->lbij\", self.left, inputs[:, :self.n_half])\n",
    "    right = torch.einsum(\"slij,bls->lbij\", self.right, inputs[:, self.n_half:])\n",
    "    left = self.reduction(left)\n",
    "    right = self.reduction(right)\n",
    "    return torch.einsum(\"bij,cjk,bki->bc\", left, self.middle, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    IsoMPSLayer(n_sites, chi, n_classes),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_parameters = model.parameters()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainable_parameters, lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch, return accuracy and average loss.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        probabilities = model(images.to(DEVICE))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            labels = labels.to(DEVICE)\n",
    "            predictions = probabilities.max(1)[1]\n",
    "            \n",
    "            total += len(labels)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "\n",
    "        loss_value = criterion(probabilities, labels)\n",
    "        total_loss += loss_value.item() * len(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "          ls = model[0].left.size()\n",
    "          # # test = torch.zeros(ls).to(DEVICE)\n",
    "          # # test[0, :, :, :] = torch.stack(ls[1]*(torch.eye(ls[2]),))\n",
    "          # # test[1, :, :, :] = torch.stack(ls[1]*(torch.eye(ls[2]),))\n",
    "          # model[0].left[0] = torch.mul(model[0].left[0],  torch.stack(ls[1]*(torch.eye(ls[2]),)).to(DEVICE) )\n",
    "          # model[0].left[1] = torch.mul(model[0].left[0],  torch.stack(ls[1]*(torch.eye(ls[2]),)).to(DEVICE) )\n",
    "          # model[0].right[0] = torch.mul(model[0].left[0],  torch.stack(ls[1]*(torch.eye(ls[2]),)).to(DEVICE) )\n",
    "          # #model[0].right[1] = torch.mul(model[0].left[0],  torch.stack(ls[1]*(torch.eye(ls[2]),)).to(DEVICE) )\n",
    "    return correct / total, total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 0\n",
    "train_accuracy, val_accuracy, train_loss = float('nan'), float('nan'), float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 6 epochs, training accuracy: 97.55% (loss 0.0914), validation accuracy: 97.56%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1257b95a904d7084a248a9ed8704b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 7 epochs, training accuracy: 97.68% (loss 0.0817), validation accuracy: 97.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4aaab88c1f5486cb277f4f59ba69aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decreasing the learning rate to 2.9999999999999997e-05\n",
      "After 8 epochs, training accuracy: 97.92% (loss 0.0763), validation accuracy: 97.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9dfd6b5764477fb7b602ce17f4c712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 9 epochs, training accuracy: 99.11% (loss 0.0295), validation accuracy: 98.35%\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    # Compute validation accuracy\n",
    "    val_accuracy = validate(model, val_dataloader)\n",
    "    print(\n",
    "        f\"After {epochs} epochs, training accuracy: {train_accuracy * 100:.2f}%\"\n",
    "        f\" (loss {train_loss:.4f}), validation accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Train for one epoch\n",
    "    train_accuracy, train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    epochs += 1\n",
    "\n",
    "    # Decrease learning rate sometimes\n",
    "    if epochs in (8, 13, 16):\n",
    "        learning_rate /= 10\n",
    "        set_learning_rate(optimizer, learning_rate)\n",
    "        print(f\"Decreasing the learning rate to {learning_rate}\")\n",
    "\n",
    "# Compute final validation accuracy\n",
    "val_accuracy = validate(model, val_dataloader)\n",
    "print(\n",
    "    f\"After {epochs} epochs, training accuracy: {train_accuracy * 100:.2f}%\"\n",
    "    f\" (loss {train_loss:.4f}), validation accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
