{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9RlKLfDFY73G",
    "outputId": "cb5c1f48-082e-4287-8e75-43355123aaf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4hJraDiYdrQ"
   },
   "outputs": [],
   "source": [
    "#!cd drive/My\\ Drive/ML/data && wget http://www.timeseriesclassification.com/Downloads/Archives/Univariate2018_ts.zip && unzip Univariate2018_ts.zip && rm Univariate2018_ts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "SNCbT5QEpqts",
    "outputId": "516884a0-397a-4501-8394-d839f999faed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sktime) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (1.18.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (0.10.2)\n",
      "Requirement already satisfied: scikit-posthocs>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from sktime) (0.6.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->sktime) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->sktime) (2018.9)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.9.0->sktime) (0.5.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from scikit-posthocs>=0.5.0->sktime) (3.2.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from scikit-posthocs>=0.5.0->sktime) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23.0->sktime) (1.12.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-posthocs>=0.5.0->sktime) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-posthocs>=0.5.0->sktime) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-posthocs>=0.5.0->sktime) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->scikit-posthocs>=0.5.0->sktime) (46.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WiOOxzap--_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils import data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JQaSST6p_-t"
   },
   "outputs": [],
   "source": [
    "def preprocessing(data, n , l):\n",
    "  x =np.array(data['val']).reshape(n,l).astype('float32')\n",
    "  scaler = MinMaxScaler()\n",
    "  data_normalized = scaler.fit_transform(x)\n",
    "  return data_normalized\n",
    "\n",
    "def read_dataset(path):\n",
    "  \"\"\"\n",
    "  Represents TS in the format of DataFrame with features: id, time, val\n",
    "  - id corresponts to a particular TS\n",
    "  - time - range from 0 to length of time series\n",
    "  - val - series values\n",
    "  (this format is necessary for tsfresh feature extraction)\n",
    "  \"\"\"\n",
    "  raw_data, target = load_from_tsfile_to_dataframe(path)\n",
    "  target = target.astype(dtype=np.int64)\n",
    "  number_of_series = raw_data.shape[0]\n",
    "  len_of_series = raw_data['dim_0'][0].shape[0]\n",
    "  # print('Number of series = %d, length of series = %d' % (number_of_series, len_of_series))\n",
    "  # print('Number of classes = %d' % len(np.unique(target)))\n",
    "\n",
    "  data = pd.DataFrame(np.zeros((number_of_series * len_of_series, 3)), \n",
    "                      columns=['id', 'time', 'val'])\n",
    "  for series_id in range(number_of_series):\n",
    "    # boarders for rows in data\n",
    "    low = series_id * len_of_series\n",
    "    high = (series_id + 1) * len_of_series\n",
    "    # fill data with values: id, time, val\n",
    "    data['id'][low:high] = series_id * np.ones(len_of_series) \n",
    "    data['time'][low:high] = np.arange(0, len_of_series)\n",
    "    data['val'][low:high] = raw_data['dim_0'][series_id].values\n",
    "  data = preprocessing(data,number_of_series,len_of_series)\n",
    "  return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cuI2uLt2zUDW"
   },
   "outputs": [],
   "source": [
    "!wget  https://conda.anaconda.org/pytorch/linux-64/faiss-gpu-1.5.0-py36_cuda10.0_1.tar.bz2\n",
    "!tar xvjf faiss-gpu-1.5.0-py36_cuda10.0_1.tar.bz2\n",
    "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
    "!pip install mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymJiUecmzYxV"
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwMtTAfovkTP"
   },
   "outputs": [],
   "source": [
    "def visualize(X,centers,y_kmeans, d):\n",
    "    print(centers.shape)\n",
    "    print(centers[0].shape)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "    # plt.scatter(centers[0,:], centers[1,:], c='black', s=200, alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def run_kmeans(x, nmb_clusters):\n",
    "    \"\"\"Runs kmeans on 1 GPU.\n",
    "    Args:\n",
    "        x: data\n",
    "        nmb_clusters (int): number of clusters\n",
    "    Returns:\n",
    "        list: ids of data in each cluster\n",
    "    \"\"\"\n",
    "    n_data, d = x.shape\n",
    "    # faiss implementation of k-means\n",
    "    clus = faiss.Clustering(d, nmb_clusters)\n",
    "\n",
    "    # Change faiss seed at each k-means so that the randomly picked\n",
    "    # initialization centroids do not correspond to the same feature ids\n",
    "    # from an epoch to another.\n",
    "    clus.seed = np.random.randint(1234)\n",
    "\n",
    "    clus.niter = 10\n",
    "    clus.max_points_per_centroid = 100\n",
    "    res = faiss.StandardGpuResources()\n",
    "    flat_config = faiss.GpuIndexFlatConfig()\n",
    "    flat_config.useFloat16 = False\n",
    "    flat_config.device = 0\n",
    "    index = faiss.GpuIndexFlatL2(res, d, flat_config)\n",
    "\n",
    "    # perform the training\n",
    "    clus.train(x, index)\n",
    "    _, I = index.search(x, 1) #ids of the k most similar vectors for each query vector\n",
    "    losses = faiss.vector_to_array(clus.obj)\n",
    "    centers = faiss.vector_to_array(clus.centroids).reshape(-1, d)\n",
    "    # visualize(x,centers,I,d)\n",
    "    losses\n",
    "    return [int(n[0]) for n in I], losses[-1]\n",
    "\n",
    "\n",
    "def preprocess_features(npdata, pca=15):\n",
    "    \"\"\"Preprocess an array of features.\n",
    "    Args:\n",
    "        npdata (np.array N * ndim): features to preprocess\n",
    "        pca (int): dim of output\n",
    "    Returns:\n",
    "        np.array of dim N * pca: data PCA-reduced, whitened and L2-normalized\n",
    "    \"\"\"\n",
    "    _, ndim = npdata.shape\n",
    "    npdata =  npdata.astype('float32')\n",
    "\n",
    "    # Apply PCA-whitening with Faiss\n",
    "    # mat = faiss.PCAMatrix (ndim, pca, eigen_power=-0.5)\n",
    "    # mat.train(npdata)\n",
    "    # assert mat.is_trained\n",
    "    # npdata = mat.apply_py(npdata)\n",
    "\n",
    "    # L2 normalization\n",
    "    row_sums = np.linalg.norm(npdata, axis=1)\n",
    "    npdata = npdata / row_sums[:, np.newaxis]\n",
    "\n",
    "    return npdata\n",
    "\n",
    "def arrange_clustering(ts_lists):\n",
    "    \"\"\"Creates a dataset from clustering, with clusters as labels.\n",
    "    Args:\n",
    "        ts_lists (list of list): for each cluster, the list of time series indexes\n",
    "                                    belonging to this cluster\n",
    "    Returns:\n",
    "        pseudolabels,corresponding to initial data points\n",
    "    \"\"\"\n",
    "    pseudolabels = []\n",
    "    ts_indexes = []\n",
    "    for cluster, ts in enumerate(ts_lists):\n",
    "        ts_indexes.extend(ts)\n",
    "        pseudolabels.extend([cluster] * len(ts))\n",
    "    indexes = np.argsort(ts_indexes)\n",
    "    # print('CHHHHHHEEEEECCCKKK')\n",
    "    # print(pseudolabels)\n",
    "    # print(indexes)\n",
    "    # print(np.asarray(pseudolabels)[indexes])\n",
    "    return np.asarray(pseudolabels)[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cfp5t8UCvo9z"
   },
   "outputs": [],
   "source": [
    "def cluster(data,k):\n",
    "        \"\"\"Performs k-means clustering.\n",
    "            Args:\n",
    "                x_data (np.array N * dim): data to cluster\n",
    "        \"\"\"\n",
    "        xb = preprocess_features(data)\n",
    "\n",
    "        # cluster the data\n",
    "        I, loss = run_kmeans(xb, k) \n",
    "        ts_lists = [[] for i in range(k)]\n",
    "        for i in range(len(data)):\n",
    "            ts_lists[I[i]].append(i)\n",
    "        return loss, ts_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-bxvkFIgzc6"
   },
   "outputs": [],
   "source": [
    "# туц\n",
    "class TS_CNN(nn.Module):\n",
    "    def __init__(self, channels, pools, feature_size, num_classes):\n",
    "        super(TS_CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(channels[0], channels[1], 7),\n",
    "            nn.AvgPool1d(pools[0]),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Conv1d(channels[1], channels[2], 7),\n",
    "            nn.AvgPool1d(pools[1]),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.cnn.apply(weights_init)\n",
    "        self.classifier = nn.Linear(feature_size, num_classes)\n",
    "        self.classifier.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_out = self.cnn(x)\n",
    "        cnn_out = torch.flatten(cnn_out, start_dim=1)\n",
    "        preds = self.classifier(cnn_out)\n",
    "        return cnn_out, preds, F.softmax(preds)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGT5COoqCXw-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# from tqdm import tqdm_notebook, tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aaAI2_yTJbCO"
   },
   "outputs": [],
   "source": [
    "# HOW TO USE:\n",
    "# PASTE\n",
    "#\n",
    "# dict_ts_lists = {label: indices for label, indices in enumerate(ts_lists)}\n",
    "# sampler = UnifLabelSampler(len(np_y), dict_ts_lists)\n",
    "\n",
    "# #### Dataset with new pseudolabels ####\n",
    "# train_ds = data.TensorDataset(torch.from_numpy(np_x).float(), torch.from_numpy(np_y))\n",
    "# trainloader = data.DataLoader(train_ds, batch_size=32, sampler=sampler)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class UnifLabelSampler(Sampler):\n",
    "    \"\"\"Samples elements uniformely accross pseudolabels.\n",
    "        Args:\n",
    "            N (int): size of returned iterator.\n",
    "            ts_lists: dict of key (target), value (list of data with this target)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, ts_lists):\n",
    "        self.N = N\n",
    "        self.ts_lists = ts_lists\n",
    "        self.indexes = self.generate_indexes_epoch()\n",
    "\n",
    "    def generate_indexes_epoch(self):\n",
    "        nmb_non_empty_clusters = 0\n",
    "        for i in range(len(self.ts_lists)):\n",
    "            if len(self.ts_lists[i]) != 0:\n",
    "                nmb_non_empty_clusters += 1\n",
    "\n",
    "        size_per_pseudolabel = int(self.N / nmb_non_empty_clusters) + 1\n",
    "        res = np.array([])\n",
    "\n",
    "        for i in range(len(self.ts_lists)):\n",
    "            # skip empty clusters\n",
    "            if len(self.ts_lists[i]) == 0:\n",
    "                continue\n",
    "            indexes = np.random.choice(\n",
    "                self.ts_lists[i],\n",
    "                size_per_pseudolabel,\n",
    "                replace=(len(self.ts_lists[i]) <= size_per_pseudolabel)\n",
    "            )\n",
    "            res = np.concatenate((res, indexes))\n",
    "\n",
    "        np.random.shuffle(res)\n",
    "        res = list(res.astype('int'))\n",
    "        if len(res) >= self.N:\n",
    "            return res[:self.N]\n",
    "        res += res[: (self.N - len(res))]\n",
    "        return res\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LkNIWr2jjseV"
   },
   "outputs": [],
   "source": [
    "skiplist = [\n",
    "    'AllGestureWiimoteX',\n",
    "    'AllGestureWiimoteY',\n",
    "    'AllGestureWiimoteZ',\n",
    "    'AsphaltObstacles',\n",
    "    'AsphaltObstaclesCoordinates',\n",
    "    'AsphaltPavementType',\n",
    "    'AsphaltPavementTypeCoordinates',\n",
    "    'AsphaltRegularity',\n",
    "    'AsphaltRegularityCoordinates',\n",
    "    'GesturePebbleZ1',\n",
    "    'GesturePebbleZ2',\n",
    "    'PickupGestureWiimoteZ',\n",
    "    'PLAID',\n",
    "    'ShakeGestureWiimoteZ',\n",
    "    'MelbournePedestrian'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "92737dcaad4e4a54919de369501de698",
      "21ef8a0c39ee46bb989b228c00ed11a1",
      "7058deacb42b405e8ceeac304464ca29",
      "0f8df1ac8bdb4baa86f88dd43c6d2722",
      "a1786f8686de4f8ca9f6bc764d255408",
      "2173dc4ffc074caeb9d2495813138d74",
      "9af2ecb27143428ab12d7a8fd4028cb3",
      "6c6d812ade2547d6a00cb2a27565d6b2"
     ]
    },
    "colab_type": "code",
    "id": "f6gWi8vpsuxq",
    "outputId": "9a8c3a6d-d7dc-47c1-8e75-dc6cc132ed1c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92737dcaad4e4a54919de369501de698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mallat\n",
      "1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedicalImages\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meat\n",
      "564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiddlePhalanxOutlineCorrect\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiddlePhalanxOutlineAgeGroup\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiddlePhalanxTW\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MixedShapesRegularTrain\n",
      "1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MixedShapesSmallTrain\n",
      "1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoteStrain\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonInvasiveFetalECGThorax1\n",
      "960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NonInvasiveFetalECGThorax2\n",
      "960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OliveOil\n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSULeaf\n",
      "528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhalangesOutlinesCorrect\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme\n",
      "1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PigAirwayPressure\n",
      "2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PigArtPressure\n",
      "2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PigCVP\n",
      "2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerCons\n",
      "156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane\n",
      "156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProximalPhalanxOutlineAgeGroup\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProximalPhalanxOutlineCorrect\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProximalPhalanxTW\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RefrigerationDevices\n",
      "924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock\n",
      "3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScreenType\n",
      "924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemgHandGenderCh2\n",
      "1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemgHandMovementCh2\n",
      "1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemgHandSubjectCh2\n",
      "1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapeletSim\n",
      "624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapesAll\n",
      "648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallKitchenAppliances\n",
      "924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SonyAIBORobotSurface1\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmoothSubspace\n",
      "-12\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-edf00a389b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdeepcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;31m#train_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-edf00a389b80>\u001b[0m in \u001b[0;36mdeepcluster\u001b[0;34m(np_x, true_y)\u001b[0m\n\u001b[1;32m     20\u001b[0m              \u001b[0mpools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m              \u001b[0mfeature_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m              num_classes=len(np.unique(np_y)))\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# net = TS_CNN(channels=[1, 128, 128, 128],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#              pools=[2, 2, 2],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-1ec897b57e33>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, channels, pools, feature_size, num_classes)\u001b[0m\n\u001b[1;32m     11\u001b[0m         )\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to create tensor with negative dimension -12: [3, -12]"
     ]
    }
   ],
   "source": [
    "#fix random seeds\n",
    "torch.manual_seed(31)\n",
    "torch.cuda.manual_seed_all(31)\n",
    "np.random.seed(31)\n",
    "def deepcluster(np_x,true_y):\n",
    "    np_y=np.copy(true_y)\n",
    "    ################################## Loading Data #########################################\n",
    "    # np_x = np.random.normal(0, 1, (500, 100))\n",
    "    L= np_x.shape[1]\n",
    "    np_x = np.expand_dims(np_x, axis=1)\n",
    "    # np_y = np.random.randint(0, 4, (500,), dtype=np.int64)  #just random labels for the very first iteration of feature extraction\n",
    "    # k = 4\n",
    "    train_ds = data.TensorDataset(torch.from_numpy(np_x).float(), torch.from_numpy(np_y))\n",
    "    trainloader = data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "    ################################## Creating the model ###################################\n",
    "    device =torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    feature_size = ((L - 7 + 1)//3 - 7 + 1)//3*12\n",
    "    print(feature_size)\n",
    "    net = TS_CNN(channels=[1, 6,12],\n",
    "             pools=[3,3],\n",
    "             feature_size=feature_size,\n",
    "             num_classes=len(np.unique(np_y)))\n",
    "    # net = TS_CNN(channels=[1, 128, 128, 128],\n",
    "    #              pools=[2, 2, 2],\n",
    "    #              feature_size=256,\n",
    "    #              num_classes=4)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay= 0.0001)\n",
    "    net.to(device)\n",
    "    k=len(np.unique(np_y))\n",
    "    ################################## Traing loop ##########################################\n",
    "    feature_average = None\n",
    "    for epoch in range(500):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        #### Extracting features for clustering ####\n",
    "        all_features = []\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(trainloader, 0):\n",
    "                inputs, _ = batch\n",
    "                inputs = inputs.to(device)\n",
    "                feats, _, _ = net(inputs)\n",
    "                all_features.append(feats.detach().cpu().numpy())\n",
    "        net.train()\n",
    "        if feature_average is None:\n",
    "            feature_average = np.vstack(all_features)\n",
    "        else:\n",
    "            feature_average = 0.9*feature_average + 0.1 * np.vstack(all_features)\n",
    "        cluster_loss, ts_lists = cluster(feature_average,k)\n",
    "        dict_ts_lists = {label: indices for label, indices in enumerate(ts_lists)}\n",
    "        sampler = UnifLabelSampler(len(np_y), dict_ts_lists)\n",
    " \n",
    "        if epoch % 10==0:\n",
    "            np_y = arrange_clustering(ts_lists)\n",
    "        # np_y = np.random.randint(0, 4, (500,), dtype=np.int64)  #change the random label generation to clustering\n",
    "        # print(train_dataset.shape)\n",
    "        #### Dataset with new pseudolabels ####\n",
    "        train_ds = data.TensorDataset(torch.from_numpy(np_x).float(), torch.from_numpy(np_y))\n",
    "        trainloader = data.DataLoader(train_ds, batch_size=32, sampler=sampler)\n",
    "\n",
    "        #### Regular Forward/Backward passes ####\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "            inputs, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feats, outputs, normalized_preds = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds, preds_sm = net.forward(torch.Tensor(np_x).to(device))\n",
    "\n",
    "    ###Freezing CNN###\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    net.eval()\n",
    "    ds = data.TensorDataset(torch.from_numpy(np_x).float(), torch.from_numpy(np_y))\n",
    "    loader = data.DataLoader(ds, batch_size=32, shuffle=True)\n",
    "    ### Extracting Features with the frozen CNN ###\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader, 0):\n",
    "            inputs, _ = batch\n",
    "            inputs = inputs.to(device)\n",
    "            feats, _, _ = net(inputs)\n",
    "            all_features.append(feats.detach().cpu().numpy())\n",
    "    preextracted_features = np.vstack(all_features)\n",
    "    ### New Classifier ###\n",
    "    \n",
    "    top_classifier  = nn.Linear(feature_size, len(np.unique(true_y)))\n",
    "\n",
    "    top_classifier.apply(weights_init)\n",
    "    top_classifier.to(device)\n",
    "    ds = data.TensorDataset(torch.from_numpy(preextracted_features).float(), torch.from_numpy(true_y.astype(dtype=np.int64)))\n",
    "    loader = data.DataLoader(ds, batch_size=32, shuffle=True)\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(top_classifier.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
    "    ### Finetuning the classifier ###\n",
    "    for epoch in range(500):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(loader, 0):\n",
    "                inputs, labels = batch\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = top_classifier(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                # _, p, p_sm = top_classifier.forward(train_ds)\n",
    "    return net, top_classifier\n",
    "\n",
    "path_to_data = 'drive/My Drive/ML/Univariate_ts'\n",
    "path_to_results='drive/My Drive/ML/predictions_new' #pls create the folder predictions first\n",
    "test_acc = []\n",
    "train_acc = []\n",
    "folders= os.listdir(path_to_data)\n",
    "device =torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "folders\n",
    "for e, folder in tqdm(enumerate(folders)):\n",
    "    if folder in skiplist:\n",
    "        continue\n",
    "    path = path_to_data + '/' + folder\n",
    "    print(folder)\n",
    "    X_train, y_train = read_dataset(path+'/'+folder+'_TRAIN.ts')\n",
    "    X_test, y_test = read_dataset(path+'/'+folder+'_TEST.ts')\n",
    "    #train\n",
    "    x  = X_train\n",
    "    x = np.expand_dims(x, axis=1)\n",
    "    y = y_train.astype(dtype=np.int64)\n",
    "    conv = {label: i for i,label in enumerate(np.unique(y))}\n",
    "    y_new = np.array([conv[a] for a in y]).reshape(y.shape)\n",
    "\n",
    "    net, net2 =deepcluster(X_train,y_new)\n",
    "    #train_acc\n",
    "    net2.eval\n",
    "    train_ds = data.TensorDataset(torch.from_numpy(x).float(), torch.from_numpy(y_new))\n",
    "    train_loader = data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    ### Extracting Features with the frozen CNN ###\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader, 0):\n",
    "            inputs, _ = batch\n",
    "            inputs = inputs.to(device)\n",
    "            feats, _, _ = net(inputs)\n",
    "            all_features.append(feats.detach().cpu().numpy())\n",
    "    preextracted_features = np.vstack(all_features)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      p_sm = net2.forward(torch.from_numpy(preextracted_features).float().to(device))\n",
    "    preds_labels = np.argmax(p_sm.detach().cpu().numpy(), axis=1)\n",
    "    train_acc.append(accuracy_score(y_new, preds_labels))\n",
    "    # pd.DataFrame({'train_preds_sm': list(preds_sm.detach().numpy()}).to_csv(path_to_results+'/train/'+folder+'.csv')\n",
    "    #test\n",
    "    x  = X_test\n",
    "    x = np.expand_dims(x, axis=1)\n",
    "    y = y_test.astype(dtype=np.int64)\n",
    "    conv = {label: i for i,label in enumerate(np.unique(y))}\n",
    "    y_new = np.array([conv[a] for a in y]).reshape(y.shape)\n",
    "    net2.eval\n",
    "    test_ds = data.TensorDataset(torch.from_numpy(x).float(), torch.from_numpy(y_new))\n",
    "    test_loader = data.DataLoader(test_ds, batch_size=32, shuffle=True)\n",
    "    ### Extracting Features with the frozen CNN ###\n",
    "    all_features = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader, 0):\n",
    "            inputs, _ = batch\n",
    "            inputs = inputs.to(device)\n",
    "            feats, _, _ = net(inputs)\n",
    "            all_features.append(feats.detach().cpu().numpy())\n",
    "    preextracted_features = np.vstack(all_features)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      p_sm = net2.forward(torch.from_numpy(preextracted_features).float().to(device))\n",
    "    preds_labels = np.argmax(p_sm.detach().cpu().numpy(), axis=1)\n",
    "    test_acc.append(accuracy_score(y_new, preds_labels))\n",
    "    # pd.DataFrame({'test_preds_sm': list(preds_sm.detach().numpy())}).to_csv(path_to_results+'/test/'+folder+'.csv')\n",
    "\n",
    "    pd.DataFrame({'name': folders[0:e],'train_accuracy': train_acc, 'test_accuracy': test_acc}).to_csv('drive/My Drive/ML/Accuracy_scores'+ str(e) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOk0jLaXRgIi"
   },
   "outputs": [],
   "source": [
    "path_to_data = 'drive/My Drive/ML/Univariate_ts'\n",
    "for paths, folders, dataset in os.walk(path_to_data):\n",
    "    for name in dataset:\n",
    "        if any([w in name for w in skiplist]):\n",
    "            continue \n",
    "        path = paths + '/' + name\n",
    "        print(path)\n",
    "        if 'TRAIN' in name:\n",
    "            X_train, y_train = read_dataset(path)\n",
    "            print(\"\\t Shape of X_train = %s, y_train = %s\" % ( X_train.shape,y_train.shape))\n",
    "        elif 'TEST' in name:\n",
    "            X_test, y_test = read_dataset(path)\n",
    "            print(\"For dataset - %s:\" % (name[:-5]))\n",
    "            print(\"\\t Shape of X_test = %s, y_test = %s\" % (X_test.shape, y_test.shape))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Integration_new (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f8df1ac8bdb4baa86f88dd43c6d2722": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c6d812ade2547d6a00cb2a27565d6b2",
      "placeholder": "​",
      "style": "IPY_MODEL_9af2ecb27143428ab12d7a8fd4028cb3",
      "value": " 37/? [1:21:50&lt;00:00, 110.86s/it]"
     }
    },
    "2173dc4ffc074caeb9d2495813138d74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21ef8a0c39ee46bb989b228c00ed11a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c6d812ade2547d6a00cb2a27565d6b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7058deacb42b405e8ceeac304464ca29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2173dc4ffc074caeb9d2495813138d74",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1786f8686de4f8ca9f6bc764d255408",
      "value": 1
     }
    },
    "92737dcaad4e4a54919de369501de698": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7058deacb42b405e8ceeac304464ca29",
       "IPY_MODEL_0f8df1ac8bdb4baa86f88dd43c6d2722"
      ],
      "layout": "IPY_MODEL_21ef8a0c39ee46bb989b228c00ed11a1"
     }
    },
    "9af2ecb27143428ab12d7a8fd4028cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1786f8686de4f8ca9f6bc764d255408": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
