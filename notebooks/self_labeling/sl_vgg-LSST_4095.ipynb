{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tfs\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from utils import kNN, AverageMeter, py_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG\"\n",
    "magic_dim = 9216 #2048 \n",
    "\n",
    "# model_name = \"ResNet\"\n",
    "# magic_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"LSST/LSST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "datadir = \"/root/data/Multivariate_ts\"\n",
    "\n",
    "# optimization\n",
    "lamb = 0.1      # SK lambda-parameter\n",
    "nopts = 400    # number of SK-optimizations\n",
    "epochs = 400   # numbers of epochs\n",
    "momentum = 0.9 # sgd momentum\n",
    "exp = './resnet1d_exp' # experiments results dir\n",
    "\n",
    "\n",
    "# other\n",
    "devc='0'  # cuda device\n",
    "batch_size = 500\n",
    "lr=0.0005*2     #learning rate\n",
    "alr=0.0005*2    #starting learning rate\n",
    "\n",
    "knn_dim = 100\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:' + devc) if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"GPU device: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sktime.utils.load_data import load_from_tsfile_to_dataframe\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_torch(X):\n",
    "    X = X.applymap(np.array)\n",
    "    dimensions_lst = []\n",
    "\n",
    "    for dim in X.columns:\n",
    "        dimensions_lst.append(np.dstack(list(X[dim].values))[0])\n",
    "\n",
    "    dimensions_lst = np.array(dimensions_lst)\n",
    "    X = torch.from_numpy(np.array(dimensions_lst, dtype=np.float64))\n",
    "    X = X.transpose(0, 2)\n",
    "    X = X.transpose(1, 2)\n",
    "    X = F.normalize(X, dim=1)\n",
    "    return X.float()\n",
    "\n",
    "def answers_to_torch(y):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    y = torch.from_numpy(np.array(y, dtype=np.int32))\n",
    "    y = y.long()\n",
    "    return y\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt], excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_tsfile_to_dataframe(datadir + f'/{dataset_name}_TRAIN.ts')\n",
    "X_test, y_test = load_from_tsfile_to_dataframe(datadir + f'/{dataset_name}_TEST.ts')\n",
    "\n",
    "X_train = features_to_torch(X_train)\n",
    "X_test = features_to_torch(X_test)\n",
    "\n",
    "y_train = answers_to_torch(y_train)\n",
    "y_test = answers_to_torch(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_steps: 36\n",
      "train samples_num: 2459\n",
      "dims_num: 6\n",
      "num_classes: 14\n"
     ]
    }
   ],
   "source": [
    "N = X_train.shape[0]\n",
    "time_steps = X_train.shape[2]\n",
    "dims_num = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print('time_steps:', time_steps)\n",
    "print('train samples_num:', N)\n",
    "print('dims_num:', dims_num)\n",
    "print('num_classes:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters (AlexNet in that case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc=10                 # number of heads\n",
    "ncl=num_classes       # number of clusters\n",
    "\n",
    "numc = [ncl] * hc\n",
    "# # (number of filters, kernel size, stride, pad) for AlexNet, two vesions\n",
    "# CFG = {\n",
    "#     'big': [(96, 11, 4, 2), 'M', (256, 5, 1, 2), 'M', (384, 3, 1, 1), (384, 3, 1, 1), (256, 3, 1, 1), 'M'],\n",
    "#     'small': [(64, 11, 4, 2), 'M', (192, 5, 1, 2), 'M', (384, 3, 1, 1), (256, 3, 1, 1), (256, 3, 1, 1), 'M']\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['resnetv1','resnetv1_18']\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, power=2):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.power = power\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = x.pow(self.power).sum(1, keepdim=True).pow(1. / self.power)\n",
    "        out = x.div(norm)\n",
    "        return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, in_channel=3, width=1, num_classes=[1000]):\n",
    "        self.inplanes = 16\n",
    "        super(ResNet, self).__init__()\n",
    "        self.headcount = len(num_classes)\n",
    "        self.base = int(16 * width)\n",
    "        self.features = nn.Sequential(*[                                                     # [100, 8, 18]\n",
    "                            nn.Conv1d(in_channel, 16, kernel_size=3, padding=1, bias=False), # [100, 16, 36]\n",
    "                            nn.BatchNorm1d(16),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            self._make_layer(block, self.base, layers[0]),                   # [100, 16, 36]\n",
    "                            self._make_layer(block, self.base * 2, layers[1]),               # [100, 32, 36]\n",
    "                            self._make_layer(block, self.base * 4, layers[2]),               # [100, 64, 36]\n",
    "                            self._make_layer(block, self.base * 8, layers[3]),               # [100, 128, 36]\n",
    "                            nn.AvgPool1d(2),                                                 # [100, 128, 18]\n",
    "        ])\n",
    "    \n",
    "        if len(num_classes) == 1:\n",
    "            self.top_layer = nn.Sequential(nn.Linear(magic_dim, num_classes[0]))\n",
    "        else:\n",
    "            for a, i in enumerate(num_classes):\n",
    "                setattr(self, \"top_layer%d\" % a, nn.Linear(magic_dim, i))\n",
    "            self.top_layer = None\n",
    "        for m in self.features.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x.float())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        if self.headcount == 1:\n",
    "            if self.top_layer:\n",
    "                out = self.top_layer(out)\n",
    "            return out\n",
    "        else:\n",
    "            outp = []\n",
    "            for i in range(self.headcount):\n",
    "                outp.append(getattr(self, \"top_layer%d\" % i)(out))\n",
    "            return outp\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "def resnetv1_18(num_classes=[1000]):\n",
    "    \"\"\"Encoder for instance discrimination and MoCo\"\"\"\n",
    "    return resnet18(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG, self).__init__()\n",
    "        self.headcount = len(num_classes)\n",
    "        \n",
    "        self.features = nn.Sequential(*[                                                     # [100, 8, 18]\n",
    "                            nn.Conv1d(dims_num, 64, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "#                             nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "                            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "\n",
    "#                             nn.Flatten(),\n",
    "#                             nn.Linear(in_features=512 * (time_steps // 2**5), out_features=fc_hidden_dim, bias=True),\n",
    "\n",
    "#                             nn.ReLU(inplace=True),\n",
    "#                             nn.Dropout(p=0.5, inplace=False),\n",
    "#                             nn.Linear(in_features=fc_hidden_dim, out_features=fc_hidden_dim, bias=True),\n",
    "#                             nn.ReLU(inplace=True),\n",
    "#                             nn.Dropout(p=0.5, inplace=False),\n",
    "#                             nn.Linear(in_features=fc_hidden_dim, out_features=num_classes, bias=True),\n",
    "#                             nn.Softmax()\n",
    "        ])\n",
    "        \n",
    "        if len(num_classes) == 1:\n",
    "            self.top_layer = nn.Sequential(nn.Linear(magic_dim, num_classes[0]))\n",
    "        else:\n",
    "            for a, i in enumerate(num_classes):\n",
    "                setattr(self, \"top_layer%d\" % a, nn.Linear(magic_dim, i))\n",
    "            self.top_layer = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x.float())  # [50, 10, 400] -> [50, 512, 12]\n",
    "        out = out.view(out.size(0), -1) # [50, magic_dim]\n",
    "        if self.headcount == 1:\n",
    "            if self.top_layer:\n",
    "                out = self.top_layer(out)\n",
    "                print (out.size())\n",
    "            return out\n",
    "        else:\n",
    "            outp = []\n",
    "            for i in range(self.headcount):\n",
    "                outp.append(getattr(self, \"top_layer%d\" % i)(out))\n",
    "            return outp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn-Knopp optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_L_sk(PS):\n",
    "    N, K = PS.shape\n",
    "    tt = time.time()\n",
    "    PS = PS.T  # now it is K x N\n",
    "    r = np.ones((K, 1)) / K\n",
    "    c = np.ones((N, 1)) / N\n",
    "    PS **= lamb  # K x N\n",
    "    inv_K = 1. / K\n",
    "    inv_N = 1. / N\n",
    "    err = 1e3\n",
    "    _counter = 0\n",
    "    while err > 1e-2:\n",
    "        r = inv_K / (PS @ c)  # (KxN)@(N,1) = K x 1\n",
    "        c_new = inv_N / (r.T @ PS).T  # ((1,K)@(KxN)).t() = N x 1\n",
    "        if _counter % 10 == 0:\n",
    "            err = np.nansum(np.abs(c / c_new - 1))\n",
    "        c = c_new\n",
    "        _counter += 1\n",
    "        \n",
    "    print(\"error: \", err, 'step ', _counter, flush=True)  # \" nonneg: \", sum(I), flush=True)\n",
    "    # inplace calculations.\n",
    "    PS *= np.squeeze(c)\n",
    "    PS = PS.T\n",
    "    PS *= np.squeeze(r)\n",
    "    PS = PS.T\n",
    "    argmaxes = np.nanargmax(PS, 0)  # size N\n",
    "    newL = torch.LongTensor(argmaxes)\n",
    "    selflabels = newL.to(device)\n",
    "    PS = PS.T\n",
    "    PS /= np.squeeze(r)\n",
    "    PS = PS.T\n",
    "    PS /= np.squeeze(c)\n",
    "    sol = PS[argmaxes, np.arange(N)]\n",
    "    np.log(sol, sol)\n",
    "    cost = -(1. / lamb) * np.nansum(sol) / N\n",
    "    print('cost: ', cost, flush=True)\n",
    "    print('opt took {0:.2f}min, {1:4d}iters'.format(((time.time() - tt) / 60.), _counter), flush=True)\n",
    "    return cost, selflabels\n",
    "\n",
    "def opt_sk(model, selflabels_in, epoch):\n",
    "    if hc == 1:\n",
    "        PS = np.zeros((N, ncl))\n",
    "    else:\n",
    "        PS_pre = np.zeros((N, magic_dim)) # knn_dim\n",
    "    \n",
    "    for batch_idx, (data, _, _selected) in enumerate(iterate_minibatches(X_train, y_train, batch_size, shuffle=True)):\n",
    "        data = data.to(device)#cuda()\n",
    "        if hc == 1:\n",
    "            p = nn.functional.softmax(model(data), 1)\n",
    "            PS[_selected, :] = p.detach().cpu().numpy()\n",
    "        else:\n",
    "            p = model(data.float())\n",
    "            PS_pre[_selected, :] = p.detach().cpu().numpy() # p: [20, magic_dim]\n",
    "    if hc == 1:\n",
    "        cost, selflabels = optimize_L_sk(PS)\n",
    "        _costs = [cost]\n",
    "    else:\n",
    "        _nmis = np.zeros(hc)\n",
    "        _costs = np.zeros(hc)\n",
    "        nh = epoch % hc  # np.random.randint(args.hc)\n",
    "        print(\"computing head %s \" % nh, end=\"\\r\", flush=True)\n",
    "        tl = getattr(model, \"top_layer%d\" % nh)\n",
    "        # do the forward pass:\n",
    "        PS = (PS_pre @ tl.weight.cpu().numpy().T\n",
    "                   + tl.bias.cpu().numpy())\n",
    "        PS = py_softmax(PS, 1)\n",
    "        c, selflabels_ = optimize_L_sk(PS)\n",
    "        _costs[nh] = c\n",
    "        selflabels_in[nh] = selflabels_\n",
    "        selflabels = selflabels_in\n",
    "    return selflabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = alr\n",
    "    if epochs == 200:\n",
    "        if epoch >= 80:\n",
    "            lr = alr * (0.1 ** ((epoch - 80) // 40))  # i.e. 120, 160\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    elif epochs == 400:\n",
    "        if epoch >= 160:\n",
    "            lr = alr * (0.1 ** ((epoch - 160) // 80))  # i.e. 240,320\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    elif epochs == 800:\n",
    "        if epoch >= 320:\n",
    "            lr = alr * (0.1 ** ((epoch - 320) // 160))  # i.e. 480, 640\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    elif epochs == 1600:\n",
    "        if epoch >= 640:\n",
    "            lr = alr * (0.1 ** ((epoch - 640) // 320))\n",
    "            print(lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_return_switch(model, bool=True):\n",
    "    \"\"\"\n",
    "    switch between network output or conv5features\n",
    "        if True: changes switch s.t. forward pass returns post-conv5 features\n",
    "        if False: changes switch s.t. forward will give full network output\n",
    "    \"\"\"\n",
    "    if bool:\n",
    "        model.headcount = 1\n",
    "    else:\n",
    "        model.headcount = hc\n",
    "    model.return_feature = bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, selflabels):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    print(model_name)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train_loss = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets, indexes) in enumerate(iterate_minibatches(X_train, y_train, batch_size, shuffle=True)):\n",
    "        inputs = inputs.float().to(device)\n",
    "        niter = epoch * N // batch_size + batch_idx\n",
    "        if niter * batch_size >= optimize_times[-1]:\n",
    "            with torch.no_grad():\n",
    "                _ = optimize_times.pop()\n",
    "                if hc >1:\n",
    "                    feature_return_switch(model, True)\n",
    "                selflabels = opt_sk(model, selflabels, epoch)\n",
    "                if hc >1:\n",
    "                    feature_return_switch(model, False)\n",
    "        data_time.update(time.time() - end)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)#, indexes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        if hc == 1:\n",
    "            loss = criterion(outputs, selflabels[indexes])\n",
    "        else:\n",
    "            loss = torch.mean(torch.stack([criterion(outputs[h], selflabels[h, indexes]) for h in range(hc)]))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "#         if True:\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: [{}][{}/{}]'\n",
    "                  'Time: {batch_time.val:.3f} ({batch_time.avg:.3f}) '\n",
    "                  'Data: {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Loss: {train_loss.val:.4f} ({train_loss.avg:.4f})'.format(\n",
    "                epoch, batch_idx, N // batch_size, batch_time=batch_time, data_time=data_time, train_loss=train_loss))\n",
    "#             writer.add_scalar(\"loss\", loss.item(), batch_idx*512 +epoch*N/batch_size)\n",
    "    return selflabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG created\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"ResNet\":\n",
    "    model = resnet18(num_classes=numc, in_channel=dims_num)\n",
    "else:\n",
    "    model = VGG(num_classes=numc)\n",
    "print (model_name, \"created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will optimize L at epochs: [410.0, 401.0, 400.0, 398.99, 397.99, 396.98, 395.98, 394.97, 393.97, 392.96, 391.95, 390.95, 389.94, 388.94, 387.93, 386.93, 385.92, 384.92, 383.91, 382.91, 381.9, 380.9, 379.89, 378.89, 377.88, 376.88, 375.87, 374.87, 373.86, 372.86, 371.85, 370.85, 369.84, 368.84, 367.83, 366.83, 365.82, 364.82, 363.81, 362.81, 361.8, 360.8, 359.79, 358.79, 357.78, 356.78, 355.77, 354.77, 353.76, 352.76, 351.75, 350.75, 349.74, 348.74, 347.73, 346.73, 345.72, 344.72, 343.71, 342.71, 341.7, 340.7, 339.69, 338.69, 337.68, 336.68, 335.67, 334.67, 333.66, 332.66, 331.65, 330.65, 329.64, 328.64, 327.63, 326.63, 325.62, 324.62, 323.61, 322.61, 321.6, 320.6, 319.59, 318.59, 317.58, 316.58, 315.57, 314.57, 313.56, 312.56, 311.55, 310.55, 309.54, 308.54, 307.53, 306.53, 305.52, 304.52, 303.51, 302.51, 301.5, 300.5, 299.49, 298.49, 297.48, 296.48, 295.47, 294.47, 293.46, 292.46, 291.45, 290.45, 289.44, 288.44, 287.43, 286.43, 285.42, 284.42, 283.41, 282.41, 281.4, 280.4, 279.39, 278.39, 277.38, 276.38, 275.37, 274.37, 273.36, 272.36, 271.35, 270.35, 269.34, 268.34, 267.33, 266.33, 265.32, 264.32, 263.31, 262.31, 261.3, 260.3, 259.29, 258.29, 257.28, 256.28, 255.27, 254.27, 253.26, 252.26, 251.25, 250.25, 249.24, 248.24, 247.23, 246.23, 245.22, 244.22, 243.21, 242.21, 241.2, 240.2, 239.19, 238.19, 237.18, 236.18, 235.17, 234.17, 233.16, 232.16, 231.15, 230.15, 229.14, 228.14, 227.13, 226.13, 225.12, 224.12, 223.11, 222.11, 221.1, 220.1, 219.09, 218.09, 217.08, 216.08, 215.07, 214.07, 213.06, 212.06, 211.05, 210.05, 209.04, 208.04, 207.03, 206.03, 205.02, 204.02, 203.01, 202.01, 201.0, 200.0, 198.99, 197.99, 196.98, 195.98, 194.97, 193.97, 192.96, 191.96, 190.95, 189.95, 188.94, 187.94, 186.93, 185.93, 184.92, 183.92, 182.91, 181.91, 180.9, 179.9, 178.89, 177.89, 176.88, 175.88, 174.87, 173.87, 172.86, 171.86, 170.85, 169.85, 168.84, 167.84, 166.83, 165.83, 164.82, 163.82, 162.81, 161.81, 160.8, 159.8, 158.79, 157.79, 156.78, 155.78, 154.77, 153.77, 152.76, 151.76, 150.75, 149.75, 148.74, 147.74, 146.73, 145.73, 144.72, 143.72, 142.71, 141.71, 140.7, 139.7, 138.69, 137.69, 136.68, 135.68, 134.67, 133.67, 132.66, 131.66, 130.65, 129.65, 128.64, 127.64, 126.63, 125.63, 124.62, 123.62, 122.61, 121.61, 120.6, 119.6, 118.59, 117.59, 116.58, 115.58, 114.57, 113.57, 112.56, 111.56, 110.55, 109.55, 108.54, 107.54, 106.53, 105.53, 104.52, 103.52, 102.51, 101.51, 100.5, 99.5, 98.49, 97.49, 96.48, 95.48, 94.47, 93.47, 92.46, 91.46, 90.45, 89.45, 88.44, 87.44, 86.43, 85.43, 84.42, 83.42, 82.41, 81.41, 80.4, 79.4, 78.39, 77.39, 76.38, 75.38, 74.37, 73.37, 72.36, 71.36, 70.35, 69.35, 68.34, 67.34, 66.33, 65.33, 64.32, 63.32, 62.31, 61.31, 60.3, 59.3, 58.29, 57.29, 56.28, 55.28, 54.27, 53.27, 52.26, 51.26, 50.25, 49.25, 48.24, 47.24, 46.23, 45.23, 44.22, 43.22, 42.21, 41.21, 40.2, 39.2, 38.19, 37.19, 36.18, 35.18, 34.17, 33.17, 32.16, 31.16, 30.15, 29.15, 28.14, 27.14, 26.13, 25.13, 24.12, 23.12, 22.11, 21.11, 20.1, 19.1, 18.09, 17.09, 16.08, 15.08, 14.07, 13.07, 12.06, 11.06, 10.05, 9.05, 8.04, 7.04, 6.03, 5.03, 4.02, 3.02, 2.01, 1.01, 0.0]\n"
     ]
    }
   ],
   "source": [
    "optimize_times = ((epochs + 1.0001)*N*(np.linspace(0, 1, nopts))[::-1]).tolist()\n",
    "optimize_times = [(epochs +10)*N] + optimize_times\n",
    "print('We will optimize L at epochs:', [np.round(1.0*t/N, 2) for t in optimize_times], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init selflabels randomly\n",
    "if hc == 1:\n",
    "    selflabels = np.zeros(N, dtype=np.int32)\n",
    "    for qq in range(N):\n",
    "        selflabels[qq] = qq % ncl\n",
    "    selflabels = np.random.permutation(selflabels)\n",
    "    selflabels = torch.LongTensor(selflabels).to(device)\n",
    "else:\n",
    "    selflabels = np.zeros((hc, N), dtype=np.int32)\n",
    "    for nh in range(hc):\n",
    "        for _i in range(N):\n",
    "            selflabels[nh, _i] = _i % numc[nh]\n",
    "        selflabels[nh] = np.random.permutation(selflabels[nh])\n",
    "    selflabels = torch.LongTensor(selflabels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'./runs/{dataset_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training! \n",
    "Takes a couple of minutes per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kNN(net, K, sigma=0.1, dim=128, use_pca=False):\n",
    "    net.eval()\n",
    "    # this part is ugly but made to be backwards-compatible. there was a change in cifar dataset's structure.\n",
    "    trainLabels = y_train\n",
    "    LEN = N\n",
    "    C = trainLabels.max() + 1\n",
    "\n",
    "    trainFeatures = torch.zeros((magic_dim, LEN))  # , device='cuda:0') # dim\n",
    "    normalize = Normalize()\n",
    "    for batch_idx, (inputs, targets, _) in enumerate(iterate_minibatches(X_train, y_train, batch_size, shuffle=False)):\n",
    "        batchSize = batch_size\n",
    "        inputs = inputs.cuda()\n",
    "        features = net(inputs.float())\n",
    "        if not use_pca:\n",
    "            features = normalize(features)\n",
    "        trainFeatures[:, batch_idx * batchSize:batch_idx * batchSize + batchSize] = features.data.t().cpu()\n",
    "        \n",
    "    if use_pca:\n",
    "        comps = 4\n",
    "        print('doing PCA with %s components'%comps, end=' ')\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=comps, whiten=False)\n",
    "        trainFeatures = pca.fit_transform(trainFeatures.numpy().T)\n",
    "        trainFeatures = torch.Tensor(trainFeatures)\n",
    "        trainFeatures = normalize(trainFeatures).t()\n",
    "        print('..done')\n",
    "    def eval_k_s(K_,sigma_):\n",
    "        total = 0\n",
    "        top1 = 0.\n",
    "#         top5 = 0.\n",
    "\n",
    "        with torch.no_grad():\n",
    "            retrieval_one_hot = torch.zeros(K_, C)# .cuda()\n",
    "            for batch_idx, (inputs, targets, _) in enumerate(iterate_minibatches(X_test, y_test, batch_size, shuffle=False)):\n",
    "                targets = targets # .cuda(async=True) # or without async for py3.7\n",
    "                inputs = inputs.cuda()\n",
    "                batchSize = batch_size\n",
    "                features = net(inputs)\n",
    "                if use_pca:\n",
    "                    features = pca.transform(features.cpu().numpy())\n",
    "                    features = torch.Tensor(features).cuda()\n",
    "                features = normalize(features).cpu()\n",
    "\n",
    "                dist = torch.mm(features, trainFeatures)\n",
    "\n",
    "                yd, yi = dist.topk(K_, dim=1, largest=True, sorted=True)\n",
    "                candidates = trainLabels.view(1, -1).expand(batchSize, -1)\n",
    "                retrieval = torch.gather(candidates, 1, yi).long()\n",
    "\n",
    "                retrieval_one_hot.resize_(batchSize * K_, C).zero_()\n",
    "                retrieval_one_hot.scatter_(1, retrieval.view(-1, 1), 1.)\n",
    "                \n",
    "                yd_transform = yd.clone().div_(sigma_).exp_()\n",
    "                probs = torch.sum(torch.mul(retrieval_one_hot.view(batchSize, -1, C),\n",
    "                                            yd_transform.view(batchSize, -1, 1)),\n",
    "                                  1)\n",
    "                _, predictions = probs.sort(1, True)\n",
    "\n",
    "                # Find which predictions match the target\n",
    "                correct = predictions.eq(targets.data.view(-1, 1))\n",
    "\n",
    "                top1 = top1 + correct.narrow(1, 0, 1).sum().item()\n",
    "#                 top5 = top5 + correct.narrow(1, 0, 5).sum().item()\n",
    "\n",
    "                total += targets.size(0)\n",
    "\n",
    "        print(f\"{K_}-NN,s={sigma_}: TOP1: \", top1 * 100. / total)\n",
    "        return top1 / total\n",
    "\n",
    "    if isinstance(K, list):\n",
    "        res = []\n",
    "        for K_ in K:\n",
    "            for sigma_ in sigma:\n",
    "                res.append(eval_k_s(K_, sigma_))\n",
    "        return res\n",
    "    else:\n",
    "        res = eval_k_s(K, sigma)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "VGG\n",
      "error:  0.0016160950934341889 step  1\n",
      "cost:  2.6250176852413056\n",
      "opt took 0.00min,    1iters\n",
      "Epoch: [0][0/4]Time: 0.260 (0.260) Data: 0.176 (0.176) Loss: 2.6378 (2.6378)\n",
      "10-NN,s=0.1: TOP1:  20.05\n",
      "Saving..\n",
      "Saving..\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  20.5\n",
      "50-NN,s=0.5: TOP1:  20.5\n",
      "10-NN,s=0.1: TOP1:  16.85\n",
      "10-NN,s=0.5: TOP1:  16.85\n",
      "best accuracy: 20.05\n",
      "\n",
      "Epoch: 1\n",
      "VGG\n",
      "Epoch: [1][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 2.4578 (2.4578)\n",
      "error:  0.0 step  11\n",
      "cost:  2.5290816467742885\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.8\n",
      "Saving..\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 2\n",
      "VGG\n",
      "Epoch: [2][0/4]Time: 0.067 (0.067) Data: 0.001 (0.001) Loss: 2.4231 (2.4231)\n",
      "error:  1.532107773982716e-14 step  11\n",
      "cost:  2.312843616378358\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.95\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 3\n",
      "VGG\n",
      "Epoch: [3][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 2.1260 (2.1260)\n",
      "error:  0.0 step  11\n",
      "cost:  2.2880568192096473\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.95\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 4\n",
      "VGG\n",
      "Epoch: [4][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.8639 (1.8639)\n",
      "error:  1.3844481117075702e-13 step  11\n",
      "cost:  2.324647283361126\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.5\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 5\n",
      "VGG\n",
      "Epoch: [5][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.6302 (1.6302)\n",
      "error:  0.0 step  11\n",
      "cost:  2.3075055155150284\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.15\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 6\n",
      "VGG\n",
      "Epoch: [6][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.3753 (1.3753)\n",
      "error:  1.297850715786808e-13 step  11\n",
      "cost:  2.277851111224223\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.5\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 7\n",
      "VGG\n",
      "Epoch: [7][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.1464 (1.1464)\n",
      "error:  0.0 step  11\n",
      "cost:  2.346071141856718\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.65\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 8\n",
      "VGG\n",
      "Epoch: [8][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9571 (0.9571)\n",
      "error:  0.0 step  11\n",
      "cost:  2.309899263987152\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.6\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 9\n",
      "VGG\n",
      "Epoch: [9][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7470 (0.7470)\n",
      "error:  3.7414515929867775e-14 step  11\n",
      "cost:  2.160019521295273\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.85\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 10\n",
      "VGG\n",
      "Epoch: [10][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.5360 (0.5360)\n",
      "error:  3.4425795547576854e-12 step  11\n",
      "cost:  0.8342405679032193\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.3\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 11\n",
      "VGG\n",
      "Epoch: [11][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6527 (0.6527)\n",
      "error:  9.880984919163893e-14 step  11\n",
      "cost:  0.7674083318663721\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.85\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 12\n",
      "VGG\n",
      "Epoch: [12][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7125 (0.7125)\n",
      "error:  0.0 step  11\n",
      "cost:  0.696489137222803\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.6\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 13\n",
      "VGG\n",
      "Epoch: [13][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7169 (0.7169)\n",
      "error:  3.4861002973229915e-14 step  11\n",
      "cost:  0.6387208854705743\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.8\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 14\n",
      "VGG\n",
      "Epoch: [14][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.7123 (0.7123)\n",
      "error:  1.3067324999838092e-13 step  11\n",
      "cost:  0.6456965251191795\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.75\n",
      "best accuracy: 27.80\n",
      "\n",
      "Epoch: 15\n",
      "VGG\n",
      "Epoch: [15][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6451 (0.6451)\n",
      "error:  1.312283615106935e-13 step  11\n",
      "cost:  0.6288700450558343\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.75\n",
      "Saving..\n",
      "best accuracy: 29.75\n",
      "\n",
      "Epoch: 16\n",
      "VGG\n",
      "Epoch: [16][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6639 (0.6639)\n",
      "error:  1.517674874662589e-13 step  11\n",
      "cost:  0.6882167306060563\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.5\n",
      "best accuracy: 29.75\n",
      "\n",
      "Epoch: 17\n",
      "VGG\n",
      "Epoch: [17][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6864 (0.6864)\n",
      "error:  1.857403120197887e-13 step  11\n",
      "cost:  0.7049067461391691\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.5\n",
      "best accuracy: 29.75\n",
      "\n",
      "Epoch: 18\n",
      "VGG\n",
      "Epoch: [18][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6686 (0.6686)\n",
      "error:  2.573496971081113e-13 step  11\n",
      "cost:  0.696044329937946\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.9\n",
      "Saving..\n",
      "best accuracy: 30.90\n",
      "\n",
      "Epoch: 19\n",
      "VGG\n",
      "Epoch: [19][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7051 (0.7051)\n",
      "error:  2.09277040141842e-13 step  11\n",
      "cost:  0.7378064701536363\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.15\n",
      "Saving..\n",
      "best accuracy: 32.15\n",
      "\n",
      "Epoch: 20\n",
      "VGG\n",
      "Epoch: [20][0/4]Time: 0.067 (0.067) Data: 0.001 (0.001) Loss: 0.6695 (0.6695)\n",
      "error:  1.461053500406706e-13 step  11\n",
      "cost:  0.6946239896194768\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.65\n",
      "best accuracy: 32.15\n",
      "\n",
      "Epoch: 21\n",
      "VGG\n",
      "Epoch: [21][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7224 (0.7224)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7145547877735294\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.35\n",
      "best accuracy: 32.15\n",
      "\n",
      "Epoch: 22\n",
      "VGG\n",
      "Epoch: [22][0/4]Time: 0.067 (0.067) Data: 0.002 (0.002) Loss: 0.7053 (0.7053)\n",
      "error:  7.438494264988549e-14 step  11\n",
      "cost:  0.6478796719164289\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.1\n",
      "best accuracy: 32.15\n",
      "\n",
      "Epoch: 23\n",
      "VGG\n",
      "Epoch: [23][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7338 (0.7338)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7065443178019813\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.05\n",
      "Saving..\n",
      "best accuracy: 33.05\n",
      "\n",
      "Epoch: 24\n",
      "VGG\n",
      "Epoch: [24][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7052 (0.7052)\n",
      "error:  1.1013412404281553e-13 step  11\n",
      "cost:  0.7126654915726044\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.85\n",
      "Saving..\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 25\n",
      "VGG\n",
      "Epoch: [25][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6683 (0.6683)\n",
      "error:  1.0724754417879012e-13 step  11\n",
      "cost:  0.6562837061419231\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.7\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 26\n",
      "VGG\n",
      "Epoch: [26][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7025 (0.7025)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6711803977543437\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.45\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 27\n",
      "VGG\n",
      "Epoch: [27][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6781 (0.6781)\n",
      "error:  2.5091040356528538e-14 step  11\n",
      "cost:  0.7385229410388399\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  15.15\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 28\n",
      "VGG\n",
      "Epoch: [28][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6524 (0.6524)\n",
      "error:  2.1826984664130578e-13 step  11\n",
      "cost:  0.6762282638169559\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  13.8\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 29\n",
      "VGG\n",
      "Epoch: [29][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6443 (0.6443)\n",
      "error:  1.0658141036401503e-13 step  11\n",
      "cost:  0.6934991818987623\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  17.15\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 30\n",
      "VGG\n",
      "Epoch: [30][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6295 (0.6295)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6016031452244113\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  14.9\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 31\n",
      "VGG\n",
      "Epoch: [31][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6452 (0.6452)\n",
      "error:  1.4099832412739488e-13 step  11\n",
      "cost:  0.6809758826571295\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.7\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 32\n",
      "VGG\n",
      "Epoch: [32][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6413 (0.6413)\n",
      "error:  1.326716514427062e-13 step  11\n",
      "cost:  0.6498479945492734\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.55\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 33\n",
      "VGG\n",
      "Epoch: [33][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6318 (0.6318)\n",
      "error:  1.52433621281034e-13 step  11\n",
      "cost:  0.6325748726838305\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.35\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 34\n",
      "VGG\n",
      "Epoch: [34][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6668 (0.6668)\n",
      "error:  1.9706458687096529e-13 step  11\n",
      "cost:  0.6519288658188855\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.8\n",
      "best accuracy: 33.85\n",
      "\n",
      "Epoch: 35\n",
      "VGG\n",
      "Epoch: [35][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6405 (0.6405)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  2.395861287141088e-13 step  11\n",
      "cost:  0.6342434987506834\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.65\n",
      "Saving..\n",
      "best accuracy: 36.65\n",
      "\n",
      "Epoch: 36\n",
      "VGG\n",
      "Epoch: [36][0/4]Time: 0.068 (0.068) Data: 0.001 (0.001) Loss: 0.6428 (0.6428)\n",
      "error:  3.0531133177191805e-14 step  11\n",
      "cost:  0.6426954870787297\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.8\n",
      "Saving..\n",
      "best accuracy: 36.80\n",
      "\n",
      "Epoch: 37\n",
      "VGG\n",
      "Epoch: [37][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6414 (0.6414)\n",
      "error:  1.149080830487037e-13 step  11\n",
      "cost:  0.67711290457048\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.3\n",
      "Saving..\n",
      "best accuracy: 39.30\n",
      "\n",
      "Epoch: 38\n",
      "VGG\n",
      "Epoch: [38][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6438 (0.6438)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6829747188678573\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.6\n",
      "Saving..\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 39\n",
      "VGG\n",
      "Epoch: [39][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6292 (0.6292)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6689291314163356\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.55\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 40\n",
      "VGG\n",
      "Epoch: [40][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6549 (0.6549)\n",
      "error:  1.6009416015094757e-13 step  11\n",
      "cost:  0.6665653735933098\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.4\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 41\n",
      "VGG\n",
      "Epoch: [41][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6904 (0.6904)\n",
      "error:  2.5979218776228663e-14 step  11\n",
      "cost:  0.7311333250739627\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.6\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 42\n",
      "VGG\n",
      "Epoch: [42][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7404 (0.7404)\n",
      "error:  2.275957200481571e-14 step  11\n",
      "cost:  0.750060700040408\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.1\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 43\n",
      "VGG\n",
      "Epoch: [43][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7301 (0.7301)\n",
      "error:  1.9884094371036554e-13 step  11\n",
      "cost:  0.7490466797899806\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.65\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 44\n",
      "VGG\n",
      "Epoch: [44][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7202 (0.7202)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6801235252650984\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.9\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 45\n",
      "VGG\n",
      "Epoch: [45][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6816 (0.6816)\n",
      "error:  3.0808688933348094e-13 step  11\n",
      "cost:  0.6729546089555415\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.2\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 46\n",
      "VGG\n",
      "Epoch: [46][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6451 (0.6451)\n",
      "error:  2.5757174171303632e-14 step  11\n",
      "cost:  0.6739927019510101\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.8\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 47\n",
      "VGG\n",
      "Epoch: [47][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6316 (0.6316)\n",
      "error:  5.3512749786932545e-14 step  11\n",
      "cost:  0.6404823489071898\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.05\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 48\n",
      "VGG\n",
      "Epoch: [48][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6033 (0.6033)\n",
      "error:  2.355893258254582e-13 step  11\n",
      "cost:  0.6500345143377512\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.0\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 49\n",
      "VGG\n",
      "Epoch: [49][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6374 (0.6374)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6239361050878912\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.45\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 50\n",
      "VGG\n",
      "Epoch: [50][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6525 (0.6525)\n",
      "error:  2.1793677973391823e-13 step  11\n",
      "cost:  0.6433969079673656\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.65\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  35.15\n",
      "50-NN,s=0.5: TOP1:  35.1\n",
      "10-NN,s=0.1: TOP1:  33.0\n",
      "10-NN,s=0.5: TOP1:  33.0\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 51\n",
      "VGG\n",
      "Epoch: [51][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6886 (0.6886)\n",
      "error:  2.2248869413488137e-13 step  11\n",
      "cost:  0.6441886021533355\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.95\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 52\n",
      "VGG\n",
      "Epoch: [52][0/4]Time: 0.068 (0.068) Data: 0.003 (0.003) Loss: 0.7062 (0.7062)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6331951992334232\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.95\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 53\n",
      "VGG\n",
      "Epoch: [53][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6714 (0.6714)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6053395819253605\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.8\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 54\n",
      "VGG\n",
      "Epoch: [54][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6671 (0.6671)\n",
      "error:  0.0 step  11\n",
      "cost:  0.665938093068478\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.4\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 55\n",
      "VGG\n",
      "Epoch: [55][0/4]Time: 0.065 (0.065) Data: 0.002 (0.002) Loss: 0.6957 (0.6957)\n",
      "error:  2.289279876777073e-13 step  11\n",
      "cost:  0.7201689232602665\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.0\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 56\n",
      "VGG\n",
      "Epoch: [56][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6582 (0.6582)\n",
      "error:  1.7208456881689926e-13 step  11\n",
      "cost:  0.6703286659517161\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.85\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 57\n",
      "VGG\n",
      "Epoch: [57][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7000 (0.7000)\n",
      "error:  3.5083047578154947e-14 step  11\n",
      "cost:  0.7136555916211506\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.6\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 58\n",
      "VGG\n",
      "Epoch: [58][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7001 (0.7001)\n",
      "error:  4.263256414560601e-14 step  11\n",
      "cost:  0.6673325698383252\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.4\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 59\n",
      "VGG\n",
      "Epoch: [59][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6812 (0.6812)\n",
      "error:  1.4210854715202004e-14 step  11\n",
      "cost:  0.7027207559604425\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.25\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 60\n",
      "VGG\n",
      "Epoch: [60][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6532 (0.6532)\n",
      "error:  2.1782575743145571e-13 step  11\n",
      "cost:  0.6627005699706703\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.3\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 61\n",
      "VGG\n",
      "Epoch: [61][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6620 (0.6620)\n",
      "error:  1.5432100042289676e-13 step  11\n",
      "cost:  0.6092248904734732\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 62\n",
      "VGG\n",
      "Epoch: [62][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7035 (0.7035)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6947907252191274\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.35\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 63\n",
      "VGG\n",
      "Epoch: [63][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6594 (0.6594)\n",
      "error:  1.0758061108617767e-13 step  11\n",
      "cost:  0.6413898390448652\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.5\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 64\n",
      "VGG\n",
      "Epoch: [64][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6951 (0.6951)\n",
      "error:  5.040412531798211e-14 step  11\n",
      "cost:  0.6301082643216708\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.0\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 65\n",
      "VGG\n",
      "Epoch: [65][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6571 (0.6571)\n",
      "error:  2.204902926905561e-13 step  11\n",
      "cost:  0.7003290047811944\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.3\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 66\n",
      "VGG\n",
      "Epoch: [66][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7058 (0.7058)\n",
      "error:  2.020605904817785e-13 step  11\n",
      "cost:  0.6490461998221617\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.95\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 67\n",
      "VGG\n",
      "Epoch: [67][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6627 (0.6627)\n",
      "error:  1.1579626146840383e-13 step  11\n",
      "cost:  0.6246124557943277\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.45\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 68\n",
      "VGG\n",
      "Epoch: [68][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6830 (0.6830)\n",
      "error:  2.821076705572523e-13 step  11\n",
      "cost:  0.6008322160517814\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.3\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 69\n",
      "VGG\n",
      "Epoch: [69][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6668 (0.6668)\n",
      "error:  2.653433028854124e-14 step  11\n",
      "cost:  0.662701732769349\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.1\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 70\n",
      "VGG\n",
      "Epoch: [70][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6908 (0.6908)\n",
      "error:  0.0 step  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.6244876784948751\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.5\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 71\n",
      "VGG\n",
      "Epoch: [71][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6895 (0.6895)\n",
      "error:  1.3988810110276972e-13 step  11\n",
      "cost:  0.619989612310105\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.95\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 72\n",
      "VGG\n",
      "Epoch: [72][0/4]Time: 0.068 (0.068) Data: 0.001 (0.001) Loss: 0.6959 (0.6959)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6624748424260856\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 73\n",
      "VGG\n",
      "Epoch: [73][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6677 (0.6677)\n",
      "error:  2.036149027162537e-13 step  11\n",
      "cost:  0.6953594784403954\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.25\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 74\n",
      "VGG\n",
      "Epoch: [74][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6628 (0.6628)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6803345531513031\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.55\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 75\n",
      "VGG\n",
      "Epoch: [75][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7090 (0.7090)\n",
      "error:  2.0794477251229182e-13 step  11\n",
      "cost:  0.7354119016706856\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  37.15\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 76\n",
      "VGG\n",
      "Epoch: [76][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6950 (0.6950)\n",
      "error:  2.525757381022231e-13 step  11\n",
      "cost:  0.6856465546196456\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  38.65\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 77\n",
      "VGG\n",
      "Epoch: [77][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6974 (0.6974)\n",
      "error:  1.149080830487037e-13 step  11\n",
      "cost:  0.642571021979908\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.4\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 78\n",
      "VGG\n",
      "Epoch: [78][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7086 (0.7086)\n",
      "error:  2.716715741257758e-13 step  11\n",
      "cost:  0.6893311000390029\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.4\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 79\n",
      "VGG\n",
      "Epoch: [79][0/4]Time: 0.067 (0.067) Data: 0.001 (0.001) Loss: 0.6599 (0.6599)\n",
      "error:  2.942091015256665e-14 step  11\n",
      "cost:  0.6612881801175512\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.55\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 80\n",
      "VGG\n",
      "Epoch: [80][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6909 (0.6909)\n",
      "error:  2.5757174171303632e-14 step  11\n",
      "cost:  0.664192580572307\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  38.15\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 81\n",
      "VGG\n",
      "Epoch: [81][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6865 (0.6865)\n",
      "error:  2.6645352591003757e-14 step  11\n",
      "cost:  0.6584623184615007\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.25\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 82\n",
      "VGG\n",
      "Epoch: [82][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7056 (0.7056)\n",
      "error:  2.2171153801764376e-13 step  11\n",
      "cost:  0.6151988357040215\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.1\n",
      "best accuracy: 39.60\n",
      "\n",
      "Epoch: 83\n",
      "VGG\n",
      "Epoch: [83][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6733 (0.6733)\n",
      "error:  1.0902390101819037e-13 step  11\n",
      "cost:  0.6287629509904167\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  40.45\n",
      "Saving..\n",
      "best accuracy: 40.45\n",
      "\n",
      "Epoch: 84\n",
      "VGG\n",
      "Epoch: [84][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6594 (0.6594)\n",
      "error:  1.346700528870315e-13 step  11\n",
      "cost:  0.6251207643517023\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  40.2\n",
      "best accuracy: 40.45\n",
      "\n",
      "Epoch: 85\n",
      "VGG\n",
      "Epoch: [85][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6690 (0.6690)\n",
      "error:  2.4424906541753444e-14 step  11\n",
      "cost:  0.7054768939345445\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  40.95\n",
      "Saving..\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 86\n",
      "VGG\n",
      "Epoch: [86][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7052 (0.7052)\n",
      "10-NN,s=0.1: TOP1:  38.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 87\n",
      "VGG\n",
      "error:  4.285460875053104e-14 step  11\n",
      "cost:  0.7258484378465219\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [87][0/4]Time: 0.224 (0.224) Data: 0.157 (0.157) Loss: 0.7157 (0.7157)\n",
      "10-NN,s=0.1: TOP1:  38.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 88\n",
      "VGG\n",
      "error:  6.661338147750939e-14 step  11\n",
      "cost:  0.6945975948254588\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [88][0/4]Time: 0.219 (0.219) Data: 0.154 (0.154) Loss: 0.6962 (0.6962)\n",
      "error:  1.8240964294591322e-13 step  11\n",
      "cost:  0.6262107975461829\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  37.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 89\n",
      "VGG\n",
      "Epoch: [89][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6368 (0.6368)\n",
      "error:  9.892087149410145e-14 step  11\n",
      "cost:  0.6696651946327864\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 90\n",
      "VGG\n",
      "Epoch: [90][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6672 (0.6672)\n",
      "error:  2.468025783741723e-13 step  11\n",
      "cost:  0.6564175925146613\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 91\n",
      "VGG\n",
      "Epoch: [91][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7204 (0.7204)\n",
      "error:  4.071187831300449e-13 step  11\n",
      "cost:  0.6324313915285559\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  37.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 92\n",
      "VGG\n",
      "Epoch: [92][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7463 (0.7463)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6744799636633356\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  37.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 93\n",
      "VGG\n",
      "Epoch: [93][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7094 (0.7094)\n",
      "error:  2.1582735598713043e-13 step  11\n",
      "cost:  0.6591191585457049\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 94\n",
      "VGG\n",
      "Epoch: [94][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6847 (0.6847)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7162952273623171\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  39.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 95\n",
      "VGG\n",
      "Epoch: [95][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7073 (0.7073)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6827610055381729\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 96\n",
      "VGG\n",
      "Epoch: [96][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7555 (0.7555)\n",
      "error:  2.1604940059205546e-13 step  11\n",
      "cost:  0.6544174819657776\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 97\n",
      "VGG\n",
      "Epoch: [97][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7587 (0.7587)\n",
      "error:  3.5771385853422544e-13 step  11\n",
      "cost:  0.640923215700669\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 98\n",
      "VGG\n",
      "Epoch: [98][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7491 (0.7491)\n",
      "10-NN,s=0.1: TOP1:  33.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 99\n",
      "VGG\n",
      "error:  2.2803980925800715e-13 step  11\n",
      "cost:  0.7134300798198089\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [99][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 0.7554 (0.7554)\n",
      "10-NN,s=0.1: TOP1:  33.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 100\n",
      "VGG\n",
      "error:  2.6645352591003757e-14 step  11\n",
      "cost:  0.6902470892038762\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [100][0/4]Time: 0.233 (0.233) Data: 0.168 (0.168) Loss: 0.7616 (0.7616)\n",
      "10-NN,s=0.1: TOP1:  34.8\n",
      "Saving..\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  37.3\n",
      "50-NN,s=0.5: TOP1:  37.4\n",
      "10-NN,s=0.1: TOP1:  35.9\n",
      "10-NN,s=0.5: TOP1:  35.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 101\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6504195525995784\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [101][0/4]Time: 0.240 (0.240) Data: 0.174 (0.174) Loss: 0.7717 (0.7717)\n",
      "10-NN,s=0.1: TOP1:  30.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 102\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.7022477220176121\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [102][0/4]Time: 0.225 (0.225) Data: 0.158 (0.158) Loss: 0.7354 (0.7354)\n",
      "10-NN,s=0.1: TOP1:  31.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 103\n",
      "VGG\n",
      "error:  7.649436639667329e-14 step  11\n",
      "cost:  0.6335116937809881\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [103][0/4]Time: 0.229 (0.229) Data: 0.164 (0.164) Loss: 0.7504 (0.7504)\n",
      "10-NN,s=0.1: TOP1:  30.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 104\n",
      "VGG\n",
      "error:  4.440892098500626e-14 step  11\n",
      "cost:  0.6595487522794902\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [104][0/4]Time: 0.223 (0.223) Data: 0.157 (0.157) Loss: 0.7460 (0.7460)\n",
      "10-NN,s=0.1: TOP1:  36.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 105\n",
      "VGG\n",
      "error:  5.651035195342047e-14 step  11\n",
      "cost:  0.7044768485237209\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [105][0/4]Time: 0.262 (0.262) Data: 0.184 (0.184) Loss: 0.7218 (0.7218)\n",
      "error:  1.66644475996236e-13 step  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.6584738592543026\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  38.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 106\n",
      "VGG\n",
      "Epoch: [106][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6258 (0.6258)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6909156422257584\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 107\n",
      "VGG\n",
      "Epoch: [107][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6995 (0.6995)\n",
      "error:  4.6629367034256575e-14 step  11\n",
      "cost:  0.7233143544905271\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 108\n",
      "VGG\n",
      "Epoch: [108][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7013 (0.7013)\n",
      "error:  1.028066520802895e-13 step  11\n",
      "cost:  0.6855696571644329\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  38.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 109\n",
      "VGG\n",
      "Epoch: [109][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7269 (0.7269)\n",
      "error:  1.412203687323199e-13 step  11\n",
      "cost:  0.6913522555703135\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  37.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 110\n",
      "VGG\n",
      "Epoch: [110][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7322 (0.7322)\n",
      "10-NN,s=0.1: TOP1:  31.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 111\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6649640943369524\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [111][0/4]Time: 0.230 (0.230) Data: 0.164 (0.164) Loss: 0.7806 (0.7806)\n",
      "10-NN,s=0.1: TOP1:  34.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 112\n",
      "VGG\n",
      "error:  1.305622276959184e-13 step  11\n",
      "cost:  0.6925357951929223\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [112][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 0.7819 (0.7819)\n",
      "10-NN,s=0.1: TOP1:  36.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 113\n",
      "VGG\n",
      "error:  5.5289106626332796e-14 step  11\n",
      "cost:  0.7267750458583786\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [113][0/4]Time: 0.226 (0.226) Data: 0.161 (0.161) Loss: 0.7390 (0.7390)\n",
      "10-NN,s=0.1: TOP1:  35.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 114\n",
      "VGG\n",
      "error:  3.963496197911809e-14 step  11\n",
      "cost:  0.6663779473634779\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [114][0/4]Time: 0.253 (0.253) Data: 0.187 (0.187) Loss: 0.7450 (0.7450)\n",
      "10-NN,s=0.1: TOP1:  30.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 115\n",
      "VGG\n",
      "error:  1.2456702336294256e-13 step  11\n",
      "cost:  0.6370269444618127\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [115][0/4]Time: 0.221 (0.221) Data: 0.154 (0.154) Loss: 0.7184 (0.7184)\n",
      "10-NN,s=0.1: TOP1:  25.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 116\n",
      "VGG\n",
      "error:  6.261657858885883e-14 step  11\n",
      "cost:  0.6838032427771454\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [116][0/4]Time: 0.225 (0.225) Data: 0.155 (0.155) Loss: 0.7199 (0.7199)\n",
      "10-NN,s=0.1: TOP1:  21.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 117\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6385470682170471\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [117][0/4]Time: 0.215 (0.215) Data: 0.150 (0.150) Loss: 0.7194 (0.7194)\n",
      "10-NN,s=0.1: TOP1:  20.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 118\n",
      "VGG\n",
      "error:  2.6645352591003757e-14 step  11\n",
      "cost:  0.6645963776512904\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [118][0/4]Time: 0.223 (0.223) Data: 0.158 (0.158) Loss: 0.7203 (0.7203)\n",
      "10-NN,s=0.1: TOP1:  19.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 119\n",
      "VGG\n",
      "error:  6.017408793468348e-14 step  11\n",
      "cost:  0.6500794347610158\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [119][0/4]Time: 0.230 (0.230) Data: 0.155 (0.155) Loss: 0.7539 (0.7539)\n",
      "10-NN,s=0.1: TOP1:  16.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 120\n",
      "VGG\n",
      "error:  5.595524044110789e-14 step  11\n",
      "cost:  0.646024282310979\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [120][0/4]Time: 0.232 (0.232) Data: 0.165 (0.165) Loss: 0.7077 (0.7077)\n",
      "10-NN,s=0.1: TOP1:  14.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 121\n",
      "VGG\n",
      "error:  2.3647750424515834e-14 step  11\n",
      "cost:  0.6319001757827278\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [121][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 0.7303 (0.7303)\n",
      "10-NN,s=0.1: TOP1:  12.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 122\n",
      "VGG\n",
      "error:  2.5091040356528538e-14 step  11\n",
      "cost:  0.6466338736255394\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [122][0/4]Time: 0.245 (0.245) Data: 0.173 (0.173) Loss: 0.7240 (0.7240)\n",
      "10-NN,s=0.1: TOP1:  13.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 123\n",
      "VGG\n",
      "error:  2.439159985101469e-13 step  11\n",
      "cost:  0.6731060122366823\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [123][0/4]Time: 0.265 (0.265) Data: 0.199 (0.199) Loss: 0.7188 (0.7188)\n",
      "10-NN,s=0.1: TOP1:  17.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 124\n",
      "VGG\n",
      "error:  1.5987211554602254e-14 step  11\n",
      "cost:  0.7011577152043355\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [124][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 0.7437 (0.7437)\n",
      "10-NN,s=0.1: TOP1:  15.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 125\n",
      "VGG\n",
      "error:  1.2323475573339238e-13 step  11\n",
      "cost:  0.6512318026499301\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [125][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 0.7164 (0.7164)\n",
      "10-NN,s=0.1: TOP1:  16.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 126\n",
      "VGG\n",
      "error:  1.6209256159527285e-13 step  11\n",
      "cost:  0.6234291289864974\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [126][0/4]Time: 0.234 (0.234) Data: 0.168 (0.168) Loss: 0.7718 (0.7718)\n",
      "10-NN,s=0.1: TOP1:  16.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 127\n",
      "VGG\n",
      "error:  1.2922996006636822e-13 step  11\n",
      "cost:  0.6157859640965796\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [127][0/4]Time: 0.221 (0.221) Data: 0.156 (0.156) Loss: 0.7511 (0.7511)\n",
      "10-NN,s=0.1: TOP1:  16.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 128\n",
      "VGG\n",
      "error:  2.7622348852673895e-13 step  11\n",
      "cost:  0.709880629956665\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [128][0/4]Time: 0.219 (0.219) Data: 0.153 (0.153) Loss: 0.7056 (0.7056)\n",
      "10-NN,s=0.1: TOP1:  15.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 129\n",
      "VGG\n",
      "error:  6.361577931102147e-14 step  11\n",
      "cost:  0.691315117405623\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [129][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 0.7054 (0.7054)\n",
      "10-NN,s=0.1: TOP1:  16.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 130\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6822359032849613\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [130][0/4]Time: 0.250 (0.250) Data: 0.185 (0.185) Loss: 0.7408 (0.7408)\n",
      "10-NN,s=0.1: TOP1:  23.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 131\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6557597121165671\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [131][0/4]Time: 0.228 (0.228) Data: 0.161 (0.161) Loss: 0.7558 (0.7558)\n",
      "10-NN,s=0.1: TOP1:  10.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 132\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.5931421726506283\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [132][0/4]Time: 0.231 (0.231) Data: 0.166 (0.166) Loss: 0.7009 (0.7009)\n",
      "10-NN,s=0.1: TOP1:  10.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 133\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6625188773498333\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [133][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 0.7132 (0.7132)\n",
      "10-NN,s=0.1: TOP1:  12.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 134\n",
      "VGG\n",
      "error:  2.877698079828406e-13 step  11\n",
      "cost:  0.6980966039892728\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [134][0/4]Time: 0.260 (0.260) Data: 0.187 (0.187) Loss: 0.7126 (0.7126)\n",
      "10-NN,s=0.1: TOP1:  11.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 135\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6492688222756015\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [135][0/4]Time: 0.242 (0.242) Data: 0.169 (0.169) Loss: 0.7298 (0.7298)\n",
      "10-NN,s=0.1: TOP1:  12.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 136\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.7462458489532023\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [136][0/4]Time: 0.262 (0.262) Data: 0.197 (0.197) Loss: 0.7111 (0.7111)\n",
      "10-NN,s=0.1: TOP1:  12.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 137\n",
      "VGG\n",
      "error:  8.881784197001252e-14 step  11\n",
      "cost:  0.6965904274041473\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [137][0/4]Time: 0.223 (0.223) Data: 0.157 (0.157) Loss: 0.7280 (0.7280)\n",
      "10-NN,s=0.1: TOP1:  13.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 138\n",
      "VGG\n",
      "error:  1.3367085216486885e-13 step  11\n",
      "cost:  0.6839794551538634\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [138][0/4]Time: 0.218 (0.218) Data: 0.152 (0.152) Loss: 0.7061 (0.7061)\n",
      "10-NN,s=0.1: TOP1:  14.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 139\n",
      "VGG\n",
      "error:  3.531619441332623e-13 step  11\n",
      "cost:  0.6426660723110439\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [139][0/4]Time: 0.219 (0.219) Data: 0.154 (0.154) Loss: 0.7284 (0.7284)\n",
      "10-NN,s=0.1: TOP1:  12.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 140\n",
      "VGG\n",
      "error:  1.688649220454863e-13 step  11\n",
      "cost:  0.7175752509058781\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [140][0/4]Time: 0.221 (0.221) Data: 0.156 (0.156) Loss: 0.7251 (0.7251)\n",
      "10-NN,s=0.1: TOP1:  10.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 141\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6651106767770407\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [141][0/4]Time: 0.217 (0.217) Data: 0.151 (0.151) Loss: 0.7324 (0.7324)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  11.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 142\n",
      "VGG\n",
      "error:  2.489120021209601e-13 step  11\n",
      "cost:  0.6689005990103979\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [142][0/4]Time: 0.217 (0.217) Data: 0.151 (0.151) Loss: 0.7304 (0.7304)\n",
      "10-NN,s=0.1: TOP1:  10.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 143\n",
      "VGG\n",
      "error:  1.8463008899516353e-13 step  11\n",
      "cost:  0.6912774000667296\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [143][0/4]Time: 0.250 (0.250) Data: 0.185 (0.185) Loss: 0.7261 (0.7261)\n",
      "10-NN,s=0.1: TOP1:  11.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 144\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.684969744323886\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [144][0/4]Time: 0.236 (0.236) Data: 0.170 (0.170) Loss: 0.7157 (0.7157)\n",
      "10-NN,s=0.1: TOP1:  12.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 145\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.7035568368837732\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [145][0/4]Time: 0.221 (0.221) Data: 0.155 (0.155) Loss: 0.7789 (0.7789)\n",
      "10-NN,s=0.1: TOP1:  12.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 146\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6782937266259996\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [146][0/4]Time: 0.236 (0.236) Data: 0.168 (0.168) Loss: 0.7708 (0.7708)\n",
      "10-NN,s=0.1: TOP1:  12.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 147\n",
      "VGG\n",
      "error:  9.170442183403793e-14 step  11\n",
      "cost:  0.6860047104090905\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [147][0/4]Time: 0.224 (0.224) Data: 0.158 (0.158) Loss: 0.7515 (0.7515)\n",
      "10-NN,s=0.1: TOP1:  11.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 148\n",
      "VGG\n",
      "error:  3.43836070726411e-13 step  11\n",
      "cost:  0.6358210665597501\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [148][0/4]Time: 0.244 (0.244) Data: 0.171 (0.171) Loss: 0.7474 (0.7474)\n",
      "10-NN,s=0.1: TOP1:  13.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 149\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6617206524910281\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [149][0/4]Time: 0.215 (0.215) Data: 0.150 (0.150) Loss: 0.7936 (0.7936)\n",
      "10-NN,s=0.1: TOP1:  11.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 150\n",
      "VGG\n",
      "error:  1.3722356584366935e-13 step  11\n",
      "cost:  0.6451043244428386\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [150][0/4]Time: 0.227 (0.227) Data: 0.158 (0.158) Loss: 0.7861 (0.7861)\n",
      "10-NN,s=0.1: TOP1:  12.5\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  22.35\n",
      "50-NN,s=0.5: TOP1:  22.4\n",
      "10-NN,s=0.1: TOP1:  14.65\n",
      "10-NN,s=0.5: TOP1:  14.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 151\n",
      "VGG\n",
      "error:  5.229150445984487e-14 step  11\n",
      "cost:  0.6634097483154925\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [151][0/4]Time: 0.245 (0.245) Data: 0.179 (0.179) Loss: 0.7864 (0.7864)\n",
      "10-NN,s=0.1: TOP1:  13.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 152\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.65456843458384\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [152][0/4]Time: 0.233 (0.233) Data: 0.167 (0.167) Loss: 0.7765 (0.7765)\n",
      "10-NN,s=0.1: TOP1:  11.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 153\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.7234178246111673\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [153][0/4]Time: 0.223 (0.223) Data: 0.158 (0.158) Loss: 0.7589 (0.7589)\n",
      "10-NN,s=0.1: TOP1:  11.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 154\n",
      "VGG\n",
      "error:  6.94999613415348e-14 step  11\n",
      "cost:  0.6683694507838022\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [154][0/4]Time: 0.236 (0.236) Data: 0.168 (0.168) Loss: 0.7737 (0.7737)\n",
      "10-NN,s=0.1: TOP1:  12.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 155\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6618939696350706\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [155][0/4]Time: 0.228 (0.228) Data: 0.162 (0.162) Loss: 0.7415 (0.7415)\n",
      "10-NN,s=0.1: TOP1:  11.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 156\n",
      "VGG\n",
      "error:  5.1958437552457326e-14 step  11\n",
      "cost:  0.6476556611271465\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [156][0/4]Time: 0.216 (0.216) Data: 0.151 (0.151) Loss: 0.7511 (0.7511)\n",
      "10-NN,s=0.1: TOP1:  12.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 157\n",
      "VGG\n",
      "error:  3.111955138024314e-13 step  11\n",
      "cost:  0.6520598770937928\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [157][0/4]Time: 0.235 (0.235) Data: 0.170 (0.170) Loss: 0.7028 (0.7028)\n",
      "10-NN,s=0.1: TOP1:  12.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 158\n",
      "VGG\n",
      "error:  6.09512440519211e-14 step  11\n",
      "cost:  0.7311054341448522\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [158][0/4]Time: 0.239 (0.239) Data: 0.174 (0.174) Loss: 0.7425 (0.7425)\n",
      "10-NN,s=0.1: TOP1:  10.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 159\n",
      "VGG\n",
      "error:  0.0 step  11\n",
      "cost:  0.6453552735398086\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [159][0/4]Time: 0.231 (0.231) Data: 0.163 (0.163) Loss: 0.7161 (0.7161)\n",
      "10-NN,s=0.1: TOP1:  12.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 160\n",
      "VGG\n",
      "0.001\n",
      "error:  5.284661597215745e-14 step  11\n",
      "cost:  0.7020963358938027\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [160][0/4]Time: 0.269 (0.269) Data: 0.187 (0.187) Loss: 0.7667 (0.7667)\n",
      "10-NN,s=0.1: TOP1:  9.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 161\n",
      "VGG\n",
      "0.001\n",
      "error:  8.493206138382448e-14 step  11\n",
      "cost:  0.6831032037531551\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [161][0/4]Time: 0.223 (0.223) Data: 0.158 (0.158) Loss: 0.7702 (0.7702)\n",
      "10-NN,s=0.1: TOP1:  24.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 162\n",
      "VGG\n",
      "0.001\n",
      "error:  3.8469227803261674e-13 step  11\n",
      "cost:  0.7293189660553012\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [162][0/4]Time: 0.226 (0.226) Data: 0.161 (0.161) Loss: 0.7500 (0.7500)\n",
      "10-NN,s=0.1: TOP1:  20.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 163\n",
      "VGG\n",
      "0.001\n",
      "error:  4.318767565791859e-14 step  11\n",
      "cost:  0.6400589625019409\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [163][0/4]Time: 0.226 (0.226) Data: 0.159 (0.159) Loss: 0.7636 (0.7636)\n",
      "10-NN,s=0.1: TOP1:  10.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 164\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.6380128249801909\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [164][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 0.8003 (0.8003)\n",
      "10-NN,s=0.1: TOP1:  9.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 165\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.7345834995785414\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [165][0/4]Time: 0.223 (0.223) Data: 0.152 (0.152) Loss: 0.7466 (0.7466)\n",
      "10-NN,s=0.1: TOP1:  12.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 166\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.6983436698331174\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [166][0/4]Time: 0.258 (0.258) Data: 0.187 (0.187) Loss: 0.7784 (0.7784)\n",
      "10-NN,s=0.1: TOP1:  10.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 167\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.7031277743354423\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [167][0/4]Time: 0.247 (0.247) Data: 0.178 (0.178) Loss: 0.7785 (0.7785)\n",
      "10-NN,s=0.1: TOP1:  12.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 168\n",
      "VGG\n",
      "0.001\n",
      "error:  1.304512053934559e-13 step  11\n",
      "cost:  0.6776054203749307\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [168][0/4]Time: 0.223 (0.223) Data: 0.158 (0.158) Loss: 0.7993 (0.7993)\n",
      "10-NN,s=0.1: TOP1:  10.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 169\n",
      "VGG\n",
      "0.001\n",
      "error:  4.6629367034256575e-14 step  11\n",
      "cost:  0.7206365063996943\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [169][0/4]Time: 0.244 (0.244) Data: 0.172 (0.172) Loss: 0.7923 (0.7923)\n",
      "10-NN,s=0.1: TOP1:  8.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 170\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.695617067728181\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [170][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 0.7945 (0.7945)\n",
      "10-NN,s=0.1: TOP1:  16.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 171\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [171][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6665 (0.6665)\n",
      "error:  1.0447198661722723e-13 step  11\n",
      "cost:  0.5968898576893366\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 172\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [172][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6865 (0.6865)\n",
      "error:  2.353672812205332e-14 step  11\n",
      "cost:  0.6788550048784192\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  37.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 173\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [173][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6719 (0.6719)\n",
      "error:  1.4988010832439613e-13 step  11\n",
      "cost:  0.6591886091509325\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 174\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [174][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7089 (0.7089)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6748850924655178\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 175\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [175][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6667 (0.6667)\n",
      "error:  3.3306690738754696e-14 step  11\n",
      "cost:  0.6556740564904233\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  40.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 176\n",
      "VGG\n",
      "0.001\n",
      "error:  2.4502622153477205e-13 step  11\n",
      "cost:  0.6739155296591686\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [176][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 0.7368 (0.7368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  40.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 177\n",
      "VGG\n",
      "0.001\n",
      "error:  1.8418599978531347e-13 step  11\n",
      "cost:  0.6653904488395175\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [177][0/4]Time: 0.221 (0.221) Data: 0.155 (0.155) Loss: 0.7092 (0.7092)\n",
      "10-NN,s=0.1: TOP1:  38.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 178\n",
      "VGG\n",
      "0.001\n",
      "error:  1.766364832178624e-13 step  11\n",
      "cost:  0.6797773152678519\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [178][0/4]Time: 0.224 (0.224) Data: 0.157 (0.157) Loss: 0.7419 (0.7419)\n",
      "10-NN,s=0.1: TOP1:  26.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 179\n",
      "VGG\n",
      "0.001\n",
      "error:  4.030109579389318e-13 step  11\n",
      "cost:  0.6839972140896621\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [179][0/4]Time: 0.227 (0.227) Data: 0.161 (0.161) Loss: 0.7355 (0.7355)\n",
      "10-NN,s=0.1: TOP1:  25.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 180\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.7222781155074196\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [180][0/4]Time: 0.228 (0.228) Data: 0.157 (0.157) Loss: 0.7589 (0.7589)\n",
      "10-NN,s=0.1: TOP1:  24.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 181\n",
      "VGG\n",
      "0.001\n",
      "error:  0.0 step  11\n",
      "cost:  0.5920344058118062\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [181][0/4]Time: 0.219 (0.219) Data: 0.153 (0.153) Loss: 0.7355 (0.7355)\n",
      "10-NN,s=0.1: TOP1:  25.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 182\n",
      "VGG\n",
      "0.001\n",
      "error:  2.148281552649678e-13 step  11\n",
      "cost:  0.752505559409823\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [182][0/4]Time: 0.219 (0.219) Data: 0.154 (0.154) Loss: 0.7339 (0.7339)\n",
      "10-NN,s=0.1: TOP1:  26.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 183\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [183][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6225 (0.6225)\n",
      "error:  1.2378986724570495e-13 step  11\n",
      "cost:  0.6031594920169913\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 184\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [184][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6478 (0.6478)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6658407906226719\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 185\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [185][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6859 (0.6859)\n",
      "error:  2.575717417130363e-13 step  11\n",
      "cost:  0.6457049577649567\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 186\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [186][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7008 (0.7008)\n",
      "error:  1.525446435834965e-13 step  11\n",
      "cost:  0.678899968212474\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 187\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [187][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7057 (0.7057)\n",
      "error:  1.6187051699034782e-13 step  11\n",
      "cost:  0.7287776789281061\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 188\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [188][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7115 (0.7115)\n",
      "error:  1.8207657603852567e-14 step  11\n",
      "cost:  0.7119691093735269\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 189\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [189][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7276 (0.7276)\n",
      "error:  5.3179682879545e-14 step  11\n",
      "cost:  0.7162493240465543\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 190\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [190][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6960 (0.6960)\n",
      "error:  2.2104540420286867e-13 step  11\n",
      "cost:  0.6668662809220973\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 191\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [191][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7378 (0.7378)\n",
      "error:  6.539213615042172e-14 step  11\n",
      "cost:  0.7077200268768593\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 192\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [192][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7237 (0.7237)\n",
      "error:  2.8310687127941492e-14 step  11\n",
      "cost:  0.6584257882253262\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 193\n",
      "VGG\n",
      "0.001\n",
      "error:  2.3236967905404526e-13 step  11\n",
      "cost:  0.6761986251507025\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [193][0/4]Time: 0.245 (0.245) Data: 0.166 (0.166) Loss: 0.8109 (0.8109)\n",
      "10-NN,s=0.1: TOP1:  26.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 194\n",
      "VGG\n",
      "0.001\n",
      "error:  3.3306690738754696e-14 step  11\n",
      "cost:  0.6171637420918563\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [194][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 0.7758 (0.7758)\n",
      "10-NN,s=0.1: TOP1:  25.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 195\n",
      "VGG\n",
      "0.001\n",
      "error:  1.0547118733938987e-13 step  11\n",
      "cost:  0.6333745155271898\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [195][0/4]Time: 0.227 (0.227) Data: 0.162 (0.162) Loss: 0.7462 (0.7462)\n",
      "10-NN,s=0.1: TOP1:  25.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 196\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [196][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.5934 (0.5934)\n",
      "error:  1.1146639167236572e-13 step  11\n",
      "cost:  0.7798913333856032\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 197\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [197][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6085 (0.6085)\n",
      "error:  1.5432100042289676e-14 step  11\n",
      "cost:  0.6488202138470764\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 198\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [198][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6214 (0.6214)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6016028317811046\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 199\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [199][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.5990 (0.5990)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6288263386606826\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 200\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [200][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.5762 (0.5762)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6632808408520683\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.45\n",
      "Saving..\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  24.9\n",
      "50-NN,s=0.5: TOP1:  24.9\n",
      "10-NN,s=0.1: TOP1:  21.5\n",
      "10-NN,s=0.5: TOP1:  21.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 201\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [201][0/4]Time: 0.068 (0.068) Data: 0.003 (0.003) Loss: 0.6552 (0.6552)\n",
      "error:  1.1168843627729075e-13 step  11\n",
      "cost:  0.6502187473924376\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 202\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [202][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6577 (0.6577)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6342303779101727\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 203\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [203][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6723 (0.6723)\n",
      "error:  1.6919798895287386e-13 step  11\n",
      "cost:  0.6437568809682052\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 204\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [204][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6612 (0.6612)\n",
      "error:  9.059419880941277e-14 step  11\n",
      "cost:  0.638090491982368\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 205\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [205][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6965 (0.6965)\n",
      "error:  8.870681966755001e-14 step  11\n",
      "cost:  0.6116589096226815\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 206\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [206][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6739 (0.6739)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6736864523657798\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 207\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [207][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6311 (0.6311)\n",
      "error:  2.772226892489016e-13 step  11\n",
      "cost:  0.6947688540633847\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 208\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [208][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6550 (0.6550)\n",
      "error:  2.3947510641164627e-13 step  11\n",
      "cost:  0.6453509860101051\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 209\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [209][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6791 (0.6791)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6153868897945245\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 210\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [210][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6681 (0.6681)\n",
      "error:  4.718447854656915e-14 step  11\n",
      "cost:  0.6560322400311702\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 211\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [211][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7008 (0.7008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.0 step  11\n",
      "cost:  0.7121632304939135\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 212\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [212][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6904 (0.6904)\n",
      "error:  3.1530333899354446e-14 step  11\n",
      "cost:  0.6526241944778554\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 213\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [213][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6738 (0.6738)\n",
      "error:  2.3281376826389533e-13 step  11\n",
      "cost:  0.6944003641972\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  35.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 214\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [214][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6953 (0.6953)\n",
      "error:  2.8310687127941492e-14 step  11\n",
      "cost:  0.7019728774820804\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 215\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [215][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6693 (0.6693)\n",
      "error:  7.549516567451064e-14 step  11\n",
      "cost:  0.6404894073336463\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 216\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [216][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6601 (0.6601)\n",
      "error:  4.618527782440651e-14 step  11\n",
      "cost:  0.6974022410608853\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 217\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [217][0/4]Time: 0.064 (0.064) Data: 0.001 (0.001) Loss: 0.6562 (0.6562)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6791006757866835\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 218\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [218][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6692 (0.6692)\n",
      "error:  6.927791673660977e-14 step  11\n",
      "cost:  0.6811672438061689\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 219\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [219][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6593 (0.6593)\n",
      "error:  2.8266278206956486e-13 step  11\n",
      "cost:  0.6506566049758646\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 220\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [220][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6928 (0.6928)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7023218919107636\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 221\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [221][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7430 (0.7430)\n",
      "error:  1.1191048088221578e-13 step  11\n",
      "cost:  0.6430964906502468\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 222\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [222][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7401 (0.7401)\n",
      "error:  4.973799150320701e-14 step  11\n",
      "cost:  0.7033526047528023\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 223\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [223][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7463 (0.7463)\n",
      "error:  2.916555885690286e-13 step  11\n",
      "cost:  0.6658306711915624\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 224\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [224][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7240 (0.7240)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6542484833846747\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 225\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [225][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7032 (0.7032)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6815544451104387\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 226\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [226][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7137 (0.7137)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6460445917191486\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 227\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [227][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7250 (0.7250)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6684401129891466\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 228\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [228][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.7020 (0.7020)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6125028226726986\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 229\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [229][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6888 (0.6888)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6202094901381636\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 230\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [230][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6289 (0.6289)\n",
      "error:  5.739853037312059e-14 step  11\n",
      "cost:  0.6082131395958724\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 231\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [231][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6739 (0.6739)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6693881013734613\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 232\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [232][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6545 (0.6545)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7232125665369893\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 233\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [233][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6720 (0.6720)\n",
      "error:  1.0735856648125264e-13 step  11\n",
      "cost:  0.689969474241507\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 234\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [234][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6685 (0.6685)\n",
      "error:  5.917488721252084e-14 step  11\n",
      "cost:  0.6935680177092445\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 235\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [235][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.6942 (0.6942)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6439798356759022\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 236\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [236][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.6811 (0.6811)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6536937734215061\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 237\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [237][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6538 (0.6538)\n",
      "error:  2.2237767183241886e-13 step  11\n",
      "cost:  0.6398181973332833\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 238\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [238][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6762 (0.6762)\n",
      "error:  1.907363156306019e-13 step  11\n",
      "cost:  0.6843281951395228\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 239\n",
      "VGG\n",
      "0.001\n",
      "Epoch: [239][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6734 (0.6734)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6652358883426605\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 240\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [240][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.6756 (0.6756)\n",
      "error:  4.984901380566953e-14 step  11\n",
      "cost:  0.6159712274763398\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 241\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [241][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.7964 (0.7964)\n",
      "error:  7.982503547054876e-14 step  11\n",
      "cost:  0.7023232774028144\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 242\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [242][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.8569 (0.8569)\n",
      "error:  7.138734048339757e-14 step  11\n",
      "cost:  0.6772020948231683\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 243\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [243][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9629 (0.9629)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7050063840130698\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 244\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [244][0/4]Time: 0.067 (0.067) Data: 0.002 (0.002) Loss: 0.9732 (0.9732)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7481219153601585\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 245\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [245][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0303 (1.0303)\n",
      "error:  0.0 step  11\n",
      "cost:  0.8539353364157243\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 246\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [246][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0573 (1.0573)\n",
      "error:  0.0 step  11\n",
      "cost:  0.751025296164089\n",
      "opt took 0.00min,   11iters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  24.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 247\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [247][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0893 (1.0893)\n",
      "error:  9.64783808399261e-14 step  11\n",
      "cost:  0.7444711273230293\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 248\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [248][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.1261 (1.1261)\n",
      "error:  2.853273173286652e-14 step  11\n",
      "cost:  0.6825778054346366\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 249\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [249][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0949 (1.0949)\n",
      "error:  2.277067423506196e-13 step  11\n",
      "cost:  0.6703055665735815\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 250\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [250][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 1.0899 (1.0899)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6660086323749715\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.85\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  32.9\n",
      "50-NN,s=0.5: TOP1:  32.9\n",
      "10-NN,s=0.1: TOP1:  29.95\n",
      "10-NN,s=0.5: TOP1:  30.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 251\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [251][0/4]Time: 0.070 (0.070) Data: 0.005 (0.005) Loss: 1.1284 (1.1284)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7134874307722954\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 252\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [252][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0972 (1.0972)\n",
      "error:  1.4432899320127035e-13 step  11\n",
      "cost:  0.7409769021927283\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  36.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 253\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [253][0/4]Time: 0.068 (0.068) Data: 0.001 (0.001) Loss: 1.1480 (1.1480)\n",
      "error:  2.341460358934455e-13 step  11\n",
      "cost:  0.6839560271712983\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  34.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 254\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [254][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0925 (1.0925)\n",
      "error:  2.475797344914099e-14 step  11\n",
      "cost:  0.7484163815759819\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  33.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 255\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [255][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0966 (1.0966)\n",
      "error:  4.3143266736933583e-13 step  11\n",
      "cost:  0.778065688300491\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 256\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [256][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0691 (1.0691)\n",
      "error:  0.0 step  11\n",
      "cost:  0.745526360635812\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 257\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [257][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0532 (1.0532)\n",
      "error:  2.8976820942716586e-13 step  11\n",
      "cost:  0.7132232070034771\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  32.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 258\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [258][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0737 (1.0737)\n",
      "error:  2.1260770921571748e-13 step  11\n",
      "cost:  0.7080368291619055\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 259\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [259][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0815 (1.0815)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6971927066795917\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 260\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [260][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0512 (1.0512)\n",
      "error:  1.7319479184152442e-14 step  11\n",
      "cost:  0.6659447657497848\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 261\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [261][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0908 (1.0908)\n",
      "error:  1.4221956945448255e-13 step  11\n",
      "cost:  0.6902822507940554\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 262\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [262][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0887 (1.0887)\n",
      "error:  2.4202861936828413e-14 step  11\n",
      "cost:  0.7119050453226791\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 263\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [263][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0302 (1.0302)\n",
      "error:  2.347011474057581e-13 step  11\n",
      "cost:  0.6614785293392991\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 264\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [264][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0669 (1.0669)\n",
      "error:  1.3222756223285614e-13 step  11\n",
      "cost:  0.6855183248368195\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  24.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 265\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [265][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0644 (1.0644)\n",
      "error:  1.1479706074624119e-13 step  11\n",
      "cost:  0.7255655987751556\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 266\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [266][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 1.0236 (1.0236)\n",
      "error:  0.0 step  11\n",
      "cost:  0.701695873943346\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 267\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [267][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0276 (1.0276)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6785212725066188\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 268\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [268][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0230 (1.0230)\n",
      "error:  2.19824158875781e-13 step  11\n",
      "cost:  0.7082619984625179\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 269\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [269][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0575 (1.0575)\n",
      "error:  2.0872192862952943e-13 step  11\n",
      "cost:  0.7024875717725172\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 270\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [270][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0346 (1.0346)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6532003494910699\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 271\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [271][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9868 (0.9868)\n",
      "error:  4.524158825347513e-13 step  11\n",
      "cost:  0.6308847715321213\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 272\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [272][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9893 (0.9893)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7038024006805773\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 273\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [273][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0023 (1.0023)\n",
      "error:  3.647082635893639e-13 step  11\n",
      "cost:  0.7153048041789342\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 274\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [274][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0075 (1.0075)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6844972231674146\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  20.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 275\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [275][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0006 (1.0006)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6927038990598082\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 276\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [276][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9769 (0.9769)\n",
      "error:  6.494804694057166e-14 step  11\n",
      "cost:  0.6797031118857008\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 277\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [277][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0255 (1.0255)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6976961772842235\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 278\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [278][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0236 (1.0236)\n",
      "error:  4.030109579389318e-14 step  11\n",
      "cost:  0.7147657350981376\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 279\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [279][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0593 (1.0593)\n",
      "error:  3.397282455352979e-14 step  11\n",
      "cost:  0.6712550300356703\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 280\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [280][0/4]Time: 0.068 (0.068) Data: 0.001 (0.001) Loss: 1.0343 (1.0343)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6385166636219727\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 281\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [281][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0175 (1.0175)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.0 step  11\n",
      "cost:  0.6551286564094382\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 282\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [282][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 1.0161 (1.0161)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6914690867352843\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 283\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [283][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9827 (0.9827)\n",
      "error:  1.7508217098338719e-13 step  11\n",
      "cost:  0.6885741799918073\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 284\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [284][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0232 (1.0232)\n",
      "error:  2.360334150353083e-13 step  11\n",
      "cost:  0.6875938829768439\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 285\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [285][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9948 (0.9948)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6915448305258277\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  21.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 286\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [286][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0346 (1.0346)\n",
      "error:  1.1468603844377867e-13 step  11\n",
      "cost:  0.6995427570887598\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  22.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 287\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [287][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9971 (0.9971)\n",
      "error:  1.304512053934559e-13 step  11\n",
      "cost:  0.6698424655062037\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  23.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 288\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [288][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0367 (1.0367)\n",
      "error:  1.587618925213974e-14 step  11\n",
      "cost:  0.7058918403400715\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 289\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [289][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9672 (0.9672)\n",
      "error:  6.639133687258436e-14 step  11\n",
      "cost:  0.7083910666049159\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 290\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [290][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9340 (0.9340)\n",
      "error:  1.2889689315898067e-13 step  11\n",
      "cost:  0.6848351063536993\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 291\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [291][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.9839 (0.9839)\n",
      "error:  6.150635556423367e-14 step  11\n",
      "cost:  0.6546088106602208\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 292\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [292][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0070 (1.0070)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6378614294547305\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 293\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [293][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9823 (0.9823)\n",
      "10-NN,s=0.1: TOP1:  28.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 294\n",
      "VGG\n",
      "0.0001\n",
      "error:  1.4432899320127035e-13 step  11\n",
      "cost:  0.6735476212489168\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [294][0/4]Time: 0.236 (0.236) Data: 0.171 (0.171) Loss: 0.9851 (0.9851)\n",
      "10-NN,s=0.1: TOP1:  28.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 295\n",
      "VGG\n",
      "0.0001\n",
      "error:  2.5868196473766147e-13 step  11\n",
      "cost:  0.6936888229463346\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [295][0/4]Time: 0.238 (0.238) Data: 0.173 (0.173) Loss: 1.0184 (1.0184)\n",
      "10-NN,s=0.1: TOP1:  26.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 296\n",
      "VGG\n",
      "0.0001\n",
      "error:  0.0 step  11\n",
      "cost:  0.657976682748055\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [296][0/4]Time: 0.221 (0.221) Data: 0.155 (0.155) Loss: 1.0328 (1.0328)\n",
      "10-NN,s=0.1: TOP1:  26.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 297\n",
      "VGG\n",
      "0.0001\n",
      "error:  1.8318679906315083e-14 step  11\n",
      "cost:  0.6571317134687469\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [297][0/4]Time: 0.243 (0.243) Data: 0.177 (0.177) Loss: 0.9801 (0.9801)\n",
      "10-NN,s=0.1: TOP1:  27.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 298\n",
      "VGG\n",
      "0.0001\n",
      "error:  7.893685705084863e-14 step  11\n",
      "cost:  0.6569132059429696\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [298][0/4]Time: 0.229 (0.229) Data: 0.163 (0.163) Loss: 1.0126 (1.0126)\n",
      "error:  5.051514762044462e-14 step  11\n",
      "cost:  0.6697052588396497\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 299\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [299][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9736 (0.9736)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6827626288995094\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 300\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [300][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9590 (0.9590)\n",
      "error:  9.869882688917642e-14 step  11\n",
      "cost:  0.6780357931591855\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.4\n",
      "Saving..\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  26.95\n",
      "50-NN,s=0.5: TOP1:  27.0\n",
      "10-NN,s=0.1: TOP1:  23.25\n",
      "10-NN,s=0.5: TOP1:  23.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 301\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [301][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9714 (0.9714)\n",
      "error:  7.593925488436071e-14 step  11\n",
      "cost:  0.6816826766915206\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 302\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [302][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 0.9528 (0.9528)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6824700034893266\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 303\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [303][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9731 (0.9731)\n",
      "error:  2.3658852654762086e-13 step  11\n",
      "cost:  0.7215719349618643\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  31.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 304\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [304][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0172 (1.0172)\n",
      "error:  1.3067324999838092e-13 step  11\n",
      "cost:  0.6757103771513465\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  30.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 305\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [305][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 0.9774 (0.9774)\n",
      "10-NN,s=0.1: TOP1:  30.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 306\n",
      "VGG\n",
      "0.0001\n",
      "error:  3.963496197911809e-14 step  11\n",
      "cost:  0.6608294325959607\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [306][0/4]Time: 0.221 (0.221) Data: 0.155 (0.155) Loss: 0.9953 (0.9953)\n",
      "10-NN,s=0.1: TOP1:  28.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 307\n",
      "VGG\n",
      "0.0001\n",
      "error:  3.3495428652940973e-13 step  11\n",
      "cost:  0.6742580147420519\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [307][0/4]Time: 0.221 (0.221) Data: 0.155 (0.155) Loss: 0.9958 (0.9958)\n",
      "10-NN,s=0.1: TOP1:  28.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 308\n",
      "VGG\n",
      "0.0001\n",
      "error:  0.0 step  11\n",
      "cost:  0.6659868960788058\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [308][0/4]Time: 0.222 (0.222) Data: 0.157 (0.157) Loss: 1.0118 (1.0118)\n",
      "10-NN,s=0.1: TOP1:  25.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 309\n",
      "VGG\n",
      "0.0001\n",
      "error:  2.177147351289932e-13 step  11\n",
      "cost:  0.6761997986726639\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [309][0/4]Time: 0.224 (0.224) Data: 0.159 (0.159) Loss: 1.0353 (1.0353)\n",
      "10-NN,s=0.1: TOP1:  26.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 310\n",
      "VGG\n",
      "0.0001\n",
      "error:  0.0 step  11\n",
      "cost:  0.6745519411843631\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [310][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 1.0190 (1.0190)\n",
      "10-NN,s=0.1: TOP1:  27.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 311\n",
      "VGG\n",
      "0.0001\n",
      "error:  0.0 step  11\n",
      "cost:  0.6974154443296929\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [311][0/4]Time: 0.222 (0.222) Data: 0.157 (0.157) Loss: 1.0258 (1.0258)\n",
      "10-NN,s=0.1: TOP1:  30.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 312\n",
      "VGG\n",
      "0.0001\n",
      "error:  1.532107773982716e-13 step  11\n",
      "cost:  0.656673962990491\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [312][0/4]Time: 0.245 (0.245) Data: 0.179 (0.179) Loss: 1.0186 (1.0186)\n",
      "10-NN,s=0.1: TOP1:  29.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 313\n",
      "VGG\n",
      "0.0001\n",
      "error:  3.441691376337985e-14 step  11\n",
      "cost:  0.6498258482441123\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [313][0/4]Time: 0.218 (0.218) Data: 0.152 (0.152) Loss: 1.0432 (1.0432)\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 314\n",
      "VGG\n",
      "0.0001\n",
      "error:  1.787459069646502e-13 step  11\n",
      "cost:  0.6719397384971834\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [314][0/4]Time: 0.232 (0.232) Data: 0.166 (0.166) Loss: 1.0119 (1.0119)\n",
      "10-NN,s=0.1: TOP1:  26.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 315\n",
      "VGG\n",
      "0.0001\n",
      "error:  4.54081217071689e-14 step  11\n",
      "cost:  0.6710861624672552\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [315][0/4]Time: 0.230 (0.230) Data: 0.165 (0.165) Loss: 1.0467 (1.0467)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  0.0 step  11\n",
      "cost:  0.6798805991268642\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  25.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 316\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [316][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0145 (1.0145)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7195649874819392\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 317\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [317][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0090 (1.0090)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7183577533674365\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  26.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 318\n",
      "VGG\n",
      "0.0001\n",
      "Epoch: [318][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0372 (1.0372)\n",
      "10-NN,s=0.1: TOP1:  26.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 319\n",
      "VGG\n",
      "0.0001\n",
      "error:  1.482147737874584e-13 step  11\n",
      "cost:  0.7081349374414078\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [319][0/4]Time: 0.230 (0.230) Data: 0.159 (0.159) Loss: 0.9844 (0.9844)\n",
      "10-NN,s=0.1: TOP1:  25.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 320\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  2.042810365310288e-14 step  11\n",
      "cost:  0.6718113016507832\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [320][0/4]Time: 0.251 (0.251) Data: 0.175 (0.175) Loss: 0.9939 (0.9939)\n",
      "10-NN,s=0.1: TOP1:  25.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 321\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  9.603429163007604e-14 step  11\n",
      "cost:  0.6386133444584219\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [321][0/4]Time: 0.230 (0.230) Data: 0.164 (0.164) Loss: 1.0577 (1.0577)\n",
      "10-NN,s=0.1: TOP1:  25.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 322\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.268984917146554e-13 step  11\n",
      "cost:  0.6575445784390507\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [322][0/4]Time: 0.221 (0.221) Data: 0.156 (0.156) Loss: 1.0416 (1.0416)\n",
      "10-NN,s=0.1: TOP1:  25.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 323\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6521249491559116\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [323][0/4]Time: 0.223 (0.223) Data: 0.158 (0.158) Loss: 1.0675 (1.0675)\n",
      "10-NN,s=0.1: TOP1:  25.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 324\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  2.6645352591003757e-14 step  11\n",
      "cost:  0.7111392368727171\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [324][0/4]Time: 0.218 (0.218) Data: 0.152 (0.152) Loss: 1.0719 (1.0719)\n",
      "10-NN,s=0.1: TOP1:  26.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 325\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.097522238704187e-14 step  11\n",
      "cost:  0.7179181614921971\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [325][0/4]Time: 0.226 (0.226) Data: 0.159 (0.159) Loss: 1.0816 (1.0816)\n",
      "10-NN,s=0.1: TOP1:  26.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 326\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.1601830607332886e-13 step  11\n",
      "cost:  0.7275081050226496\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [326][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 1.0883 (1.0883)\n",
      "10-NN,s=0.1: TOP1:  26.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 327\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.681499549657019e-13 step  11\n",
      "cost:  0.7442144071609569\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [327][0/4]Time: 0.244 (0.244) Data: 0.180 (0.180) Loss: 1.0819 (1.0819)\n",
      "10-NN,s=0.1: TOP1:  27.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 328\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.80855330711438e-13 step  11\n",
      "cost:  0.7350462627327198\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [328][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 1.0948 (1.0948)\n",
      "10-NN,s=0.1: TOP1:  27.8\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 329\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.9240165016753963e-13 step  11\n",
      "cost:  0.7271855069562407\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [329][0/4]Time: 0.250 (0.250) Data: 0.183 (0.183) Loss: 1.0697 (1.0697)\n",
      "10-NN,s=0.1: TOP1:  28.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 330\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  7.238654120556021e-14 step  11\n",
      "cost:  0.7031033479064737\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [330][0/4]Time: 0.224 (0.224) Data: 0.153 (0.153) Loss: 1.0877 (1.0877)\n",
      "10-NN,s=0.1: TOP1:  28.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 331\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.3655743202889425e-14 step  11\n",
      "cost:  0.6685054338178416\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [331][0/4]Time: 0.243 (0.243) Data: 0.170 (0.170) Loss: 1.0676 (1.0676)\n",
      "10-NN,s=0.1: TOP1:  28.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 332\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  9.336975637097567e-14 step  11\n",
      "cost:  0.677191739781303\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [332][0/4]Time: 0.236 (0.236) Data: 0.160 (0.160) Loss: 1.0744 (1.0744)\n",
      "10-NN,s=0.1: TOP1:  27.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 333\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7037504756358128\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [333][0/4]Time: 0.215 (0.215) Data: 0.150 (0.150) Loss: 1.0611 (1.0611)\n",
      "10-NN,s=0.1: TOP1:  29.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 334\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.2529534621517087e-14 step  11\n",
      "cost:  0.7135333381147466\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [334][0/4]Time: 0.218 (0.218) Data: 0.153 (0.153) Loss: 1.0997 (1.0997)\n",
      "10-NN,s=0.1: TOP1:  28.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 335\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7331565382838316\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [335][0/4]Time: 0.229 (0.229) Data: 0.163 (0.163) Loss: 1.0605 (1.0605)\n",
      "10-NN,s=0.1: TOP1:  29.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 336\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7011399667287199\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [336][0/4]Time: 0.222 (0.222) Data: 0.156 (0.156) Loss: 1.1042 (1.1042)\n",
      "10-NN,s=0.1: TOP1:  28.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 337\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7183392237084317\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [337][0/4]Time: 0.224 (0.224) Data: 0.158 (0.158) Loss: 1.0708 (1.0708)\n",
      "10-NN,s=0.1: TOP1:  28.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 338\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7100701780004686\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [338][0/4]Time: 0.225 (0.225) Data: 0.158 (0.158) Loss: 1.0369 (1.0369)\n",
      "10-NN,s=0.1: TOP1:  28.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 339\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7021234303768104\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [339][0/4]Time: 0.219 (0.219) Data: 0.154 (0.154) Loss: 1.0800 (1.0800)\n",
      "10-NN,s=0.1: TOP1:  28.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 340\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.8185453143360064e-13 step  11\n",
      "cost:  0.6760423815950625\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [340][0/4]Time: 0.297 (0.297) Data: 0.230 (0.230) Loss: 1.0675 (1.0675)\n",
      "10-NN,s=0.1: TOP1:  28.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 341\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.561595462997502e-13 step  11\n",
      "cost:  0.7231857345694325\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [341][0/4]Time: 0.216 (0.216) Data: 0.151 (0.151) Loss: 1.0505 (1.0505)\n",
      "10-NN,s=0.1: TOP1:  27.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 342\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  8.104628079763643e-14 step  11\n",
      "cost:  0.672796456383195\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [342][0/4]Time: 0.240 (0.240) Data: 0.165 (0.165) Loss: 1.0521 (1.0521)\n",
      "10-NN,s=0.1: TOP1:  28.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 343\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.929567616798522e-13 step  11\n",
      "cost:  0.7023224559033601\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [343][0/4]Time: 0.220 (0.220) Data: 0.153 (0.153) Loss: 1.0738 (1.0738)\n",
      "10-NN,s=0.1: TOP1:  28.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 344\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.318456620604593e-13 step  11\n",
      "cost:  0.6816585757005456\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [344][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 1.0436 (1.0436)\n",
      "10-NN,s=0.1: TOP1:  29.3\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 345\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.2023715356690445e-13 step  11\n",
      "cost:  0.688245622769051\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [345][0/4]Time: 0.219 (0.219) Data: 0.153 (0.153) Loss: 1.0854 (1.0854)\n",
      "10-NN,s=0.1: TOP1:  28.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 346\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.8429702208777599e-13 step  11\n",
      "cost:  0.7054256042409801\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [346][0/4]Time: 0.243 (0.243) Data: 0.164 (0.164) Loss: 1.0708 (1.0708)\n",
      "10-NN,s=0.1: TOP1:  28.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 347\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.375077994860476e-14 step  11\n",
      "cost:  0.7229050533608445\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [347][0/4]Time: 0.222 (0.222) Data: 0.157 (0.157) Loss: 1.0743 (1.0743)\n",
      "10-NN,s=0.1: TOP1:  28.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 348\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.186340080674199e-14 step  11\n",
      "cost:  0.6969260032093918\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [348][0/4]Time: 0.334 (0.334) Data: 0.269 (0.269) Loss: 1.0075 (1.0075)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-NN,s=0.1: TOP1:  28.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 349\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6983430524417416\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [349][0/4]Time: 0.219 (0.219) Data: 0.152 (0.152) Loss: 1.0687 (1.0687)\n",
      "10-NN,s=0.1: TOP1:  28.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 350\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.375077994860476e-14 step  11\n",
      "cost:  0.6828419967560178\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [350][0/4]Time: 0.220 (0.220) Data: 0.155 (0.155) Loss: 1.0662 (1.0662)\n",
      "10-NN,s=0.1: TOP1:  28.7\n",
      "doing PCA with 4 components ..done\n",
      "50-NN,s=0.1: TOP1:  27.05\n",
      "50-NN,s=0.5: TOP1:  27.05\n",
      "10-NN,s=0.1: TOP1:  23.85\n",
      "10-NN,s=0.5: TOP1:  23.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 351\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.1080025785759062e-13 step  11\n",
      "cost:  0.7270919136459121\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [351][0/4]Time: 0.234 (0.234) Data: 0.167 (0.167) Loss: 1.0551 (1.0551)\n",
      "10-NN,s=0.1: TOP1:  28.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 352\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.653122083666858e-13 step  11\n",
      "cost:  0.676362652540103\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [352][0/4]Time: 0.217 (0.217) Data: 0.153 (0.153) Loss: 1.0774 (1.0774)\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 353\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  7.638334409421077e-14 step  11\n",
      "cost:  0.6781186886559569\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [353][0/4]Time: 0.218 (0.218) Data: 0.152 (0.152) Loss: 1.0489 (1.0489)\n",
      "10-NN,s=0.1: TOP1:  29.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 354\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7180555421719035\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [354][0/4]Time: 0.337 (0.337) Data: 0.272 (0.272) Loss: 1.0696 (1.0696)\n",
      "10-NN,s=0.1: TOP1:  28.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 355\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7122499056803662\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [355][0/4]Time: 0.238 (0.238) Data: 0.171 (0.171) Loss: 1.0515 (1.0515)\n",
      "10-NN,s=0.1: TOP1:  29.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 356\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7269561394266493\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [356][0/4]Time: 0.239 (0.239) Data: 0.173 (0.173) Loss: 1.0486 (1.0486)\n",
      "10-NN,s=0.1: TOP1:  28.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 357\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7233153143250781\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [357][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 1.0375 (1.0375)\n",
      "10-NN,s=0.1: TOP1:  28.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 358\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  8.892886427247504e-14 step  11\n",
      "cost:  0.7159134809606656\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [358][0/4]Time: 0.246 (0.246) Data: 0.179 (0.179) Loss: 1.0468 (1.0468)\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 359\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6989878272014391\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [359][0/4]Time: 0.228 (0.228) Data: 0.161 (0.161) Loss: 1.0398 (1.0398)\n",
      "10-NN,s=0.1: TOP1:  29.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 360\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6649690613144873\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [360][0/4]Time: 0.237 (0.237) Data: 0.171 (0.171) Loss: 1.0365 (1.0365)\n",
      "10-NN,s=0.1: TOP1:  28.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 361\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  9.203748874142548e-14 step  11\n",
      "cost:  0.7207316331066076\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [361][0/4]Time: 0.243 (0.243) Data: 0.177 (0.177) Loss: 1.0543 (1.0543)\n",
      "10-NN,s=0.1: TOP1:  28.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 362\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  9.814371537686384e-14 step  11\n",
      "cost:  0.6977050329115129\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [362][0/4]Time: 0.231 (0.231) Data: 0.165 (0.165) Loss: 1.0541 (1.0541)\n",
      "10-NN,s=0.1: TOP1:  28.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 363\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.3788969965844444e-13 step  11\n",
      "cost:  0.6740611061148928\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [363][0/4]Time: 0.229 (0.229) Data: 0.155 (0.155) Loss: 1.0747 (1.0747)\n",
      "10-NN,s=0.1: TOP1:  29.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 364\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.2811973704174306e-13 step  11\n",
      "cost:  0.7052818335186102\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [364][0/4]Time: 0.236 (0.236) Data: 0.170 (0.170) Loss: 1.0863 (1.0863)\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 365\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7276925520686733\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [365][0/4]Time: 0.216 (0.216) Data: 0.151 (0.151) Loss: 1.1116 (1.1116)\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 366\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [366][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0382 (1.0382)\n",
      "error:  1.0658141036401503e-13 step  11\n",
      "cost:  0.713905910826845\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.75\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 367\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [367][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0285 (1.0285)\n",
      "error:  1.6986412276764895e-14 step  11\n",
      "cost:  0.7106924985996629\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 368\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [368][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0882 (1.0882)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6913893101145231\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.05\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 369\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.695689333269069\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [369][0/4]Time: 0.234 (0.234) Data: 0.165 (0.165) Loss: 1.0595 (1.0595)\n",
      "10-NN,s=0.1: TOP1:  28.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 370\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  9.336975637097567e-14 step  11\n",
      "cost:  0.6666352858553394\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [370][0/4]Time: 0.220 (0.220) Data: 0.154 (0.154) Loss: 1.0309 (1.0309)\n",
      "10-NN,s=0.1: TOP1:  28.9\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 371\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6555733410624663\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [371][0/4]Time: 0.233 (0.233) Data: 0.168 (0.168) Loss: 1.0624 (1.0624)\n",
      "10-NN,s=0.1: TOP1:  28.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 372\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.1468603844377867e-13 step  11\n",
      "cost:  0.6962562864612105\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [372][0/4]Time: 0.219 (0.219) Data: 0.153 (0.153) Loss: 1.0212 (1.0212)\n",
      "10-NN,s=0.1: TOP1:  28.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 373\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6703167136315586\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [373][0/4]Time: 0.222 (0.222) Data: 0.157 (0.157) Loss: 1.1057 (1.1057)\n",
      "10-NN,s=0.1: TOP1:  28.5\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 374\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6853481016515469\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [374][0/4]Time: 0.222 (0.222) Data: 0.157 (0.157) Loss: 1.0274 (1.0274)\n",
      "10-NN,s=0.1: TOP1:  28.7\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 375\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.4861002973229915e-14 step  11\n",
      "cost:  0.6871830218847157\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [375][0/4]Time: 0.286 (0.286) Data: 0.217 (0.217) Loss: 1.0123 (1.0123)\n",
      "10-NN,s=0.1: TOP1:  28.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 376\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.6908727016652211\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [376][0/4]Time: 0.221 (0.221) Data: 0.155 (0.155) Loss: 1.0371 (1.0371)\n",
      "10-NN,s=0.1: TOP1:  27.95\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 377\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.2612133559741778e-13 step  11\n",
      "cost:  0.7091625023564427\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [377][0/4]Time: 0.232 (0.232) Data: 0.158 (0.158) Loss: 1.0273 (1.0273)\n",
      "10-NN,s=0.1: TOP1:  28.25\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 378\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.84297022087776e-14 step  11\n",
      "cost:  0.6865265379166697\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [378][0/4]Time: 0.279 (0.279) Data: 0.208 (0.208) Loss: 1.0588 (1.0588)\n",
      "10-NN,s=0.1: TOP1:  28.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 379\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [379][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0267 (1.0267)\n",
      "error:  1.4876988529977098e-14 step  11\n",
      "cost:  0.6891354183812458\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.4\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 380\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [380][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0281 (1.0281)\n",
      "error:  2.731148640577885e-14 step  11\n",
      "cost:  0.6731823580166199\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 381\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [381][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0645 (1.0645)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  7.038813976123492e-14 step  11\n",
      "cost:  0.7194679252721403\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.2\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 382\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [382][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0549 (1.0549)\n",
      "error:  4.884981308350689e-14 step  11\n",
      "cost:  0.6710563827356143\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  27.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 383\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [383][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0213 (1.0213)\n",
      "error:  0.0 step  11\n",
      "cost:  0.6726559095792009\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.85\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 384\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [384][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0377 (1.0377)\n",
      "error:  0.0 step  11\n",
      "cost:  0.7073445535633903\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 385\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [385][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0167 (1.0167)\n",
      "error:  1.587618925213974e-14 step  11\n",
      "cost:  0.6834598106925156\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 386\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.7185136858012785\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [386][0/4]Time: 0.238 (0.238) Data: 0.162 (0.162) Loss: 1.0248 (1.0248)\n",
      "10-NN,s=0.1: TOP1:  29.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 387\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  1.247890679678676e-13 step  11\n",
      "cost:  0.7329502445551361\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [387][0/4]Time: 0.265 (0.265) Data: 0.199 (0.199) Loss: 1.0297 (1.0297)\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 388\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  3.277378368693462e-13 step  11\n",
      "cost:  0.6997411795759342\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [388][0/4]Time: 0.226 (0.226) Data: 0.161 (0.161) Loss: 1.0800 (1.0800)\n",
      "10-NN,s=0.1: TOP1:  29.45\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 389\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.696812942037138\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [389][0/4]Time: 0.234 (0.234) Data: 0.168 (0.168) Loss: 1.0486 (1.0486)\n",
      "10-NN,s=0.1: TOP1:  29.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 390\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "error:  0.0 step  11\n",
      "cost:  0.661223099543386\n",
      "opt took 0.00min,   11iters\n",
      "Epoch: [390][0/4]Time: 0.232 (0.232) Data: 0.166 (0.166) Loss: 1.0510 (1.0510)\n",
      "10-NN,s=0.1: TOP1:  29.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 391\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [391][0/4]Time: 0.067 (0.067) Data: 0.001 (0.001) Loss: 1.0285 (1.0285)\n",
      "error:  2.354783035229957e-13 step  11\n",
      "cost:  0.6791172336941216\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.6\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 392\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [392][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0376 (1.0376)\n",
      "error:  1.6653345369377348e-14 step  11\n",
      "cost:  0.6654912835460496\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 393\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [393][0/4]Time: 0.067 (0.067) Data: 0.001 (0.001) Loss: 1.0050 (1.0050)\n",
      "error:  6.339373470609644e-14 step  11\n",
      "cost:  0.6945752759949437\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.55\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 394\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [394][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0495 (1.0495)\n",
      "error:  1.687538997430238e-14 step  11\n",
      "cost:  0.6753639046376976\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.0\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 395\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [395][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0460 (1.0460)\n",
      "error:  0.0 step  11\n",
      "cost:  0.691566753690082\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.1\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 396\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [396][0/4]Time: 0.066 (0.066) Data: 0.001 (0.001) Loss: 1.0222 (1.0222)\n",
      "error:  6.072919944699606e-14 step  11\n",
      "cost:  0.6837996822813186\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.65\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 397\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [397][0/4]Time: 0.066 (0.066) Data: 0.002 (0.002) Loss: 1.0019 (1.0019)\n",
      "error:  3.197442310920451e-14 step  11\n",
      "cost:  0.699720245270285\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  29.15\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 398\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [398][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 1.0663 (1.0663)\n",
      "error:  8.681944052568724e-14 step  11\n",
      "cost:  0.6931925058437903\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.35\n",
      "best accuracy: 40.95\n",
      "\n",
      "Epoch: 399\n",
      "VGG\n",
      "1.0000000000000003e-05\n",
      "Epoch: [399][0/4]Time: 0.065 (0.065) Data: 0.001 (0.001) Loss: 0.9913 (0.9913)\n",
      "error:  9.603429163007604e-14 step  11\n",
      "cost:  0.6828719225978277\n",
      "opt took 0.00min,   11iters\n",
      "10-NN,s=0.1: TOP1:  28.4\n",
      "best accuracy: 40.95\n",
      "doing PCA with 4 components ..done\n",
      "10-NN,s=0.1: TOP1:  36.75\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    selflabels = train(epoch, selflabels)\n",
    "    feature_return_switch(model, True)\n",
    "    \n",
    "    acc = my_kNN(model, K=10, sigma=0.1, dim=knn_dim)\n",
    "    feature_return_switch(model, False)\n",
    "#     writer.add_scalar(\"accuracy kNN\", acc, epoch)\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'opt': optimizer.state_dict(),\n",
    "            'L': selflabels,\n",
    "        }\n",
    "        if not os.path.isdir(exp):\n",
    "            os.mkdir(exp)\n",
    "        torch.save(state, '%s/best_ckpt.t7' % (exp))\n",
    "        best_acc = acc\n",
    "    if epoch % 100 == 0:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'opt': optimizer.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'L': selflabels,\n",
    "        }\n",
    "        if not os.path.isdir(exp):\n",
    "            os.mkdir(exp)\n",
    "        torch.save(state, '%s/ep%s.t7' % (exp, epoch))\n",
    "    if epoch % 50 == 0:\n",
    "        feature_return_switch(model, True)\n",
    "        acc = my_kNN(model, K=[50, 10], sigma=[0.1, 0.5], dim=knn_dim, use_pca=True)\n",
    "        i = 0\n",
    "#         for num_nn in [50, 10]:\n",
    "#             for sig in [0.1, 0.5]:\n",
    "#                 writer.add_scalar('knn%s-%s' % (num_nn, sig), acc[i], epoch)\n",
    "#                 i += 1\n",
    "        feature_return_switch(model, False)\n",
    "    print('best accuracy: {:.2f}'.format(best_acc * 100))\n",
    "end = time.time()\n",
    "\n",
    "checkpoint = torch.load('%s'%exp+'/best_ckpt.t7' )\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "feature_return_switch(model, True)\n",
    "acc = my_kNN(model, K=10, sigma=0.1, dim=knn_dim, use_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335.8529739379883\n"
     ]
    }
   ],
   "source": [
    "print (end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
